\documentclass[utf8, diplomski, lmodern]{fer}

\input{imports/font}

\input{imports/text}
\input{imports/math}
\input{imports/tables}
\input{imports/figures}
\input{imports/diagrams}
\input{imports/misc}

\input{imports/glossary}
\usepackage[toc]{appendix}


\begin{document}

\thesisnumber{1728}
\title{Nadzirani pristupi za procjenu nesigurnosti predikcija dubokih modela}
\author{Ivan Grubišić}
\maketitle

% Ispis stranice s napomenom o umetanju izvornika rada. Uklonite naredbu \izvornik ako želite izbaciti tu stranicu.
\izvornik
\subsection*{Nadzirani pristupi za procjenu nesigurnosti predikcija dubokih modela}

Procjena nesigurnosti predikcija vrlo je važan sastojak mnogih praktičnih primjena konvolucijskih modela računalnog vida. Do tog cilja možemo doći analizom višeznačnosti podataka, nesigurnosti odluke modela te vjerojatnosti da se podatak nalazi u distribuciji skupa za učenje. U ovom radu razmatramo pristupe koji procjenu nesigurnosti predikcija uče nadzirano, primjenom istih podataka na kojima se uči i promatrani model.

U okviru rada, potrebno je proučiti i ukratko opisati postojeće pristupe za procjenu nesigurnosti predikcija. Uhodati postupke procjene nesigurnosti dubokih konvolucijskih modela temeljene na nadziranom učenju. Validirati hiperparametre te prikazati i ocijeniti ostvarene rezultate na problemu semantičke segmentacije. Predložiti pravce budućeg razvoja.
Radu priložiti izvorni i izvršni kod razvijenih postupaka, ispitne slijedove i rezultate, uz potrebna objašnjenja i dokumentaciju. Citirati korištenu literaturu i navesti dobivenu pomoć.


% Dodavanje zahvale ili prazne stranice. Ako ne želite dodati zahvalu, naredbu ostavite radi prazne stranice.
\zahvala{zahvala}

\tableofcontents
%\listoffigures
%\listoftables

\newpage

\begingroup
\onehalfspacing
\printunsrtglossary[type=symbols,style=supergroup,title={Oznake}]
\endgroup



\chapter{Uvod}
Uvod rada. Nakon uvoda dolaze poglavlja u kojima se obrađuje tema.

duboko učenje

neizvjesnost modela

primjene procjene nesigurnosti

primjena na semantičkoj segmentaciji i procjeni dubine


\section{Struktura rada}



\chapter{Osnovni pojmovi}


\section{Teorija vjerojatnosti}

Jako važan pojam u strojnom učenju je nesigurnost ili neizvjesnost. Ona dolazi od šuma u mjerenju i iz konačnosti skupa podataka \citep{Bishop:2006:PRML}. Teorija vjerojatnosti nam omogućuje modeliranje nesigurnosti pronalaženje optimalnih zaključaka korištenjem dostupnih informacija.

Postoje dvije glavne interpretacije vjerojatnosti \citep{Murphy:2012:MLPP}. Jedna je \emph{frekventistička interpretacija} prema kojoj vjerojatnosti predstavljaju učestalosti različitih događaja ako se pokus ponavlja velik broj puta. Druga je \emph{bayesovska interpretacija} prema kojoj vjerojatnost izražava našu nesigurnost o ishodu pokusa. 
 
Ovo poglavlje daje kratak i matematički ne potpuno precizan pregled nekih od osnovnih pojmova i pravila vezanih uz vjerojatnost. Na strukturu ovog poglavlja imaju utjecaj \citet{Goodfellow:2016:DL,Murphy:2012:MLPP}.

\subsection{Slučajne varijable i razdiobe}

Neizvjesnost neke pojave modeliramo \emph{slučajnom varijablom}. Slučajnoj varijabli dodijeljena je \emph{razdioba} koja definira skup vrijednosti koje slučajna varijabla može poprimiti i vjerojatnosti ostvarivanja tih vrijednosti. Skup mogućih vrijednosti neke slučajne varijable još se naziva i \emph{prostor elementarnih događaja}. \emph{Elementarni događaj} je element prostora elementarnih događaja i, ako je $\rvar x$ slučajna varijabla za koju se u nekom eksperimentu opaža vrijednost $x$, taj događaj ima zapis $\cbr{\rvar x = x}$, a njegova vjerojatnost $\P(\cbr{\rvar x = x})$ ili $\P(\rvar x = x)$. \emph{Događaj} je skup vrijednosti i obično se izražava predikatom nad slučajnom varijablom: $\cbr{R(\rvar x)}=\cbr{x\colon R(x)}$. Ako je $\set X$ prostor elementarnih događaja slučajne varijable $\rvar x$, onda $\P(\rvar x\in \set X)=1$. Funkcija 
\begin{align*}
P_{\rvar x} \colon \set X &\to \intcc{0,1} \\
x &\mapsto \P(\rvar x=x)
\end{align*}
je \emph{funkcija vjerojatnosti} (engl. \textit{probability mass function}, \textit{pmf}).

Razlikujemo diskretne i kontinuirane slučajne varijable. Prostor elementarnih događaja diskretne slučajne varijable je prebrojiv skup. Razdioba kontinuirane slučajne varijable $\rvar x$ koja poprima vrijednosti iz skupa $\set X$ je određena \emph{funkcijom gustoće vjerojatnosti} (engl. \textit{probability density function}, \textit{pdf})
\begin{align*}
p_{\rvar x} \colon \set X &\to \intco{0,\infty} \\
x &\mapsto \p(x)
\end{align*}
za koju vrijedi
\begin{align}
\P(\rvar x\in \set A) = \int_{\set A} p_{\rvar x}(x)\dif x
\end{align}
za svaki $\set A\subset\set X$.

Funkciju gustoće vjerojatnosti možemo smatrati i \emph{poopćenom funkcijom}\footnote{\url{https://en.wikipedia.org/wiki/Distribution_(mathematics)}}. To nam omogućuje da funkcijom gustoće predstavljamo razdiobe za koje neki elementarni događaji imaju vjerojatnost veću od $0$. Diskretnu razdiobu onda možda možemo predstaviti funkcijom gustoće vjerojatnosti 
\begin{align} \label{eq:dirac-density}
p_{\rvar x}(x)=\sum_{x'\in\set X} \P(\rvar x=x) \dirac(x-x')  \text{,}
\end{align}
gdje je $\set X$ prostor elementarnih događaja slučajne varijable $\rvar x$, a $\delta$ Diracova delta, poopćena funkcija za koju vrijedi $\dirac(x)=0$ za $x\neq0$ i $\int_x\dirac(x)\dif x=1$. Diracova delta se može promatrati kao limes funkcije gustoće Gaussove razdiobe:
\begin{align*}
\delta(x)=\lim_{\sigma\to 0}\frac{1}{\sqrt{2\pi}\sigma}\exp\del{\frac{x^2}{2\sigma^2}}.
\end{align*}
Ako je $\rvar x$ vektor $\rvec x = (\rvar x_1,..,\rvar x_n)$, mora vrijediti
\begin{align}
\dirac(\vec x)\coloneqq\prod_i\dirac(x_i) \text{.}
\end{align}
Onda $n$-struki integral gustoće definirane izrazom \eqref{eq:dirac-density} ima vrijednost $1$. 

%npr. definirati i funkciju gustoće vjerojatnosti $p_{\rvar x}(x) = \frac{1}{2}\delta(x)+\frac{1}{2}$ definiranom na domeni $\intcc{0,1}$.

Razdioba slučajne varijable $\rvar x$ će se u ovom radu označavati s $\P(\rvar x)$ ako je diskretna, a s $\p(\rvar x)$ ako je kontinuirana ili neodređena. Funkcija (gustoće) vjerojatnosti će se označavati bez oznake slučajne varijable u indeksu ako je po slovu vrijednosti jasno o kojoj se varijabli radi. Druge oznake koje se koriste opisane su u popisu oznaka na početku rada. Na nekim mjestima će radi kratkoće riječ \textit{razdioba} imati značenje \textit{funkcija gustoće} ili \textit{funkcija vjerojatnosti}.

\subsection{Združena, uvjetna i marginalna vjerojatnost i osnovna pravila vjerojatnosti}

Dvije razdiobe su iste ako imaju iste funkcije gustoće vjerojatnosti. Dvije slučajne varijable, i ako imaju istu razdiobu, ne moraju biti iste jer se mogu razlikovati po odnosima s drugim slučajnim varijablama.

Možemo razmatrati više slučajnih varijable zajedno (združenu slučajnu varijablu) i njihovu \emph{združenu razdiobu} $\p(\rvar x,\rvar y)$. Događaji onda imaju oblik $\cbr{R(\rvar x,\rvar y)}$. Elementarni događaj onda ima oblik $\cbr{\rvar x=x, \rvar y=y}$. Dalje će se izrazi pravila vjerojatnosti odnositi samo na elemntarne događaje. Npr. $x, y$ će skraćeno označavati $\cbr{\rvar x=x, \rvar y=y}$ kada je jasno po slovima o kojim se slučajnim varijablama radi. Ista pravila vjerojatnosti vrijede i za općenitije događaje jer za svaki događaj možemo definirati indikatorsku slučajnu varijablu kojoj je taj događaj elementarni događaj: $\rvar e_i = \enbbracket{R_i(\rvar x, \rvar y)}$. Takve slučajne varijable imaju skup elementarnih događaja $\cbr{0,1}$ i za njih vrijede ista pravila.

\emph{Uvjetna vjerojatnost} je vjerojatnost nekog događaja ako je poznato da se neki drugi događaj ostvario. Ovako je definirana uvjetna vjerojatnost događaja $\cbr{\rvar x=x}$ ako je poznato da se ostvario događaj $\cbr{\rvar y=y}$:
\begin{align} \label{eq:uvjetna-vj}
\p(x\mid y) \coloneqq \frac{\p(x,y)}{\p(y)}  \text{.}
\end{align}

Združena vjerojatnost se može rastaviti \emph{pravilom umnoška}: 
\begin{align}
\p(x,y) = \p(x\mid y)\p(y) \text{.}
\end{align}
Općenitije, pravilo umnoška za $n$ slučajnih varijabli $\rvar x_1,..,\rvar x_n$ izgleda ovako:
\begin{align} \label{eq:pravilo-umnoska}
\p(x_1,..,x_n) 
&=\p(x_1)\p(x_2\mid x_1)\cdots\p(x_n\mid x_1,..,x_{n-1})  \\
&=\p(x_1)\prod_{i=2\bidot n}\p(x_i\mid x_1,..,x_{i-1})  \text{.}
\end{align}

\emph{Marginalna vjerojatnost} slučajne varijable $\rvar x$ je $\p(x)=\p(\rvar x=x,\rvar y\in\set Y)$, gdje je $\set Y$ prostor elementarnih događaja slučajne varijable $\rvar y$. Izraženo gustoćom vjerojatnosti (\emph{pravilo zbroja}, \emph{marginalizacija}):
\begin{align}
\p(x) = \int_{\set Y}\p(x,y)\dif y = \int_{\set Y}\p(x\mid y)\p(y)\dif y \text{.}
\end{align}

Dvije slučajne varijable koje imaju istu razdiobu ne moraju biti u istom odnosu prema drugim slučajnim varijablama. Npr. ako $\rvar x_1\sim q_1$, $\rvar x_2\sim q_1$ i $\rvar y\sim q_2$, ne mora vrijediti $\p(\rvar x_1, \rvar y) = \p(\rvar x_2, \rvar y)$.

Rastavljanjem lijeve strane jednadžbe~\eqref{eq:pravilo-umnoska} na umnožak $\p(x\mid y)\p(y)$ dobivamo \emph{Bayesovo pravilo}:
\begin{align}
\p(x\mid y) = \frac{\p(y\mid x)\p(x)}{\p(y)} \text{,}
\end{align}
što možemo i ovako zapisati:
\begin{align}
\p(x\mid y) = \frac{\p(y\mid x)\p(x)}{\int\p(y\mid x)\p(x)\dif x} \text{,}
\end{align}
gdje se nazivnik integrira po svim vrijednostima.

\subsection{Nezavisnost, uvjetna nezavisnost i uvjetna zavisnost}

Kada su dvije slučajne varijable $\rvar x$ i $\rvar y$ \emph{zavisne}, što se označava $\rvar x\not\perp\rvar y$, znanje o ishodu jedne utječe na znanje o ishodu druge, tj. uvjetna razdioba $\p\del{\rvar x\mid\rvar y = y}$ ovisi o ishodu $y$. \textit{Znanje o ishodu} ne mora značiti da je ishod poznat. Dovoljna je promjena znanja o razdiobi koja može biti posljedica opažanja neke treće slučajne varijable. Slučajne varijable $\rvar x$ i $\rvar y$ su \emph{nezavisne}, što se označava $\rvar x\perp\rvar y$, akko za svaki par $(x, y)$ vrijedi
\begin{align}
\p(x,y)=\p(x)\p(y) \text{,}
\end{align}
ili, ekvivalentno,
\begin{align}
\p(x\mid y) = \p(x) \text{.}
\end{align}
Znanje o ishodu jedne slučajne varijable onda ne utječe na znanje o ishodu druge.

Slučajne varijable $\rvar x$ i $\rvar y$, koje mogu biti zavisne, su uz znanje o ishodu slučajne varijable $\rvar z$ \emph{uvjetno nezavisne}, što se označava $\rvar x\perp\rvar y\mid\rvar z$, akko su slučajne varijable $\del{\rvar x\mid\rvar z=z}$ i $\del{\rvar y\mid\rvar z=z}$ nezavisne za svaki mogući ishod $z$. Onda za svaku trojku $(x,y,z)$ vrijedi
\begin{align}
\p(x,y\mid z) = \p(x\mid z)\p(y\mid z) \text{,}
\end{align}
 ili, ekvivalentno,
\begin{align}
\p(x\mid y,z) = \p(x\mid z) \text{.}
\end{align}

Isto tako, slučajne varijable $\rvar x$ i $\rvar y$ koje su nezavisne mogu biti \emph{uvjetno zavisne} uz znanje o ishodu neke slučajne varijable $\rvar z$. Općenito, dvije slučajne varijable ne moraju biti ni uvjetno zavisne ni uvjetno nezavisne jer neki ishodi treće slučajne varijable mogu utjecati na njihovu zavisnost, a neki ne. Također se može govoriti i o zavisnosti ili nezavisnosti pojedinih događaja.

\subsection{Očekivanje, varijanca i kovarijanca}

\emph{Očekivanje} (prvi moment) slučajne varijable definirano je ovako:
\begin{align}
\E\rvar x \coloneqq \int x\p(x)\dif x \text{,}
\end{align}
gdje se integrira po prostoru elementarnih događaja. Još se označava ovako: $\mu_{\rvar x}$. Očekivanje funkcije slučajne varijable zapisujemo ovako:
\begin{align}
\E_{x\sim\rvar x} f(x) \coloneqq \E f(\rvar x) = \int f(x)\p(x)\dif x \text{.}
\end{align}
Ako je po oznaci jasno o kojoj se slučajnoj varijabli radi, možemo kraće pisati $\E_{\rvar x} f(x)$. Očekivanje ima svojstvo linearnosti:
\begin{align}
\E\sbr{\alpha f(\rvar x)+\beta g(\rvar x)} = \alpha\E f(\rvar x)+\beta\E g(\rvar x) \text{.}
\end{align}

\emph{Varijanca} (disperzija, drugi centralni moment) slučajne varijable definirana je ovako:
\begin{align}
\D\rvar x \coloneqq \E\sbr{\del{\rvar x-\E \rvar x}^2} = \int (x-\E \rvar x)^2 \p(x)\dif x \text{.}
\end{align}
Varijanca se može izraziti preko drugog momenta $\E{\rvar x}^2$ i kvadrata očekivanja $\del{\E\rvar x}^2$:
\begin{align}
\D\rvar x 
&= \E\sbr{\del{\rvar x-\E \rvar x}^2} = \E\sbr{\del{{\rvar x}^2-2x\E \rvar x+\del{\E\rvar x}^2}} \\
&= \E{\rvar x}^2-2\del{\E\rvar x}^2+\del{\E\rvar x}^2 = \E{\rvar x}^2 - \del{\E\rvar x}^2  \text{.}
\end{align}
Drugi korijen varijance je standardna devijacija $\sigma_{\rvar x}$.

\emph{Kovarijanca} para slučajnih varijabli definirana je ovako:
\begin{align}
\Cov\del{\rvar x,\rvar y} \coloneqq \E\sbr{\del{\rvar x-\E\rvar x}\del{\rvar y-\E\rvar y}} = \E{\rvar x\rvar y} - \del{\E\rvar x}\del{\E\rvar y} \text{.}
\end{align}
\emph{Kovarijacijska matrica} slučajnog vektora $\rvec x\in\R^n$ je matrica tipa $n\times n$ takva da:
\begin{align}
\Cov\del{\rvec x}_{\sbr{i,j}} = \Cov\del{\ind{\rvec x}{i}, \ind{\rvec x}{j}} \text{.}
\end{align}
Dijagonalni elementi te matrice su $\Cov\del{\rvec x}_{\sbr{i,i}} = \D\ind{\rvec x}{i}$.

\subsection{Funkcije slučajnih varijabli}

Neka je odnos između slučajnih varijabli $\rvar x$ i $\rvar y$ definiran funkcijom $f$ koja ishode jedne slučajne varijable deterministički preslikava u ishode druge, što se označava ovako: $\rvar y = f(\rvar x)$.  Ako su $\rvar x$ i $\rvar y$ diskretne slučajne varijable, onda je razdioba slučajne varijable $\rvar y$ definirana ovako:
\begin{align}
	P_{\rvar y}(y) = \sum_{x\colon f(x)=y} P_\rvar{x}(x) \text{.}
\end{align} 
Ako su $\rvar x$ i $\rvar y$ kontinuirane slučajne varijable s vrijednostima iz $\R$ i $f$ je injektivna, može se pokazati \citep{Elezovic:2007:VSSV} da vrijedi
\begin{align}
p_{\rvar y}(y) = p_\rvar{x}(x) \envert{\od{x}{y}} \text{.}
\end{align} 
To se može poopćiti i na vektore. Onda je $p_{\rvec y}(\vec y)=\envert{\det\pd{\vec x}{\vec y}}$ \citep{Murphy:2012:MLPP}.

%Neka je $c_{\rvar x}(x) := \int_{-\infty}^{x} p_{\rvar x}(x') \dif{x'}$.
%Vrijednosti iz intervala $\intoo{x, x+\epsilon}$ na kojem je $f$ monotono rastuća preslikavaju se u interval $\intoo{f(x), f(x+\epsilon)}$ (granice su obrnute ako je monotono padajuća) i vrijedi $c_{\rvar x}(x+\epsilon)-c_{\rvar x}(x) = c_{\rvar y}(f(x)+\epsilon)-c_{\rvar y}(f(x))$.

Neka je $\rvar z$ zbroj slučajnih varijabli $\rvar x$ i $\rvar y$. Onda vrijedi
\begin{align}
	p_{\rvar z}(z) = \int p_{\rvar x,\rvar y}(x, z-x)\dif x \text{.}
\end{align}
Ako su $\rvar x$ i $\rvar y$ nezavisne, onda to postaje konvolucija:
\begin{align}
p_{\rvar z}(z) = \int p_{\rvar x}(x)p_{\rvar y}(z-x)\dif x \eqqcolon (p_{\rvar x}*p_{\rvar y})(z) \text{.}
\end{align}

\subsection{Primjeri razdioba}

\emph{Bernoullijeva razdioba} je binarna razdioba s prostorom elementarnih događaja koji je obično $\{0,1\}$. Ona je onda određena parametrom $\mu\in\intcc{0,1}$ i ima ova svojstva:
\begin{align}
	\P(x) &= \mu \enbbracket{x=1} + (1-\mu) \enbbracket{x=0} = \mu^x(1-\mu)^{1-x}, \\
	\E \rvar x &= \mu, \\
	\D \rvar x &= \mu(1-\mu) \text{.}
\end{align}

\emph{Kategorička razdioba} je poopćenje Bernoullijeve razdiobe na konačan prostor elementarnih događaja koji može imati više od 2 vrijednosti. Ako prostor elementarnih događaja ima kardinalitet $n$, razdioba je određena vektorom $\vec p\in\intcc{0,1}^{n-1}$ za koji vrijedi $\sum_i p_{\sbr{i}}\leq 1$. Prostor elementarnih događaja ne mora biti skup $\cbr{1\bidot n}$ pa je kategorička razdioba najopćenitija diskretna razdioba nad konačnim skupom elementarnih događaja.

\emph{Eksponencijalna razdioba} je kontinuirana razdioba s domenom $\R_{\geq0}$. Ona je definirana parametrom $\lambda\in\R_{>0}$ ili $\beta=\lambda^{-1}$ i ima ova svojstva:
\begin{align}
\p(x) &= \lambda\exp(-\lambda x) \\
\E \rvar x &= \lambda^{-1}, \\
\D \rvar x &= \lambda^{-2} \text{.}
\end{align}

\emph{Laplaceova razdioba} je kontinuirana razdioba definirana parametrima $\beta\in\R_{>0}$ i $\mu \in \R$ i ima ova svojstva:
\begin{align}
\p(x) &= \frac{1}{2\beta}\exp\del{-\frac{\envert{x}}{\beta}} \\
\E \rvar x &= \mu, \\
\D \rvar x &= \beta^2 \text{.}
\end{align}

\emph{Gaussova (normalna) razdioba} je kontinuirana razdioba definirana parametrima $\mu\in\R$ i $\sigma \in \R_{>0}$ i ima ova svojstva:
\begin{align}
\p(x) &= \frac{1}{\sqrt{2\pi\sigma^2}}\exp\del{\frac{\del{x-\mu}^2}{2\sigma^2}} \\
\E \rvar x &= \mu, \\
\D \rvar x &= \sigma^2 \text{.}
\end{align}
Neka je $\rvar z_n = \frac{\sum_{i=1}^n \del{\rvar x_i-\mu}}{\sigma\sqrt{n}}$ normalizirani zbroj $n$ nezavisnih slučanih varijabli $\rvar x_i$ koje imaju jednaku razdiobu s očekivanjem $\mu$ i varijancom $\sigma^2$. Prema centralnom graničnom teoremu, $\rvar z_n$ u razdiobi konvergira prema Gaussovoj razdiobi kada $n\to\infty$, tj.
\begin{align}
\lim_{n\to\infty} \P(\rvar z_n<z) = \int_{-\infty}^{z} p_{\mathcal{N}(0,1)}(z')\dif{z'} \text{.}
\end{align}
$p_{\mathcal{N}(0,1)}$ označava funkciju gustoće normalne razdiobu s $\mu=0$ i $\sigma=1$. To je detaljnije objašnjeno i dokazano npr. u \citep{Elezovic:2007:VSSV}. Centralni granični teorem je ilustriran na slici~\ref{fig:clt}.

\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{clt}
	\caption{Ilustracija centralnog graničnog teorema. Grafovi za različite brojeve pribrojnika $n$ prikazuju funkcije gustoće vjerojatnosti normaliziranih zbrojeva nezavisnih slučajnih varijabli s razdiobom prikazanom prvim grafom. Zadnji graf prikazuje funkciju gustoće Gaussove razdiobe s očekivanjem $0$ i varijancom $1$.}
	\label{fig:clt}
\end{figure}

% TODO višedimenzionalna Gaussova razdioba


\section{Teorija informacije}

Jedan od osnovnih pojmova u teoriji informacije je \emph{sadržaj informacije} koji događaj preslikava u nenegativan realni broj:
\begin{align}
\I(x\in\set A)\coloneqq\log_b \frac{1}{\P(x\in\set A)} = -\log_b \P(x\in\set A) \text{.}
\end{align}
Događaji koji imaju manju vjerojatnost sadrže više informacije. Ako je vjerojatnost nekog događaja $1$, njegov sadržaj informacije je $0$. $b$ je najčešće $2$ ili $e$.

Sadržaj informacije odgovara minimalnom broju simbola (bitova ako $b=2$) potrebnih za kodiranje elementarnih događaja prefiksnim kodom za koji je očekivanje duljine poruke minimalno \citep{Olah:2015:VIT}. Kod prefiksnog koda nijedna kodna riječ nije prefiks neke druge kodne riječi. Takav kod se može prenositi kao niz združenih kodnih riječi bez posebnog simbola za označavanje granica između kodnih riječi. Donja granica očekivanja duljine poruke kod optimalnog koda naziva se \emph{entropija}:
\begin{align}\label{eq:entropy}
\H(\rvar x) \coloneqq  \E_{\rvar x}\I(\rvar x=x) = -\E_{\rvar x}\log_b \P(x) \text{.}
\end{align}
Ona iskazuje neizvjesnost diskretne slučajne varijable. Entropija će biti $0$ ako je vjerojatnost nekog elementarnog događaja $1$, a najveća će biti kada svi elementarni događaji imaju istu vjerojatnost: $\H(\rvar x)=\log_b n$, gdje je $n$ broj elementarnih događaja. 

Entropija kontinuirane slučajne varijable je beskonačna. Ako se u izrazu \eqref{eq:entropy} vjerojatnost zamijeni gustoćom vjerojatnosti, onda on predstavlja \emph{diferencijalnu entropiju}, jedan od analoga\footnote{\url{https://en.wikipedia.org/wiki/Differential_entropy}} entropije za kontinuirane varijable koji nema neka od svojstava koja ima entropija.

\emph{Unakrsna entropija} je mjera koja iskazuje donju granicu očekivanja duljine poruke kodirane optimalnim kodom za razdiobu $\P(\rvar y)$ dok izvor poruka ima  razdiobu $\P(\rvar x)$. Ovako je definirana:
\begin{align}
\H_{\rvar y}(\rvar x)\coloneqq \E_{\rvar x}\I(\rvar y=x) = -\E_{\rvar x}\log_b P_{\rvar y}(x) \text{.}
\end{align}
Za $\P(\rvar y) = \P(\rvar x)$ je $\H_{\rvar y}(\rvar x) = \H_{\rvar x}(\rvar x)=\H(\rvar x)$. Za unakrsnu entropiju se često koristi oznaka $\H(\rvar x,\rvar y)$, ali ista oznaka se koristi i za entropiju združene slučajne varijable $(\rvar x,\rvar y)$. Po uzoru na \citet{Olah:2015:VIT}, ovdje koristimo oznaku $\H_{\rvar y}(\rvar x)$.

Kao mjera razlike između dviju razdioba često se koristi \emph{relativna entropija} ili \emph{Kullback-Leiblerova divergencija} (KL-divergencija):
\begin{align}
	\Dkl{\rvar x}{\rvar y} \coloneqq \H_{\rvar y}(\rvar x) - \H(\rvar x) = \E_{\rvar x} \log_b\frac{P_{\rvar x}(x)}{P_{\rvar y}(x)} \text{.}
	\label{eq:dkl}
\end{align}
Ona je uvijek pozitivna i mjeri koliko simbola više se u prosjeku koristi ako se opaža razdioba $\P(\rvar x)$, a događaji se kodiraju kodom optimalnim za razdiobu $\P(\rvar y)$. KL-divergencija će biti $0$ akko $\rvar x$ i $\rvar y$ imaju iste razdiobe. To je ilustrirano slikom~\ref{fig:dkl}. KL-divergencija, kao ni unakrsna entropija, nije simetrična (slika~\ref{fig:dkl-asymmetry}), tj. općenito $\Dkl{\rvar x}{\rvar y}\neq\Dkl{\rvar y}{\rvar x}$ i $\H_{\rvar y}(\rvar x)\neq\H_{\rvar x}(\rvar y)$. KL-divergencija je izrazom \eqref{eq:dkl} definirana i za kontinuirane slučajne varijable ako se funkcije vjerojatnosti zamijene funkcijama gustoće vjerojatnosti. Ona divergira kada postoji $x$ za koji $P_{\rvar x}(x)>0$ i $P_{\rvar y}(x)=0$ ili, u slučaju kontinuiranih razdioba, $p_{\rvar x}(x)>0$ i $p_{\rvar y}(x)=0$.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\draw[thick] (0,0) rectangle (8,3.5ex) node[pos=.5] {$\H_{\rvar y}(\rvar x)$};
	\draw[thick] (0,3.5ex) rectangle (5,7ex) node[pos=.5] {$\H(\rvar x)$};
	\draw[thick] (5,3.5ex) rectangle (8,7ex) node[pos=.5] {$\Dkl{\rvar x}{\rvar y}$};
	\end{tikzpicture}
	\caption{Odnos entropije, unakrsne entropije i KL-divergencije.}
	\label{fig:dkl}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{dkl-asymmetry}
	\caption{Asimetričnost KL-divergencije. $p$ je fiksna razdioba (funkcija gustoće), a $q*$ je Gaussova razdioba koja ju aproksimira minimizacijom KL-divergencije $\Dkl{q}{p}$ (lijevo) ili $\Dkl{p}{q}$ (desno). U donjem retku grafovi prikazuju podintegralne funkcije odgovarajućih KL-divergencija. Kod njih zbrojevi predznačenih površina obojanih područja odgovaraju KL-divergencijama $\Dkl{q}{p}$ (zeleno) ili $\Dkl{p}{q}$ (crveno). Optimalna aproksimirajuća razdioba desno ima veliku gustoću gdje god razdioba $p$ ima veliku gustoću. Lijevo optimalna aproksimirajuća razdioba nema veliku gustoću gdje razdioba $p$ nema veliku gustoću. Da je razmak između komponenata razdiobe $p$ malo manji, i lijeva razdioba $q^*$ bi pokrila oba moda i bila sličnija desnoj. Slika je napravljena po uzoru na sliku~3.6 u \citet{Goodfellow:2016:DL}.}
	\label{fig:dkl-asymmetry}
\end{figure}

\emph{Međusobna informacija} je mjera zavisnosti između slučajnih varijabli. Definirana je ovako:
\begin{align}
\I\del{\rvar x;\rvar y} \coloneqq \E_{\rvar x, \rvar y} \log_b\frac{P_{\rvar x, \rvar y}(x, y)}{P_{\rvar x}(x)P_{\rvar y}(y)} \text{,}
\label{eq:mutinf}
\end{align}
a može se i na ove načine izraziti:
\begin{align}
\I(\rvar x;\rvar y)
&= \H(\rvar x)+\H(\rvar y)-\H(\rvar x, \rvar y) \\
&= \H(\rvar x)-\H(\rvar x\mid \rvar y) \\ 
&= \H(\rvar y)-\H(\rvar y\mid\rvar x) \text{,}
\label{eq:mutinf2}
\end{align}
gdje je
\begin{align}
\H(\rvar x\mid \rvar y) \coloneqq \E_{\rvar x} \H(\rvar y\mid \rvar x=x)
\label{eq:condentropy}
\end{align}
\emph{uvjetna entropija}. Ako su $\rvar x$ i $\rvar y$ nezavisne, njihova međusobna informacija će biti $0$. Ako npr. postoji surjekcija $f$ tako da $\rvar y=f(\rvar x)$, tj. poznavanje ishoda varijable $\rvar x$ jednoznačno određuje ishod varijable $\rvar y$, onda $\H(\rvar y\mid\rvar x)=0$ i $\I(\rvar x;\rvar y) = \H(\rvar y)$. Ako je $f$ bijekcija, onda $\I(\rvar x;\rvar y) = \H(\rvar x) = \H(\rvar y)$. Definirane veličine mogu se prikazati kao na slici~\ref{fig:entropije}. Isti odnosi vrijede ako se entropija zamijeni diferencijalnom entropijom.

\begin{figure}
\centering
\begin{tikzpicture}
\draw[thick] (0,10.5ex) rectangle (5,14ex) node[pos=.5] {$\H(\rvar x)$};

\draw[thick] (0,7ex) rectangle (3,10.5ex) node[pos=.5] {$\H(\rvar x\mid\rvar y)$};	
\draw[thick] (3,7ex) rectangle (5,10.5ex) node[pos=.5] {$\I(\rvar x,\rvar y)$};
\draw[thick] (5,7ex) rectangle (8,10.5ex) node[pos=.5] {$\H(\rvar y\mid\rvar x)$};	
	
\draw[thick] (3,3.5ex) rectangle (8,7ex) node[pos=.5] {$\H(\rvar y)$};
\draw[thick] (0,0) rectangle (8,3.5ex) node[pos=.5] {$\H(\rvar x,\rvar y)$};
\end{tikzpicture}
\caption{Odnosi informacijsko-teorijskih veličina dviju slučajnih varijabli.}
\label{fig:entropije}
\end{figure}


\section{Optimizacija temeljena na gradijentu}

U ovom odjeljku su opisani osnovni optimizacijski algoritmi temeljeni na gradijentu. Oni su bitni u strojnom učenju (poglavlje \ref{chap:nsu}), posebno u dubokom učenju (poglavlje \ref{chap:dukm}). Izvedeni algoritmi koji se primjenjuju u dubokom učenju opisani su u pododjeljku \ref{subsec:dukn-u-optimizacijski-algoritmi}.

Neka je $\funcdef{f}{\R^n}{\R}$ funkcija čiji minumom želimo naći s obziroma na parametre $\vec x$. Ona se u okolini točke $\vec x$, ako je dovoljno (beskonačno) puta derivabilna može izraziti Taylorovim redom:
\begin{align}
f(\vec x+\vec d) = f(\vec x) + \pd{}{\vec x}f(\vec x)\vec d + \frac{1}{2}\vec d^\tp{\tfrac{\partial^2y}{\partial\vec x\partial\vec x^\tp}}{\vec x}f(\vec x)\vec d + \cdots \text{.}
\end{align}
S drugačijim oznakama:
\begin{align} \label{eq:taylorov-red}
f(\vec x+\vec d) = f(\vec x) + \nabla_{\vec x}f(\vec x)^\tp\vec d + \frac{1}{2}\vec d^\tp\mat H_f(\vec x)\vec d + \cdots \text{.}
\end{align}

\subsection{Gradijentni spust}

Ako je $\vec d$ ima malu normu, funkciju $f$ u okoline neke točke možemo dobro aproksimirati s prvih nekoliko članova Taylorovog reda. \emph{Gradijentni spust} je optimizacijski algoritam koji koristi linearnu aproksimaciju i iterativnim ažuriranjem parametara u smjeru gradijenta (\textit{najstrmijem} smjeru) traži minimum. Iteracija gradijentnog spusta ima ovakav oblik:
\begin{align}
\vec x_{i+1} = \vec x_i - \eta\nabla_{\vec x}f(\vec x_i) \text{,}
\end{align}
gdje je $i$ redni broj iteracije, a $\eta$ \emph{veličina koraka} (\emph{stopa učenja} kod strojnog učenja) koja može biti konstanta ili može ovisiti o broju iteracije $i$. Neka $\vec g=\nabla_{\vec x}f(\vec x)$ i $\mat H=\mat H_f(\vec x)$. Za dovoljno mal $\eta$
\begin{align} \label{eq:grad-delta-approx}
f(\vec x-\eta\vec g) \approx f(\vec x) - \eta\vec g^\tp\vec g - \frac{1}{2}\eta^2\vec g^\tp\mat H\vec g
\end{align}
Uz neke blage uvjete koje mora zadovoljavati $f$ i dovoljno mal $\eta$, gradijentni spust konvergira, tj. proizvoljno se blizu približi nekom lokalnom minimumu (ili stacionarnoj točki koja nije lokalni minimum, gdje $\nabla_{\vec x}f(\vec x)=\cvec 0$) ovisno o $\eta$. Jedan blagi uvjet može biti \emph{Lipschitz kontinuiranost} funkcije $f$ ili njene derivacije \citep{Goodfellow:2016:DL}. Funkcija $f$ je Lipschitz kontinuirana ako postoji konstanta $\lambda$ za koju za svaki par $(\vec x,\vec y)$ vrijedi:
\begin{align}
\envert{f(\vec x)-f(\vec y)} < \lambda\enVert{\vec x-\vec y} \text{.}
\end{align}
Najmanji takav $\lambda$ naziva se \emph{Lipschitzova konstanta}.

\subsection{Postupci drugog reda}

Ovaj pododjeljak se temelji na \citet{Goodfellow:2016:DL}.

Ako koristimo kvadratnu aproksimaciju~\eqref{eq:grad-delta-approx}, možemo pokušati pronaći optimalni $\eta$ koji ju minimizira. $\eta$ za koji $\pd{}{\eta}f(\vec x-\eta\vec g)=0$ će, ako $\vec g^\tp\mat H\vec g>0$ dati minimum u smjeru gradijenta kvadratne aproksimacije funkcije $f$ u točki $\vec x$. Dobije se:
\begin{align}
\eta = \frac{\vec g^\tp \vec g}{\vec g^\tp\mat H\vec g} \text{.}
\end{align}
Ako je $\funcdef{f}{\R^n}{\R}$ konveksna (pozitivno definitna) kvadratna funkcija, izmijenjeni algoritam gradijentnog spusta, koji ovako određuje veličinu koraka, minimum pronalazi u najviše $n$ koraka. 

Postupak drugog reda koji se ne ograničava na pomake u smjeru gradijenta je \emph{Newton-Raphsonov postupak}. Deriviranjem desne strane jednadžbe~\eqref{eq:taylorov-red} po $\vec d$ i izjednačavanjem s $\cvec 0$ dobiva se:
\begin{align}
\cvec 0 = \nabla_{\vec x}f(\vec x)^\tp + \vec d^\tp\mat H_f(\vec x) + \cdots \text{.}
\end{align}
Uz kvadratnu aproksimaciju i kraće oznake $\vec g=\nabla_{\vec x}f(\vec x)$ i $\mat H=\mat H_f(\vec x)$: $\mat H\vec d = \vec g$. Slijedi da je pomak $\vec d$ koji daje stacionarnu točku aproksimacije
\begin{align}
\vec d = \mat H^{-1}\vec g \text{.}
\end{align}
Za nekvadratne funkcije, koje imaju pozitivno definitnu Hesseovu matricu u svakoj točki, može se iterativno primjenjivati
\begin{align}
\vec x_{i+1} = \vec x_i - \eta\mat H_f(\vec x_i)\nabla_{\vec x}f(\vec x_i)
\end{align}
s $\eta<1$.





\chapter{Statističko modeliranje}


\section{Probabilistički grafički modeli}

Neka su $\rvar x_1, .., \rvar x_n$ slučajne varijable čiju združenu razdiobu razmatramo. Želimo na temelju opežanih varijabli korištenjem pravila vjerojatnosti \emph{zaključivati} o razdiobama nekih neopažanih varijabli. Općenito, zaključivanje se provodi uvjetovanjem po opažanim varijablama i marginalizacijom po varijablama koje nas ne zanimaju izravno \citep{Murphy:2012:MLPP}:
\begin{align}
\p(\vec x_\text{q}\mid\vec x_\text{o}) 
= \frac{\p(\vec x_\text{q},\vec x_\text{o})}{\p(\vec x_\text{o})} 
= \frac{\int\p(\vec x_\text{q},\vec x_\text{n},\vec x_\text{o})\dif\vec x_\text{n}}{\int\p(\vec x_\text{q},\vec x_\text{n},\vec x_\text{o})\dif(\vec x_\text{q},\vec x_\text{n})} \text{.}
\label{eq:pgm-zakljucivanje-bayes}
\end{align}
Ovdje je $\rvec x_\text{q}$ niz varijabli o kojima želimo zaključivati (varijable upita), $\rvec x_\text{o}$ niz opažanih varijabli, a $\rvec x_\text{n}$ niz varijabli \textit{smetnje} (\textit{nuisance}).

Zavisnosti između slučajnih varijabli otežavaju modeliranje i zaključivanje -- potrebno je više podataka i zaključivanje je računski zahtjevnije. Obično možemo pretpostaviti uvjetne zavisnosti između slučajnih varijabli, što se može predstaviti neusmjerenim ili usmjerenim grafom. Prema definiciji na Wikipediji \footnote{\url{https://en.wikipedia.org/wiki/Graphical_model}}, \emph{probabilistički grafički model} ili \emph{grafički model} je probabilistički model koji se može prikazati grafom koji izražava strukturu uvjetnih zavisnosti među slučajnim varijablama. U tom grafu čvorovi označavaju slučajne varijable, a bridovi zavisnosti. Umjereni bridovi označavaju modeliranje uvjetne zavisnosti, a neusmjereni združeno modeliranje. Ako je graf grafičkog modela usmjeren i acikličan, on se naziva \emph{Bayesova mreža} ili \emph{Bayesovski model}, a ako je neusmjeren, naziva se \emph{Markovljeva mreža} ili \emph{Markovljevo slučajno polje} (engl. \textit{Markov random field}, \textit{MRF}). U nastavku ovog odjeljka naglasak će biti na Bayesovim mrežama.

Združena razdioba se prema pravilu umnoška (jednadžba~\ref{eq:pravilo-umnoska}) može npr. ovako izraziti:
\begin{align}
\p(x_1,..,x_n) 
&= \p(x_1)\p(x_2\mid x_1)\cdots\p(x_n\mid x_1,..,x_{n-1}) \\
&= \prod_i\p(x_i\mid x_1,\bidot,x_{i-1}) \text{.}
\label{eq:pgm-pravilo-umnoska}
\end{align} 
Prema tome, svaki probabilistički grafički model ima ekvivalentnu Bayesovu mrežu. Ako uzmemo $n=4$, graf koji odgovara faktorizaciji u jednadžbi~\eqref{eq:pgm-pravilo-umnoska} prikazan je na slici~\ref{fig:bayesova-mreza}.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\node[node] (x1) [] {$\rvar x_1$};
	\node[node] (x2) [right=of x1] {$\rvar x_2$};
	\node[node] (x3) [above=of x2] {$\rvar x_3$};
	\node[node] (x4) [above=of x1] {$\rvar x_4$};
	\path (x1) edge [dagconn] (x2);	
	\path (x1) edge [dagconn] (x3);	
	\path (x1) edge [dagconn] (x4);
	\path (x2) edge [dagconn] (x3);	
	\path (x2) edge [dagconn] (x4);
	\path (x3) edge [dagconn] (x4);	
	\end{tikzpicture}
	\caption{Prikaz grafičkog modela s faktorizacijom $\p(x_1,x_2,x_3,x_4)=\p(x_1)\p(x_2\mid x_1)\p(x_3\mid x_1,x_2)\p(x_4\mid x_1,x_2,x_3)$.}
	\label{fig:bayesova-mreza}
\end{figure}

Pretpostavljanjem uvjetnih nezavisnosti, neki bridovi grafa $G$ se mogu ukloniti pa za varijable (čvorove grafa) vrijedi \emph{uređajno Markovljevo svojstvo}:
\begin{align}
\rvar x\perp \pred_G(\rvar x) \setminus \pa_G(\rvar x) \mid \pa_G(\rvar x).
\end{align}
Jednadžba~\eqref{eq:pgm-pravilo-umnoska} onda prelazi u 
\begin{align}
\p(x_1,..,x_n) 
= \prod_i\p\del{x_i \midmid \bigcap_{\rvar x_j\in\pa_G(\rvar x_i)}\cbr{\rvar x_j=x_j}} \text{.}
\label{eq:pgm-pravilo-umnoska}
\end{align} 
To omogućuje primjenu efikasnijih algoritama za zaključivanje \citep{Murphy:2012:MLPP}.
Na slici~\ref{fig:bm-kanonski} prikazani su osnovni slučajevi odnosa između triju slučajnih varijabli povezanih zavisnostima koje mogu biti dio većeg grafa. Oni su detaljnije objašnjeni npr. u \citet{Bishop:2006:PRML} i \citet{Alpaydin:2014:IML}. 

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\node[node] (x) [] {$\rvar x$};
		\node[node] (y) [below left=of x] {$\rvar y$};
		\node[node] (z) [below right=of x] {$\rvar z$};
		\path (x) edge [dagconn] (y);	
		\path (x) edge [dagconn] (z);
		\path (y) edge [dagconn] (z);
		\end{tikzpicture}
		\caption{Grafički model s faktorizacijom $\p(x,y,z) = \p(x)\p(y\mid x)\p(z\mid x,y)$.}
		\label{subfig:bm-kanonski-a}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\node[node] (x) [] {$\rvar x$};
		\node[node] (y) [right=of x] {$\rvar y$};
		\node[node] (z) [right=of y] {$\rvar z$};
		\path (x) edge [dagconn] (y);	
		\path (y) edge [dagconn] (z);
		\end{tikzpicture}
		\caption{Uz $\rvar x\perp\rvar z\mid\rvar y$ faktorizacija postaje $\p(x,y,z) = \p(x)\p(y\mid x)\p(z\mid y)$ (lanac).}
		\label{subfig:bm-kanonski-head-to-tail}
	\end{subfigure}
	\vskip\baselineskip
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\node[node] (x) [] {$\rvar x$};
		\node[node] (y) [below left=of x] {$\rvar y$};
		\node[node] (z) [below right=of x] {$\rvar z$};
		\path (x) edge [dagconn] (y);	
		\path (x) edge [dagconn] (z);
		\end{tikzpicture}
		\caption{Uz $\rvar y\perp\rvar z\mid\rvar x$ faktorizacija postaje $\p(x,y,z) = \p(x)\p(y\mid x)\p(z\mid x)$ (račvanje).}
		\label{subfig:bm-kanonski-tail-to-tail}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\node[node] (z) [] {$\rvar z$};
		\node[node] (x) [above left=of z] {$\rvar x$};
		\node[node] (y) [above right=of z] {$\rvar y$};
		\path (x) edge [dagconn] (z);	
		\path (y) edge [dagconn] (z);
		\end{tikzpicture}
		\caption{Uz $\rvar x\perp\rvar y$ faktorizacija postaje $\p(x,y,z) = \p(x)\p(y)\p(z\mid x,y)$ (sraz). Ovdje također vrijedi $\rvar x\not\perp\rvar y\mid \rvar z$.}
		\label{subfig:bm-kanonski-head-to-head}
	\end{subfigure}
	\caption{Osnovni slučajevi uvjetne nezavisnosti. Slike \subref{subfig:bm-kanonski-head-to-tail}, \subref{subfig:bm-kanonski-tail-to-tail} i \subref{subfig:bm-kanonski-head-to-head} prikazuju grafove dobivene uvođenjem pretpostavki uvjetne nezavisnosti za grafički model s 3 slučajne varijable prikazan na slici \subref{subfig:bm-kanonski-a}.}
	\label{fig:bm-kanonski}
\end{figure}

Na slici~\ref{fig:bm-regresija} prikazan je primjer na kojemu se koriste još neke oznake: sivi čvorovi označavaju opažane varijable, četverokut označava veći broj podgrafova s istom strukturom.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\node[node] (t) [] {$\rvec \theta$};
	\node[textnode] (a) [right=of t] {$\alpha$};
	\node[node] (e) [below=of t] {$\rvar\epsilon$};
	\node[greynode] (yi) [left=of t] {$\rvar y_i$};
	\node[greynode] (xi) [left=of yi] {$\rvec x_i$};
	\node[node] (y) [left=of e] {$\rvar y$};	
	\node[greynode] (x) [left=of y] {$\rvec x$};
	\path (a) edge [dagconn] (t);	
	\path (t) edge [dagconn] (yi);	
	\path (t) edge [dagconn] (y);
	\path (e) edge [dagconn] (yi);	
	\path (e) edge [dagconn] (y);
	\path (xi) edge [dagconn] (yi);
	\path (x) edge [dagconn] (y);
	\plate{}{(xi)(yi)}{$i \in \cbr{1\bidot N}$};
	\end{tikzpicture}
	\caption{Primjer grafičkog modela s faktorizacijom 
		$\p(\vec x, y,\vec x_1\bidot\vec x_N,y_1\bidot y_N,\vec\theta,\epsilon) 
		= \p(\vec\theta)\p(\epsilon)p_{\rvec x}(\vec x)p_{\rvec y\mid\rvec x,\rvec\theta,\rvar\epsilon}(y\mid\vec x,\vec\theta,\epsilon) \prod_i\del{p_{\rvec x}(\vec x_i)p_{\rvec y\mid\rvec x,\rvec\theta,\rvar\epsilon}(y_i\mid\vec x_i,\vec\theta,\epsilon)}$. Graf prikazuje model regresije, gdje su $\rvec\theta$ nepoznati parametri, $\rvec x_i$ i $\rvec y_i$ opažani parovi ulaza i izlaza, $\rvec x$ opažani ulaz s nepoznati izlazom, a $\rvar\epsilon$ homoskedastički šum, tj. šum koji ne ovisi o ulazu. Na slici je još eksplicitno prikazana deterministička varijabla $\alpha$ koja je parametar razdiobe $\p(\rvec\theta)=\p(\rvec\theta\mid\alpha)$. Slika je napravljena po uzoru na sliku~14.7 u \citet{Alpaydin:2014:IML}.}
	\label{fig:bm-regresija}
\end{figure}

Općenitije, o uvjetnoj nezavisnosti podskupova varijabli govori svojstvo \emph{d-separacije}. Kažemo da je staza (podgraf sa strukturom lanca) $P$ grafa $G$ \emph{d-odvojena} skupom čvorova $\set E$ akko $P$ sadrži barem jedno od sljedećeg \citep{Murphy:2012:MLPP}:
\begin{itemize}
	\item lanac $\rvar a\rightarrow\rvar b\rightarrow\rvar c$, gdje $\rvar b\in E$
	\item račvanje $\rvar a\leftarrow\rvar b\rightarrow\rvar c$, gdje $\rvar b\in E$
	\item sraz $\rvar a\rightarrow\rvar b\leftarrow\rvar c$, gdje $\forall \rvar b'\in\cbr{\rvar b}\cup\succ_G(\rvar b), \rvar b'\notin E$.
\end{itemize}
Kažemo da skup čvorova $\set E$ d-odvaja čvorove $\rvar x$ i $\rvar y$ akko su sve staze između njih d-odvojene. Vrijedi $\rvar x\perp\rvar y \mid \set E$ akko skup čvorova $\set E$ d-odvaja čvorove $\rvar x$ i $\rvar y$. To se može poopćiti na skupove čvorova. Skup čvorova opažanjem kojega neki čvor postaje neovisan o ostatku grafa naziva se \emph{Markoveljev pokrivač} (engl. \textit{Markov blanket}). Markovljev pokrivač čvora $\rvar x$ je
\begin{align}
\pa_G(\rvar x)\cup\ch_G(\rvar x)\cup\bigcup_{\rvar y\in\ch_G(\rvar x)}\pa_G(\rvar y)
\end{align}

U navedenim knjigama opisani su algoritmi koji se koriste za efikasno zaključivanje iskorištavanjem strukture grafa.


\section{Procjena parametara i zaključivanje}

\subsection{Procjenitelji i točkaste procjene parametara}

Ovaj pododjeljak se temelji na \citet{Elezovic:2007:VSSV}.

Neka je $\rvar x$ slučajna varijabla i $\p(\rvar x)$ njena razdioba s nama nepoznatim parametrom $\theta$. Taj parametar možemo procijeniti na temelju opaženih vrijednosti $x_1,..,x_n$ slučajne varijable $\rvar x$, za što definiramo funkciju $g$ koja daje procjenu parametara
\begin{align}
\hat{\theta}=f(x_1,..,x_N) \text{.}
\end{align}
Ako kao parametre takve funkcije uzmemo \emph{uzorak}, tj. skup slučajnih varijabli $\rset D=\del{\rvar x_1,..,\rvar x_N}$, gdje pretpostavljamo da su $\rvar x_1,..,\rvar x_N$ međusobno nezavisne i imaju istu razdiobu kao $\rvar x$, dobivamo slučajnu varijablu
\begin{align}
\hat{\rvar\theta}=f(\rset D) \text{.}
\end{align}
Takva slučajna varijabla naziva se \emph{statistika}. Ako je $\theta$ nepoznati parametar razdiobe $\p(\rvar x)$, onda kažemo da je ta statistika $\hat{\rvar\theta}$ \emph{procjenitelj} parametra $\theta$, a njen ishod $\hat{\theta}$ \emph{procjena} parametra $\theta$.

\subsection{Svojstva i pogreška procjenitelja}

\emph{Pristranost} procjenitelja $\hat{\rvar\theta}$ je definirana izrazom $\E\hat{\rvar\theta} - \theta$, gdje je $\theta$ stvarna vrijednost parametra koji se procjenjuje. Ona mjeri koliko procjenitelj griješi neovisno o ishodu uzorka. Kažemo da je procjenitelj parametra $\theta$ \emph{nepristran} ako vrijedi
\begin{align}
\E\hat{\rvar\theta} = \theta \text{.}
\end{align}

\emph{Varijanca} procjenitelja $\hat{\rvar\theta}$ je definirana izrazom $\D\hat{\rvar\theta}$. Ona mjeri koliko procijenitelj griješi ovisno variranju uzorka. 
%Neka je $\rset D$ uzorak od $n$ slučajnih varijabli. Ako su $\hat{\rvar\theta}_1(\rset D)$ i $\hat{\rvar\theta}_2(\rset D)$ dva nepristrana procjenitelja za $\theta$, kažemo da je $\hat{\rvar\theta}_1$ \emph{bolji} od $\hat{\rvar\theta}_2$ ako
%\begin{align}
%\D \hat{\rvar\theta}_1 < \D\hat{\rvar\theta}_2 \text{.}
%\end{align}
Neka $N$ u oznaci ${\rset D}_N$ označava veličinu uzorka. Nepristrani procjenitelj $\hat{\rvar\theta}$ je \emph{valjan} ako 
\begin{align}
\lim_{N\to\infty} \D\sbr{\hat{\rvar\theta}(\rset D_N)} = 0  \text{.}
\end{align}

Može se pokazati da je očekivanje srednje kvadratne pogreške procjenitelja jednaka zbroju njegove varijance i kvadrata njegove pristranosti \citep{Snajder:2014:SU}, tj. 
\begin{align}
\E\sbr{\del{\hat{\rvar\theta}-\theta}^2} = \D\hat{\rvar\theta} + \del{\E\hat{\rvar\theta}}^2  \text{.}
\end{align}

\subsection{Procjenitelj maksimalne izglednosti}

\emph{Procjenitelj maksimalne izglednosti} (\emph{ML-procjenitelj}, engl. \textit{maximum likelihood}) uzorku dodjeljuje parametre maksimiziraju vjerojatnost uzorka, tj. imaju najveću \emph{izglednost}:
\begin{align}
\rvec\theta_\text{ML} = \argmax_{\vec\theta} \p(\rset{D}\mid\vec\theta) \text{.}
\end{align}
Zbog pretpostavke međusobne nezavisnosti primjera vrijedi
\begin{align}
 \p(\set{D}\mid\vec\theta) = \prod_{\vec d\in\set{D}} \p(\vec d\mid\vec\theta) \text{.}
\end{align}

Za razliku od generativnih, diskriminativni modeli ne modeliraju razdiobu ulaznih primjera, nego samo uvjetnu razdiobu $\p(\vec y\mid \vec x, \set{D})$ pa kod njih razdioba ulaznih primjera ne ovisi o $\vec\theta$, tj. $\p(\vec x\mid\vec\theta) = \p(\vec x)$. Onda je izglednost
\begin{align}\label{eq:izglednost-diskr}
\p(\set{D}\mid\vec\theta) 
= \prod_{(\vec x,\vec y)\in\set{D}} \p(\vec y\mid\vec x,\vec\theta)\p(\vec x\mid\vec\theta) 
= \p(\vec x) \prod_{(\vec x,\vec y)\in\set{D}} \p(\vec y\mid\vec x,\vec\theta) \text{.}
\end{align}
Faktor $\p(\vec x)$ ne ovisi o parametrima i može se zanemariti pri optimizaciji.

\subsection{Procjenitelj maksimalne aposteriorne vjerojatnosti}

\emph{Procjenitelj maksimalne aposteriorne vjerojatnosti} (\emph{MAP-procjenitelj}, engl. \textit{maximum a posteriori estimator}) u obzir uzima \emph{apriornu razdiobu} $\p(\rvec\theta)$ koja predstavlja dodatne pretpostavke za razdiobu parametara. Apriorna razdioba parametara pojednostavljuje model dajući prednost nekim hipotezama i posebno je korisna kada ima malo podataka. Apriorna razdioba može biti definirana nekim hiperparametrima ali oni ovdje nisu prikazani. Po Bayesovom pravilu, \emph{aposteriorna vjerojatnost} parametara je
\begin{equation} \label{eq:posterior-bayes}
\p(\vec\theta\mid\set D) 
 = \frac{\p(\set{D}\mid\vec\theta)\p(\vec\theta)}{\p(\set{D})}
 = \frac{\p(\set{D}\mid\vec\theta)\p(\vec\theta)}{\int \p(\set{D}\mid\vec\theta')\p(\vec\theta')\dif\vec\theta'} \text{.}
\end{equation}
Maksimizacijom aposteriorne vjerojatnosti dobivaju se parametri
\begin{equation}
 \rvec\theta_\text{MAP} = \argmax_{\vec\theta} \p(\vec\theta\mid\rset D) = \argmax_{\vec\theta} \p(\rset{D}\mid\vec\theta)\p(\vec\theta) \text{.}
\end{equation}
Ovdje nije potrebno normalizirati aposteriornu vjerojatnost izračunavanjem \emph{marginalne izglednosti} (engl. \textit{marginal likelihood}, \textit{evidence}) $\p(\set{D})$ u nazivniku na desnoj strani jednadžbe~\eqref{eq:posterior-bayes} jer ona ne ovisi $\vec\theta$, nego samo o modelu $\set H$. Odabirom uniformne (neinformativne) apriorne razdiobe MAP-procjenitelj postaje ekvivalentan ML-procjenitelju.

Poželjno je da $\p(\set{D}\mid\vec\theta)$ i $\p(\vec\theta)$ kao funkcije parametra $\vec\theta$ imaju takav algebarski oblik da njihov umnožak ima sličan oblik i može se analitički izračunati. Ako $\p(\rvec\theta)$ i $\p(\rvec\theta\mid\set D)$ imaju isti algebarski oblik definiran nekim parametrima, nazivaju se \emph{konjugatne razdiobe} \citep{Snajder:2014:SU}.
% TODO ^^

\subsection{Bayesovski procjenitelj i zaključivanje}

Prethodno opisani procjenitelji daju točkastu procjenu parametara i ne izražavaju nesigurnost procjene kojoj uzrok može biti npr. nedovoljna količina podataka ili šum u podacima za učenje. \emph{bayesovski procjenitelj} kao procjenu daje razdiobu nad hipotezama $\p(\rvec\theta\mid\set D)$ za koju je integriranjem po svim mogućim parametrima potrebno izračunati marginalnu izglednost $\p(\set{D})=\int\p(\set{D}\mid\vec\theta')\p(\vec\theta')\dif{\vec\theta'}$ iz nazivnika na desnoj strani jednadžbe~\eqref{eq:posterior-inference}. 

Kod složenijih modela često ne možemo odabrati konjugatnu apriornu razdiobu, a i funkcija izglednosti je sama po sebi već dovoljno složena da se, neovisno o apriornoj razdiobi, marginalna izglednost $\p(\set{D})$ ne može ni analitički ni numerički traktabilno računati. 

Vjerojatnost nekog primjera $\vec d$ procjenjuje se marginalizacijom po parametrima \citep{Neal:1995:BLNN}:
\begin{align}
\p(\vec d\mid\set D) 
= \int\p(\vec d\mid\vec\theta)\p(\vec\theta\mid\set D) \dif{\vec\theta}
= \E_{\rvec\theta\mid\set D}\p(\vec d\mid\rvec\theta) \text{,}
\end{align}
gdje je korištena uvjetna nezavisnost $\rvec d\perp\rset D\mid\rvec\theta$.

Kada se parametri točkasto procjenjuju, npr. MAP-procjeniteljem, točkasta procjena parametara $\hat{\vec\theta}$ aproksimira cijelu aposteriornu razdiobu, tj. $\p(\vec\theta\mid\set{D}) \approx \dirac(\hat{\vec\theta}-\vec\theta)$. Onda je
\begin{align}
\p(\vec d\mid\set D) 
\approx \int\p(\vec d\mid\vec\theta) \dirac(\hat{\vec\theta}-\vec\theta) \dif{\vec\theta} 
=\p(\vec d\mid\hat{\vec\theta}) \text{.}
\end{align}
%TODO: treba li d biti slučajna varijabla?

Za diskriminativne modele se bayesovsko zaključivanje može izraziti ovako:
\begin{align*}
\p(\vec y\mid \vec x, \set{D})
&= \frac{\p(\vec x,\vec y\mid\set{D})}{\p(\vec x\mid\set{D})} \\
&= \frac{\int\p(\vec y\mid \vec x,\vec\theta)\p(\vec x\mid\vec\theta) \p(\vec\theta\mid\set D) \dif{\vec\theta}}{\int\p(\vec x\mid\vec\theta)\p(\vec\theta\mid\set D)\dif{\vec\theta}} \\
&= \frac{\p(\vec x)\int\p(\vec y\mid \vec x,\vec\theta)\p(\vec\theta\mid\set D) \dif{\vec\theta}}{\p(\vec x)\int\p(\vec\theta\mid\set D)\dif{\vec\theta}} \text{.}
\end{align*}
Poništavanjem $\p(\vec x)$ i integriranjem nazivnika dobiva se
\begin{align}
\p(\vec y\mid \vec x, \set{D})
= \int\p(\vec y\mid \vec x,\vec\theta)\p(\vec\theta\mid\set D) \dif{\vec\theta}
= \E_{\rvec\theta\mid\set D}\p(\vec y\mid\vec x,\rvec\theta) \text{.}
\end{align}
%TODO: trebaju li x i y biti slučajna varijabla ili obične?

Kod regresije je često, ako pretpostavljamo da pogreška izlaza ima Gaussovu razdiobu, najbolja procjena hipoteze očekivanje po naučenoj razdiobi parametara \citep{Neal:1995:BLNN}: 
\begin{align}
h(\vec x)
= \E_{\rvec\theta\mid\set D} h(\vec x; \rvec\theta)
= \int h(\vec x; \vec\theta)\p(\vec\theta\mid\set D) \dif{\vec\theta} \text{.}
\end{align}
U tom slučaju se nesigurnost može izraziti disperzijom
 $\D_{\rvec\theta\mid\set D} h(\vec x; \rvec\theta)$.

 
\section{Monte Carlo aproksimacija}

Ovaj odjeljak se temelji na \citet{Goodfellow:2016:DL}.

\emph{Monte Carlo aproksimacija} je postupak procjenjivanja vrijednosti koje se mogu izraziti kao očekivanje neke funkcije neke slučajne varijable na temelju uzoraka. Ponekad nije moguće analitički ili numerički traktabilno ili efikasno izračunati neki integral (ili zbroj). Ako se on može ovako izraziti:
\begin{align}
s = \int\p(x)f(x)\dif x = \E f(\rvar x) \text{,}
\end{align}
može se procijeniti uzorkovanjem:
\begin{align}
\hat{\rvar s}_n = \frac{1}{n}\sum_{i=1}^n f(\rvar x_i) \text{.}
\end{align}
Procjenitelj $\hat{\rvar s}_n$ je nepristran ako su $\rvar x_i$ nezavisne i imaju istu razdiobu kao $\rvar x$ i valjan ako su varijance $f(\rvar x_i)$ ograničene. Vrijedi $\D\hat{\rvar s}_n = \frac{1}{n} \D f(\rvar x)$.

U širem smislu, postupci \textit{Monte Carlo} obuhvaćaju i generiranje uzoraka slučajne varijable čije se očekivanje procjenjuje.


\section{Aproksimacija razdioba i aproksimacijsko zaključivanje}

Ovaj odjeljak se uglavnom temelji na \citet{Blei:2017:VIRS} i malo na \citet{Yang:2017:UVLB}.

Važan problem u bayesovskoj statistici, gdje se zaključivanje temelji na izračunima koji uključuju aposteriornu razdiobu, je aproksimacija razdioba koje su zahtjevne za računanje. Kod složenijih Bayesovskih modela aposteriorna razdioba se ne može lako izračunati i treba koristiti aproksimacijske postupke od kojih su glavni \emph{varijacijski} postupci \citep{Jordan:1999:IVMGM} i postupci \emph{Monte Carlo} aproksimacije s uzorkovanjem pomoću \emph{Markovljevog lanca} (MCMC, engl. \textit{Markov chain Monte Carlo}). MCMC-postupci temelje se na definiranju stohastičkog procesa koji ima stacionarnu razdiobu jednaku razdiobi koja se aproksimira, omogućuju asimptotski egzaktno uzorkovanje velike klase razdioba. Varijacijski postupci temelje se na aproksimaciji razdiobe nekom jednostavnijom koja se pronalazi rješavanjem optimizacijskog problema, brži su i jednostavniji za ostvariti za složenije modele.

Razmatramo bayesovski model koji ima latentnu varijablu $\rvec z$ i vidljivu varijablu $\rvec x$. Model je prikazan na slici~\ref{fig:pgmzx} i opisan je ovom jednadžbom združene vjerojatnosti:
\begin{align*}
\p(\vec x, \vec z) = \p(\vec z)\p(\vec x\mid\vec z) \text{.}
\end{align*}
Zaključivanjem se određuje aposteriorna razdioba latentne varijable:
\begin{align} \label{eq:posterior-inference}
\p(\vec z\mid\vec x) = \frac{\p(\vec x,\vec z)}{\p(\vec x)} = \frac{\p(\vec x,\vec z)}{\int\p(\vec x, \vec z) \dif{\vec z}} \text{.}
\end{align}
na temelju opažanih vrijednosti slučajne varijable $\rvec x$ (podataka). Kod složenijih modela integriranje marginalne izglednosti u nazivniku nije traktabilno i aposteriorna razdioba se mora aproksimirati \emph{približnim (aproksimacijskim) zaključivanjem}.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\node[node] (z) [] {$\rvec z$};
	\node[greynode] (x) [right=of z] {$\rvec x$};
	\path (z) edge [dagconn] (x);
	\end{tikzpicture}
	\caption{Prikaz grafičkog modela sa skrivenom varijablom $\rvec z$ i opažanom varijablom $\rvec x$.}
	\label{fig:pgmzx}
\end{figure}



\section{Postupci uzorkovanja}

%TODO 
TODO

1.3.1 \citet{Neal:1995:BLNN}.


\section{Varijacijsko zaključivanje}

Za razliku od uzorkovanja kod MCMC-postupaka, osnovna ideja kod varijacijskog zaključivanja je optimizacija. Prvo se odabire familija razdioba $\set{Q}=\cbr{\p(\tilde{\rvec z})}_{\tilde{\rvec z}}=\cbr{q_{\vec\phi}}_{\vec\phi}$ koje su lakše za računanje. Razdiobe iz $\set{Q}$ su parametrizirane tzv. \emph{varijacijskim parametrima} $\vec\phi$. Cilj je na temelju podataka kao zamjenu za aposteriornu razdiobu $\p(\vec z\mid\vec x)$ pronaći razdiobu iz $\set{Q}$ koja ju što bolje aproksimira. To možemo ostvariti minimizacijom Kullback-Leiblerove (KL) divergenciju s obzirom na stvarnu aposteriornu razdiobu po varijacijskim parametrima $\vec\phi$:
\begin{align}
q^* = \argmin_{\p(\tilde{\rvec z})\in\set Q} \Dkl{\tilde{\rvec z}}{(\rvec z\mid\vec x)} \text{.}
\end{align}
Naziv \emph{varijacijsko zaključivanje} dolazi od varijacijskog računa\footnote{\url{https://en.wikipedia.org/wiki/Calculus_of_variations}}, gdje se koriste varijacije, tj. male promjene u funkcijama i funkcionalima, kako bi se pronašli minimumi ili maksimumi funkcionala, preslikavanja iz skupa funkcija u $\R$, koji su često izraženi kao integrali koji uključuju funkcije i njihove derivacije.

Neka je $q$ oznaka funkcije gustoće vjerojatnosti aproksimacijske razdiobe: $q\coloneqq p_{\tilde{\rvec z}}$. Ako ciljnu funkciju ovako izrazimo:
\begin{align}
\Dkl{\tilde{\rvec z}}{(\rvec z\mid\vec x)} 
&= \E_{\tilde{\rvec z}} \ln\frac{q(\tilde{\vec z})}{p_{\rvec z\mid x}(\tilde{\vec z})} \nonumber \\
&= \E_{\tilde{\rvec z}}\ln q(\tilde{\vec z}) - \E_{\tilde{\rvec z}}\ln \p(\rvec z=\tilde{\vec z},\vec x) + \ln\p(\vec x) \text{,} \label{eq:dkl-split}
\end{align}
vidi se da se ona ne može lako izračunati jer zahtijeva računanje marginalne izglednosti $\p(\vec x)$ iz nazivnika u jednadžbi~\eqref{eq:posterior-inference} marginalizacijom po $\rvec z$. Marginalna izglednost ne ovisi o varijacijskim parametrima pa ju možemo zanemariti i maksimiziramo funkciju koja se naziva \emph{varijacijska donja granica} (engl. \textit{variational lower bound}) ili \emph{donja granica (logaritma) marginalne izglednosti} (engl. \textit{(log) evidence lower bound}, \textit{ELBO}):
\begin{align}
L_{\vec x}(\tilde{\rvec z}) 
\coloneqq \ln\p(\vec x) - \Dkl{\tilde{\rvec z}}{(\rvec z\mid\vec x)}
= \E_{\tilde{\rvec z}} \ln \p(\rvec z=\tilde{\vec z},\vec x) - \E_{\tilde{\rvec z}} \ln q(\tilde{\vec z})  \text{.} \label{eq:elbo}
\end{align}
Ona se može i ovako izraziti:
\begin{align}
L_{\vec x}(\tilde{\rvec z}) 
= \E_{\tilde{\rvec z}} \ln\p(\vec x\mid\rvec z=\tilde{\vec z}) - \Dkl{\tilde{\rvec z}}{\rvec z}  \text{.}
\end{align}
Maksimiziranje takve ciljne funkcije s obzirom na varijacijske parametre daje razdiobu $q^*=\p(\tilde{\rvec z}^*)$ koja dobro objašnjava podatke jer se potiče veće očekivanje logaritma izglednosti (prvi član), a ne razlikuje se previše od apriorne razdiobe jer se potiče manja KL-divergencija između varijacijske razdiobe i apriorne razdiobe \citep{Gal:2015:DBAA}.

Naziv \textit{donja granica marginalne izglednosti} dolazi od toga što su \citet{Jordan:1999:IVMGM} izveli nejednakost $\ln\p(\vec x) \geq L_{\vec x}(\tilde{\rvec z})$ preko Jensenove nejednakosti. Ta nejednakost slijedi i iz prethodne jednadžbe i nenegativnosti KL-divergencije:
\begin{align}
\ln\p(\vec x) = L_{\vec x}(\tilde{\rvec z}) + \Dkl{\tilde{\rvec z}}{(\rvec z\mid\rvec x)} \geq L_{\vec x}(\tilde{\rvec z}) \text{.}
\end{align}

\subsection{Metoda polja sredina}

Dodatno pojednostavljenje koje pomaže u modeliranju i optimizaciji je pretpostavljanje nezavisnosti između latentnih varijabli. Onda za varijacijsku razdiobu vrijedi ovakva faktorizacija:
\begin{align}
q(\tilde{\vec z}) = \prod_i q_i(\tilde{z}_i),
\end{align}
gdje su $q_i$ funkcije gustoće pojedinih slučajnih varijabli, a $\tilde{z}_i=\tilde{\vec z}_{[i]}$. Kod \emph{metode polja sredina} pretpostalja se takva razdioba i obično se primjenjuje koordinatni spust za optimizaciju, s čime ima veze ime metode. To je detaljnije objašnjeno u \citet{Murphy:2012:MLPP}.

\iffalse
Neka je radi kraćeg zapisa $t(\tilde{\vec z}) \coloneqq \p(\rvec z=\tilde{\vec z},\rvec x=\vec x)$. Uz aproksimaciju polja sredina donja varijacijska granica postaje
\begin{align}
L_{\vec x}(\tilde{\rvec z}) 
&= \E_{\tilde{\rvec z}}\sbr{\ln t(\tilde{\vec z}) - \ln q(\tilde{\vec z})}
\\
&= \int\dif{\tilde{\vec z}} \del{\prod_i q_i(\tilde{z}_i)}\del{\ln t(\tilde{\vec z}) - \sum_j \ln q_j(\tilde{z}_j)}
\text{.}
\end{align}
\fi



\chapter{Nadzirano strojno učenje} \label{chap:nsu}

Ovo poglavlje se uglavnom temelji na \citet{Snajder:2014:SU} i \citet{Goodfellow:2016:DL}.

Zadatak algoritama \emph{nadziranog učenja} je preslikavanje \emph{ulaznih primjera} $\vec x$ iz \emph{ulaznog prostora} $\set{X}$ u \emph{izlaze} (\emph{oznake}) $\vec y\in\set{Y}$ na temelju konačnog skupa označenih primjera $\set{D} = \cbr{\del{\vec x_i,\vec y_i}}_{i}$. Algoritmima strojnog učenja pretražuje se \emph{model} ili \emph{prostor hipoteza} u cilju pronalaska \emph{hipoteze} koja osim primjera iz skupa za učenje, u izlaze dobro preslikava i primjere koji nisu u skupu za učenje. Sposobnost postizanja dobre performanse na neviđenim primjerima naziva se \emph{generalizacija}.

Neka je $\set{D}=\cbr{\vec d_i}_i$ skup nezavisnih primjera izvučenih iz neke razdiobe $\distrib{D}$. Možemo definirati \emph{probabilistički model} $\set H$ s nepoznatim parametrima $\vec\theta$ kojemu je cilj što bolje modelirati tu razdiobu pronalaskom najbolje hipoteze na temelju podataka: $\p(\vec{d}\mid\set{D},\set H)$. Model koji modelira razdiobu primjera nazivamo \emph{generativnim modelom}. U nastavku ćemo izostavljati oznaku modela radi kraćeg zapisa.

Ako su primjeri parovi $\vec d_i = \del{\vec x_i, \vec y_i} \in \set{X}\times\set{Y}$, može nam biti cilj ulaznim primjerima iz $\set{X}$ dodjeljivati oznake iz $\set Y$. Ako je problem koji rješavamo dodjeljivanje oznaka ulaznim primjerima, onda su često prikladniji \emph{diskriminativni modeli}. Probabilistički diskriminativni modeli izravno modeliraju uvjetne razdiobe $\p(\rvec y\mid \vec x)$ hipotezom koja ulazni primjer $\vec x$ preslikava u razdiobu $\p(\rvec y\mid\vec x,\set{D})$. Neprobabilistički diskriminativni modeli modeliraju funkciju dodjeljivanja oznaka hipotezom $\funcdef{h}{\set{X}}{\set{Y}}$. Modeliranje zajedničke razdiobe $\p(\rvec x,\rvec y)$ obično zahtijeva više računalnih resursa i podataka \citep{Bishop:2006:PRML}.

Modeli se još mogu podijeliti na \emph{parametarske} i \emph{neparametarske}. Kod parametarskih modela broj parametara je unaprijed određen, dok kod neparametarskih on ovisi o podacima za učenje.


\section{Induktivna pristranost}

Uz zadani skup hipoteza koji dopušta model, \emph{algoritam strojnog učenja} traži parametre koji definiraju jednu hipotezu. Učenje hipoteze je loše definiran (engl. \textit{ill-posed}) problem jer skup podataka $\set{D}$ nije dovoljan za jednoznačan odabir hipoteze. Osim dobrog opisivanja podataka za učenje, naučena hipoteza mora dobro generalizirati. Kako bi učenje i generalizacija bili mogući, potreban je skup pretpostavki koji se naziva \emph{induktivna pristranost}. Razlikujemo dvije vrste induktivne pristranosti \citep{Snajder:2014:SU}:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item \emph{pristranost ograničavanjem} ili \emph{pristranost jezika} -- ograničavanje skupa hipoteza koje se mogu prikazati modelom,
	\item \emph{pristranost preferencijom} ili \emph{pristranost pretraživanja} -- dodjeljivanje različitih prednosti različitim hipotezama.
\end{enumerate}
Većina algoritama strojnog učenja kombinira obje vrste induktivne pristranosti. 


\section{Komponente algoritma strojnog učenja}

Prema \citet{Snajder:2014:SU}, kod većine algoritama strojnog učenja možemo razlikovati 3 osnovne komponente, od kojih prva predstavlja pristranost ograničavanjem, a druge dvije obično pristranost preferencijom:
\begin{enumerate}
	\item \emph{Model} ili prostor hipoteza. Model $\set H$ je skup funkcija $h$  parametriziranih parametrima $\vec\theta$: $\set H=\cbr{h(\vec x;\vec{\theta})}_{\vec{\theta}}$.
	\item \emph{Funkcija pogreške} ili ciljna funkcija. Funkcija pogreške $E(\vec{\theta,\set D})$ na temelju parametara modela (hipoteze) i skupa podataka izračunava broj koji izražava procjenu dobrote hipoteze. Obično pretpostavljamo da su primjeri iz skupa za učenje nezavisni i definiramo \emph{funkcija gubitka} $\funcdef{L}{\set Y\times\set Y}{\R}$, kojoj je prvi parametar predikcija hipoteze, a drugi ciljna oznaka koja odgovara ulaznom primjeru. Funkciju pogreške možemo definirati kao prosječni gubitak na skupu za učenje:
	\begin{align}
	E(\vec{\theta,\set D})=\frac{1}{\envert{\set D}}\sum_{(\vec x,\vec y)\in\set D} L(h(\vec x;\vec{\theta}),\vec y) \text{.}
	\end{align}
	Obično joj dodajemo \emph{regularizacijski} član kojim unosimo dodatne pretpostavke radi postizanja bolje generalizacije. Više o funkciji pogreške u smislu smanjivanja empirijskog i strukturnog rizika piše u odjeljku~\ref{sec:minimizacija-rizika}.
	\item \emph{Optimizacijski postupak}. Optimizacijski postupak je algoritam kojim pronalazimo hipotezu koja minimizira pogrešku:
	\begin{align}
	\vec\theta^* = \argmin_{\vec{\theta}} E(\vec{\theta,\set D}) \text{.}
	\end{align}
	Kod nekih jednostavnijih modela minimum možemo odrediti analitički. Inače moramo koristiti neki iterativni optimizacijski postupak. Kod nekih složenijih modela, kao što su neuronske mreže, funkcija pogreške nije unimodalna i vjerojatnost pronalaska globalnog optimuma je zanemariva, ali ipak se mogu pronaći dobra rješenja.
\end{enumerate}

U literaturi riječ \textit{model} često ima šire značenje. Uz skup hipoteza obično obuhvaća i induktivnu pristranost ili dio nje. Model u tom smislu bi se formalno mogao definirati kao par $(\set H, B)$, gdje je $\set H$ skup mogućih hipoteza, a $B$ induktivna pristranost koja hipotezama dodjeljuje različite važnosti. Ovdje će se u nastavku koristiti takvo značenje riječi \textit{model}, a riječ \textit{prostor hipoteza} će se koristiti sa značenjem modela u užem smislu.


\section{Kapacitet modela, podnaučenost i prenaučenost}

Cilj algoritama strojnog učenja je postići malu \emph{pogrešku generalizacije}, tj. malo očekivanje pogreške na primjera koji nisu korišteni za učenje i odabir modela. Generalizacijska pogreška se procjenjuje pogreškom na \emph{skupu za testiranje}. Obično pretpostavljamo da su skupovi primjera koje koristimo za učenje, odabir modela i testiranje generirani međusobno nezavisno i iz iste razdiobe.

\emph{Kapacitet} ili složenost modela je svojstvo koje opisuje njegovu sposobnost prilagodbe podacima. Model koji se previše prilagođava podacima za učenje (i statističkom šumu u njima) obično ima slabu prediktivnu moć. Treba odabrati model (ili hipotezu) koji dobro objašnjava podatke, ali nije previše složen. O tome govori i načelo \emph{Occamove oštrice} prema kojemu među hipotezama konzistentnima s opažanjem treba odbaciti sve osim najjednostavnije od njih. Postoje formalizacije Occamove oštrice \citep{Blumer:1987:OR,Blumer:1989:LVCD,Gruenwald:2005:TIMDL,Ratmanner:2011:PTUI}. Na ograničavanje složenosti modela možemo utjecati ograničavanjem prostora hipoteza i regularizacijom (\textit{mekim} ograničavanjem).

Model s većim kapacitetom (složeniji model) može postići manju pogrešku na skupu za učenje. Prevelik kapacitet povećava pogrešku generalizacije. Za model koji daje veliku pogrešku generalizacije kažemo da je \emph{prenaučen}. Kod takvog modela hipoteze će jako varirati u ovisnosti o skupu za učenje i zato kažemo da složeni modeli imaju visoku varijancu. Model premalog kapaciteta (prejednostavan model) ima manju razliku između pogreške na skupu za učenje i pogreške na skupu za testiranje, ali su obje pogreške veće od optimalnih. Za model koji ne postiže malu pogrešku na skupu za učenje kažemo da je \emph{podnaučen}. U jednostavan model ugrađene su jače pretpostavke i kažemo da on ima jaču pristranost. Uobičajena ovisnost pogrešaka na skupovima za učenje i testiranje o kapacitetu ilustrirana je slikom~\ref{fig:generalizacija}.

\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{generalizacija}
	\caption{Ovisnost pogrešaka na skupovima za učenje i testiranje o kapacitetu modela. Povećavanjem kapaciteta povećava se razlika između pogrške ne skupu za testiranje i pogreške na skupu za učenje.}
	\label{fig:generalizacija}
\end{figure}


\section{Odabir modela}
TODO
%https://en.wikipedia.org/wiki/Variational_Bayesian_methods

%MLPP 5.3 Bayesian model selection

\citet{Murray:2005:NEBOR} MacKay % MLPP! 5.3.1 Bayesian Occam’s razor


\section{Minimizacija rizika} \label{sec:minimizacija-rizika}

Dijelovi ovog odjeljka temelje se na \citep{Murphy:2012:MLPP}.

\subsection{Rizik i empirijski rizik}

Zadatak nadziranog strojnog učenja može se formulirati kao optimizacijski problem minimizacije \emph{rizika}. Neka su $\vec\theta$ odabrani parametri. Definiramo \emph{funkciju gubitka} $\funcdef{L}{\set{Y}\times\set{Y}}{\R}$ koja kažnjava neslaganje izlaza sa stvarnom oznakom. \emph{Rizik} definiramo kao očekivanje funkcije gubitka:
\begin{align}
R(\vec\theta, \mathcal{D}) = \E_{(\vec x,\vec y)\sim\mathcal{D}} L(h(\vec x;\vec\theta), \vec y) \text{.}
\end{align}
Razdioba koja generira podatke nije poznata pa se koristi \emph{empirijski rizik} koji prirodnu razdiobu $\mathcal{D}$ procjenjuje empirijskom, tj. uzorkom $\set{D}$:
\begin{align}
R_\text{E}(\vec\theta;\set{D}) 
= \E_{(\vec x,\vec y)\sim\set D} L(h(\vec x;\vec\theta), \vec y) 
= \frac{1}{\envert{\set{D}}} 
\sum_{(\vec x, \vec y)\in\set{D}} L(h(\vec x;\vec\theta), \vec y) \text{.}
\end{align}
U slučaju nenadziranog učenja, kada se hipoteza sastoji od kodera $E$ i dekodera $D$, tj. $h(\vec x;\theta) = E(D(\vec x;\theta);\theta)$, ili generativnog modela, kada je $h(\vec x;\theta) = \p(\vec x\mid\theta)$, gubitak mjeri \emph{pogrešku rekonstrukcije} i izraz za rizik je \citep{Murphy:2012:MLPP}:
\begin{align}
R(\rvec\theta;\mathcal{D}) = \E_{\vec d\sim\mathcal{D}} L(h(\vec d;\vec\theta), \vec d) \text{.}
\end{align}

Kod probabilističkih modela empirijski rizik se može definirati kao negativni logaritam izglednosti parametara:
\begin{align}
R_\text{E}(\vec\theta;\set{D}) = -\ln\p(\set{D}\mid\vec\theta) = -\sum_{\vec d\in\set{D}} \ln\p(\vec d\mid\vec\theta) \text{,}
\end{align}
tj. gubitak je onda $L(h(\vec d;\vec\theta), \vec d) = -\ln\p(\vec d\mid\vec\theta)$. U slučaju diskriminativnog modela, uz zanemarivanja faktora izglednosti koji ne ovisi o $\vec\theta$ (jednadžba~\eqref{eq:izglednost-diskr}), vrijedi $L(h(\vec x;\vec\theta), \vec y) = -\ln\p(\vec y\mid\vec x,\vec\theta)$.

\subsection{Strukturni rizik i regularizacija}

Kada ima malo podataka ili je model previše složen, minimizacija empirijskog rizika dovodi do velike varijance i slabe generalizacije. Procjenitelj koji minimizira empirijski rizik ne uzima u obzir apriornu razdiobu parametara. Radi postizanja bolje generalizacije, funkciji pogreške dodaje se \emph{regularizacijski} gubitak $\lambda R_\text{R}(\vec\theta)$, $\lambda\geq0$, koji predstavlja \emph{strukturni rizik} koji daje prednost jednostavnijim hipotezama:
\begin{align}
E(\vec\theta;\set{D}) = R_\text{E}(\vec\theta;\set{D}) + \lambda R_\text{R}(\vec\theta) \text{.}
\end{align}
Regularizacijski gubitak obično ovisi samo o parametrima, ali može ovisiti i o podacima \citep{Goodfellow:2016:DL}.

Kod opisanih modela koji uključuju apriorno znanje, regularizacijskom članu uz $\lambda=1$ odgovara negativni logaritam apriorne vjerojatnosti parametara: $R_\text{R}(\vec\theta) = -\frac{1}{\envert{\set{D}}}\ln\p(\vec\theta)$. $\lambda$ različit od $1$ odgovara izmjeni entropije apriorne razdiobe. Apriorna razdioba postaje $p'(\vec\theta)=p(\vec\theta)^\lambda/Z$, gdje $Z$ ne ovisi o $\vec\theta$ i ne utječe na optimizaciju. S većim $\lambda$ apriorna razdioba postaje koncentriranija i regularizacija jača. Jačom regularizacijom se povećava pristranost i smanjuje varijanca procjenitelja.

%TODO regularizacijski gubitak autoenkodera
%TODO?: MLPP 5.7.1.2 Reject option\\


\section{Osnovni zadaci nadziranog učenja}

Osnovni zadaci nadziranog učenja su \emph{klasifikacija} i \emph{regresija}. Zadatak klasifikacije je svakom ulaznom primjerima dodjeljivati oznake iz konačnog skupa oznaka, npr. $\cbr{1\bidot C}$, gdje svaka oznaka predstavlja jednu \emph{klasu} (\emph{razred}). Zadatak regresije je ulaznim primjerima dodjeljivati vrijednosti iz kontinuiranog skupa (obično $\R$ ili $\R^n$). Ulazni primjeri su obično realni vektori. Klasifikacijska hipoteza se može definirati preko funkcije s kontinuiranom kodomenom. Ako $C=2$, ta funkcija može biti $\funcdef{h}{\set X}{\R}$, a hipoteza $h_\text{c}(\vec x)=\enbbracket{h(\vec x)>0}$. Ako $C>2$, onda to može biti npr. $h_\text{c}(\vec x)=\argmax_i h_i(\vec x)$, gdje $\funcdef{h}{\set X}{\R^C}$ i $h(\vec x)=\sbr{h_i(\vec x)}_{i=1\bidot C}^\tp$. Kod nekih zadataka ulazi ili izlazi imaju složeniju strukturu i ona se može razlikovati između različitih primjera.

%klasifikacija, odnos mF1 i mIoU
%https://www.wolframalpha.com/input/?i=z+%3D+2%2F(1%2Fx%2B1%2Fy)+for+x+in+%5B0,1%5D,+y+in+%5B0,1%5D
%https://www.wolframalpha.com/input/?i=z+%3D+1%2F(1%2Fx%2B1%2Fy-1)+for+x+in+%5B0,1%5D,+y+in+%5B0,1%5D
%https://www.wolframalpha.com/input/?i=z+%3D+2%2F(1%2Fx%2B1%2Fy)%2F(1%2F(1%2Fx%2B1%2Fy-1))+for+x+in+%5B0,1%5D,+y+in+%5B0,1%5D
%https://www.wolframalpha.com/input/?i=z+%3D+2%2F(1%2Fx%2B1%2Fy)-(1%2F(1%2Fx%2B1%2Fy-1))+for+x+in+%5B0,1%5D,+y+in+%5B0,1%5D
% IoU i F1 su ekvivalnetne mjera ako se radi mikro usrednjavanje, 
%https://stats.stackexchange.com/questions/273537/f1-dice-score-vs-iou


\section{Primjer klase modela: poopćeni linearni modeli}

Ovaj odjeljak se temelji na \citep{Snajder:2014:SU}.

\emph{Linearni modeli} su modeli kod kojih je hipoteza definirana afinom transformacijom:
\begin{align}
h(\vec x) = h(\vec x;\vec\theta) = \vec w^\tp\vec x + b \text{,}
\end{align}
gdje je $\vec w$ vektor \emph{težina}, $b$ \emph{pomak} (engl \textit{bias}), a $\vec\theta=(\vec w, b)$. Kod linearnih modela je, u slučaju klasifikacije, granica $(n-1)$-dimenzionalna hiperravnina s normalom $\vec w$. Obično se na ulazne primjere primjenjuje neka nelinearna transformacija
\begin{align*}
\phi \colon \R^n &\to \R^m \\
\vec x &\mapsto \sbr{\phi_1(\vec x),\bidot,\phi_m(\vec x)}^\tp
\end{align*}
koja predstavlja preslikavanje ulaznog prostora u \emph{prostor značajki}. Funkcije $\funcdef{\phi_i}{\R^n}{\R}$ nazivaju se \emph{bazne funkcije}. Hipoteza linearnog modela onda ima oblik
\begin{align}
h(\vec x) = \vec w^\tp\phi(\vec x) \text{.}
\end{align}
Ovdje je izostavljen pomak $b$ jer jedan od izlaza transformacije $\phi$ može biti konstanta $1$ koja se množi s jednom težinom iz $\vec w$. 

\emph{Poopćeni linearni modeli} su modeli kod kojih je hipoteza ovako definirana:
\begin{align}
h(\vec x) = f(\vec w^\tp\phi(\vec x)) \text{.}
\end{align}
U odnosu na linearne modele, oni još imaju \emph{prijenosnu} (\emph{aktivacijsku}) funkciju $\funcdef{f}{\R}{\R}$. Ako je $f$ nelinearna, model je nelinearan u parametrima, ali granica klasifikacijskog modela je i dalje hiperravnina.

Slijedi pregled nekih linearnih modela prema \citet{Snajder:2017:SULR2} uz oznake $s=\vec w^\tp\phi(\vec x)$ i $\vec s=\mat W\phi(\vec x)$:
\begin{itemize}
\item Linearna regresija:
\begin{align*}
h(\vec x;\vec w) &= f(s) = s, \\
\p(y\mid\vec x,\vec w) &= \mathcal{N}(h(\vec x),\sigma^2)(y), \\
L(y, h(\vec x)) &= \del{h(\vec x)-y}^2, \\
\nabla_{\vec w}L(y, h(\vec x)) &= \del{h(\vec x)-y}\phi(\vec x),
\end{align*}
gdje $y\in\R$.
\item Logistička regresija:
\begin{align*}
h(\vec x;\vec w) &= f(s) 
= \frac{1}{1+\exp\del{s}} = \P(\rvar y=1\mid\vec x,\vec w), \\
\P(y\mid\vec x,\vec w) &= h(\vec x)^y(1-h(\vec x))^{1-y}, \\
L(y, h(\vec x)) &= -y\ln h(\vec x)^y-(1-y)\ln(1-h(\vec x)), \\
\nabla_{\vec w}L(y, h(\vec x) &= \del{h(\vec x)-y}\phi(\vec x),
\end{align*}
gdje $y\in{0,1}$. 
\item Višeklasna logistička regresija:
\begin{align*}
h(\vec x;\mat W) &= f(\vec s) 
= \frac{1}{\cvec 1^\tp\exp(\vec s)}\exp(\vec s) = \P(\rvar y\mid\vec x,\vec w), \\
\P(y\mid\vec x,\vec w) &= h(\vec x)_{[y]} = \prod_k h_k(\rvec x)^{\vec y_k}, \\
L(y, h(\vec x)) &= -\sum_k y_k\ln h(\vec x)^y, \\
\nabla_{\mat W_{[k,:]}^\tp}L(y, h_k(\vec x)) &= \del{h_k(\vec x)-y_k}\phi(\vec x) \\
\nabla_{\mat W}L(y, h(\vec x)) &= \phi(\vec x)^\tp \del{h(\vec x)-\cvec e_y},
\end{align*}
gdje $y\in{1\bidot C}$, $\vec y=\cvec e_y$, a $\cvec e_k$ predstavlja jednojedinični vektor (vektor kanonske baze), tj. ${\cvec e_k}_{[i]}=\enbbracket{i=k}$.
\end{itemize}
Funkcije gubitka su definirane kao negativni logaritam izglednosti, $L(y, h(\vec x))=-\ln\P(y\mid\vec x,\vec w)$, i konveksne su. Optimalne težine linearne regresije mogu se analitički izračunati, logistička regresija i višeklasna logistička regresija se obično uče gradijentnim spustom, ali mogu se koristiti i optimizacijski postupci drugog reda. 

Razdiobe $\P(\vec y\mid\vec x,\vec w)$ poopćenih linearnih modela spadaju u \emph{eksponencijalnu familiju razdioba}. Može se pokazati da je to jedina familija razdioba za koje postoje konjugatne apriorne razdiobe, što pojednostavljuje računanje aposteriorne razdiobe \citet{Murphy:2012:MLPP}. Opći oblik ekponencijalne familije i detalji o njoj mogu se naći u \citet{Murphy:2012:MLPP}.











\chapter{Duboko učenje i konvolucijske mreže} \label{chap:dukm}

Klasični (plitki) modeli strojnog učenja (npr. poopćeni linearni modeli) oslanjaju se na kvalitetne značajke, tj. funkciju $\phi$ koja transformira ulazne primjere u vektore značajki. Za neke zadatke koji uključuju visokodimenzionalne primjere sa složenom strukturom (npr. slike, tekst i zvuk), ručno konstruiranje transformacije koja bi bila dovoljno dobra nije izvedivo, a jezgrene metode kod kojih se preslikavanje temelji na pretpostavci sličnosti primjera bliskih u ulaznom prostoru ne generaliziraju dobro. Kod \emph{dubokog učenja} \citep{LeCun:2015:DL,Goodfellow:2016:DL} transformacija $\phi$ se uči.

Odabirom 
\begin{align}
\phi(\vec x) 
= \phi(\vec x;\mat \theta^\text{h})
= f(\mat W^\text{h}\vec x + \vec b^\text{h}) \text{,}
\end{align}
gdje je $\mat W_\text{h}$ matrica težina, $\vec b^\text{h}$ vektor pomaka, $\vec\theta^\text{h}=(\mat W,\vec b^\text{h})$ a $f$ prijenosna (aktivacijska) funkcija koja se primjenjuje na svaki element vektora posebno, dobiva se jednostavna unaprijedna \emph{umjetna neuronska mreža} (ovdje će se koristiti kraći nazivi \textit{neuronska mreža} ili \textit{mreža}) s jednim skrivenim slojem. Onda je, ako se to uvrsti u jednadžbu poopćenog linearnog modela,
\begin{align}
h(\vec x; \vec{\theta}) 
= f(\vec w^\tp f(\mat W^\text{h}\vec x + \vec b^\text{h})+b) \text{,}
\end{align}
ili, ako je izlaz vektor,
\begin{align}
h(\vec x; \vec{\theta}) 
= f(\mat W^\text{o} f(\mat W^\text{h}\vec x + \vec b^\text{h})+\vec b^\text{o}) \text{,}
\end{align}
gdje $\vec\theta=(\mat W^\text{h},\vec b^\text{h}, \mat W^\text{h},\vec b^\text{h})$.

\section{Unaprijedne neuronske mreže}


\section{Računski grafovi}


\section{Konvolucijske mreže}


\section{Učenje}

\subsection{Algortiam propagacije pogreške unatrag}

\subsection{Optimizacijski algoritmi} \label{subsec:dukn-u-optimizacijski-algoritmi}

\subsection{Algoritam propagacija pogreške unatrag}

\subsection{Isključivanje neurona - dropout}

\subsection{Normalizacija po grupama}



\chapter{Procjenjivanje nesigurnosti}


\section{Aleatorna i epistemička nesigurnost}

Kod bayesovskih modela nesigurnost zaključivanja izražava se razdiobom po vrijednostima varijable čija vrijednost se procjenjuje, a može se izraziti i entropijom ili varijancom kada je prikladno.

Postoje različiti izvori nesigurnosti \citep{Kennedy:2002:BCCM}, ali nesigurnost općenito možemo podijeliti na dvije vrste: \emph{aleatornu nesigurnost} i \emph{epistemičku nesigurnost} \citep{Kiureghian:2009:AEDM}. Riječ \textit{aleatorna} izvedena je vjerojatno od latinske riječi \textit{aleator} \citep{Gal:2016:UDL} koja znači \textit{kockar}, a riječ \textit{epistemička} izvedena je od grčke riječi \textit{epist\={e}m\={e}} koja znači \textit{znanje}. Aleatorna nesigurnost je nesigurnost koju model ne može smanjiti neovisno o znanju i količini dostupnih podataka. Ona dolazi od nedeterminizma samog procesa koji generira podatke, nedostupnosti dijela informacija ili ograničenja modela. Epistemička nesigurnost je nesigurnost u strukturu i parametre modela \citep{Gal:2016:UDL}. Ona dolazi od neznanja i može se smanjiti uz više podataka.

Granica između aleatorne i epistemičke nesigurnosti ovisi o modelu. Nešto što je kod jednostavnijeg modela aleatorna nesigurnost, kod složenijeg modela može biti epistemičkog karaktera. Ako su neke pojave po prirodi nasumične ili se ne mogu ili ne žele modelu dati informacije koje bi ih mogle objasniti, nesigurnost zaključivanja u vezi tih pojava će, neovisno o ograničenosti modela, biti aleatorna.

\section{Homoskedastička i heteroskedastička nesigurnost}

Aleatorna nesigurnost može biti homoskedastička i heteroskedastička.

TODO: homoskedastička, heteroskedastička nesigurnost

TODO: model uncertainty, predictive uncertainty Gal-thesis 1.2

\the\fontdimen5\font\newline % em
\the\fontdimen6\font\newline % ex
small {\small \the\fontdimen6\font\newline} % ex}
footnotesize {\footnotesize \the\fontdimen6\font\newline} % ex}
\the\textwidth
		
\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{homoscedastic-heteroscedastic-noises}
	\caption{Homoskedastički (lijevo) i heteroskedastički (desno) Gaussov šum.  Crta prikazuje očekivanje $f(x)$, svjetloplava površina standardnu devijaciju šuma $s(x)$, a točke slučajne uzorke. Točke su generirane prema $(\rvar y\mid x) \sim \mathcal{N}(f(x),s(x)^2)$. Na lijevoj slici je $s(x)=1$.}
	\label{fig:homoscedastic-heteroscedastic-noises}
\end{figure}
		
		

\chapter{Bayesovske neuronske mreže}



\chapter{Procjenjivanje nesigurnosti kod konvolucijskih mreža}



\chapter{Eksperimentalni rezultati}


\section{Programska izvedba}


\section{Skupovi podataka}



\chapter{Zaključak}

Zaključak.

\bibliography{literatura}
\bibliographystyle{fer}

\begin{sazetak}
Sažetak na hrvatskom jeziku.

\kljucnerijeci{Ključne riječi, odvojene zarezima.}
\end{sazetak}

% TODO: Navedite naslov na engleskom jeziku.
\engtitle{Title}
\begin{abstract}
Abstract.

\keywords{Keywords.}
\end{abstract}

\end{document}
