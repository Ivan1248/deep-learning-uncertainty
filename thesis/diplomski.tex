\documentclass[utf8, diplomski, lmodern]{fer}

\input{imports/font}

\input{imports/text}
\input{imports/math}
\input{imports/tables}
\input{imports/figures}
\input{imports/diagrams}
\input{imports/misc}

\input{imports/glossary}
\usepackage[toc]{appendix}


\begin{document}

\thesisnumber{1728}
\title{Nadzirani pristupi za procjenu nesigurnosti predikcija dubokih modela}
\author{Ivan Grubišić}
\maketitle

% Ispis stranice s napomenom o umetanju izvornika rada. Uklonite naredbu \izvornik ako želite izbaciti tu stranicu.
\izvornik
\subsection*{Nadzirani pristupi za procjenu nesigurnosti predikcija dubokih modela}

Procjena nesigurnosti predikcija vrlo je važan sastojak mnogih praktičnih primjena konvolucijskih modela računalnog vida. Do tog cilja možemo doći analizom višeznačnosti podataka, nesigurnosti odluke modela te vjerojatnosti da se podatak nalazi u distribuciji skupa za učenje. U ovom radu razmatramo pristupe koji procjenu nesigurnosti predikcija uče nadzirano, primjenom istih podataka na kojima se uči i promatrani model.

U okviru rada, potrebno je proučiti i ukratko opisati postojeće pristupe za procjenu nesigurnosti predikcija. Uhodati postupke procjene nesigurnosti dubokih konvolucijskih modela temeljene na nadziranom učenju. Validirati hiperparametre te prikazati i ocijeniti ostvarene rezultate na problemu semantičke segmentacije. Predložiti pravce budućeg razvoja.
Radu priložiti izvorni i izvršni kod razvijenih postupaka, ispitne slijedove i rezultate, uz potrebna objašnjenja i dokumentaciju. Citirati korištenu literaturu i navesti dobivenu pomoć.


% Dodavanje zahvale ili prazne stranice. Ako ne želite dodati zahvalu, naredbu ostavite radi prazne stranice.
\zahvala{
Zahvaljujem prof. dr. sc. Siniši Šegviću na pomoći, savjetima i prijedlozima tijekom studiranja i pogotovo tijekom rada na diplomskom radu. Zahvaljujem i asistentima Ivanu Kreši, Marinu Oršiću i Petri Bevandić na pomoći. Zahvaljujem svojoj obitelji na podršci.}

\tableofcontents
%\listoffigures
%\listoftables

\newpage

\begingroup
\onehalfspacing
\printunsrtglossary[type=symbols,style=supergroup,title={Oznake}]
\endgroup



\chapter{Uvod}

U mnogim praktičnim primjenama sve složenijih modela strojnog učenja procjena nesigurnosti ima veliku važnost. Osim samog iznosa nesigurnosti, kod nekih zadataka je korisno znati i je li uzrok nesigurnosti višeznačnost podatka ili nedovoljna informiranost koja se može smanjiti uz unošenje više informacija (podataka) u postupak učenja. U ovom radu se razmatraju nadzirani pristupi za procjenu nesigurnosti kod dubokih nadziranih modela za računalni vid. Ti pristupi se mogu podjeliti u dvije skupine. Jednu skupinu čine pristupi koji se temelje na ideji bayesovske procjene parametara modela i omogućuju razlikovanje navedenih uzroka nesigurnosti, a drugu pristupi za prepoznavanje primjera koji su izvan razdiobe skupa za učenje na temelju izlaza uobičajenih klasifikacijskih modela.

U poglavlju~\ref{chap:osnovni-pojmovi} su definirani i kratko objašnjeni neki od osnovnih pojmova u vezi teorije vjerojatnosti, teorije informacije i optimizacije temeljene na gradijentu, na kojima se temelje pojmovi u poglavljima koja slijede. U njemu su definirane i neke oznake, a na početku rada je tablični pregled mnogih oznaka koje se koriste u radu. 
U poglavlju~\ref{chap:statisticko-zakljucivanje} su opisani neki od osnovnih pojmova u vezi statističkog zaključivanja, koje je jako bitno u strojnom učenju.
U poglavlju~\ref{chap:nadzirano-strojno-ucenje} su opisani neki od osnovnih pojmova strojnog učenja, posebno u vezi nadziranog učenja.
U poglavlju~\ref{chap:duboko-ucenje-i-konvolucijske-mreze} su neki od osnovnih pojmova dubokog učenja, posebno u vezi unaprijednih neuronskih mreža i konvolucijskih mreža.
Poglavlje \ref{chap:procjenjivanje-nesigurnosti} se bavi glavnom temom ovog rada --- procjenjivanjem nesigurnosti kod dubokih nadziranih modela. U njemu je opisana podjela nesigurnosti, bayesovske neuronske mreže, mjere za izražavanje nesigurnosti i neki primjeri pristupa za procjenu nesigurnosti ili prepoznavanje nalazi li se podatak u razdiobi skupa za učenje. Neki od tih pristupa \citep{Kendall:2017:WUNBDLCV,Hendrycks:2016:BDMOODE,Liang:2017:PDOODENN} su isprobani za ovaj rad. Rezultati eksperimenata su opisani u poglavlju~\ref{chap:eksperimenti}.

Rad je pisan u \LaTeX-u. Za slike u radu su korišteni TikZ, Matplotlib (i druge biblioteke u Pythonu) i Inkscapes. Za programsku potpouru korišten je programski jezik Python i biblioteke TensorFlow, NumPy, PyTorch, Scikit-image, Scikit-learn, Matplotlib, SciPy i druge. Izvorni kod za sve je u repozitoriju \url{https://github.com/Ivan1248/deep-learning-uncertainty}.


\chapter{Osnovni pojmovi} \label{chap:osnovni-pojmovi}

U ovom poglavlju su definirani i kratko objašnjeni neki od osnovnih pojmova na kojima se temelje pojmovi u poglavljima koja slijede.

\section{Teorija vjerojatnosti}

Jako važan pojam u strojnom učenju je nesigurnost ili neizvjesnost. Ona dolazi od šuma u mjerenju i iz konačnosti skupa podataka \citep{Bishop:2006:PRML}. Teorija vjerojatnosti nam omogućuje modeliranje nesigurnosti i pronalaženje optimalnih zaključaka korištenjem dostupnih informacija.

Postoje dvije glavne interpretacije vjerojatnosti \citep{Murphy:2012:MLPP}. Jedna je \textit{frekventistička} interpretacija, prema kojoj vjerojatnosti predstavljaju učestalosti različitih događaja ako se pokus ponavlja velik broj puta. Druga je \textit{bayesovska} interpretacija, prema kojoj vjerojatnost izražava našu nesigurnost o ishodu pokusa. 
 
Ovo poglavlje daje kratak i matematički ne potpuno precizan pregled nekih od osnovnih pojmova i pravila vezanih uz vjerojatnost. Na strukturu ovog poglavlja imaju utjecaj \citet{Goodfellow:2016:DL,Murphy:2012:MLPP}.

\subsection{Slučajne varijable i razdiobe}

Neizvjesnost neke pojave modeliramo \emphasize{slučajnom varijablom}. Slučajnoj varijabli je dodijeljena \emphasize{razdioba} koja definira skup vrijednosti koje slučajna varijabla može poprimiti i vjerojatnosti ostvarivanja tih vrijednosti. Skup mogućih vrijednosti neke slučajne varijable se još naziva i \emphasize{prostor elementarnih događaja}. \emphasize{Elementarni događaj} je element prostora elementarnih događaja i, ako je $\rvar x$ slučajna varijabla za koju se u nekom eksperimentu opaža vrijednost $x$, taj događaj ima zapis $\cbr{\rvar x = x}$, a njegova vjerojatnost se označava $\P(\cbr{\rvar x = x})$, $\P(\rvar x = x)$ ili $\P(x)$. \emphasize{Događaj} je skup vrijednosti i obično se izražava predikatom nad slučajnom varijablom: $\cbr{R(\rvar x)}=\cbr{x\colon R(x)}$. Ako je $\set X$ prostor elementarnih događaja slučajne varijable $\rvar x$, onda $\P(\rvar x\in \set X)=1$. Funkcija 
\begin{align*}
\fullfunction{P_{\rvar x}}{\set X}{\intcc{0,1}}{x}{\P(\rvar x=x)}
\end{align*}
je \emphasize{funkcija vjerojatnosti} (engl. \textit{probability mass function}, \textit{pmf}).

Razlikujemo diskretne i kontinuirane slučajne varijable. Prostor elementarnih događaja diskretne slučajne varijable je prebrojiv skup. Razdioba kontinuirane slučajne varijable $\rvar x$ koja poprima vrijednosti iz skupa $\set X$ je određena \emphasize{funkcijom gustoće vjerojatnosti} (engl. \textit{probability density function}, \textit{pdf})
\begin{align*}
\fullfunction{p_{\rvar x}}{\set X }{\intco{0,\infty}}{x}{\p(x)}
\end{align*}
za koju vrijedi
\begin{align}
\P(\rvar x\in \set A) = \int_{\set A} p_{\rvar x}(x)\dif x
\end{align}
za svaki $\set A\subset\set X$.

Funkciju gustoće vjerojatnosti možemo smatrati i \emphasize{poopćenom funkcijom}\footnote{\url{https://en.wikipedia.org/wiki/Distribution_(mathematics)}}, tj. funkcijom koja se može izraziti kao zbroj neke funkcije $f$ i translatiranih Diracovih funkcija oblika $x\mapsto f(x)+\sum_i\dirac(x-\alpha_i)$, gdje su $\alpha_i$ neke konstante, a $\dirac$ Diracova funkcija, poopćena funkcija za koju vrijedi $\dirac(x)=0$ za $x\neq0$ i $\int_x\dirac(x)\dif x=1$. To nam omogućuje da funkcijom gustoće predstavljamo razdiobe za koje neki elementarni događaji imaju vjerojatnost veću od $0$. Razdiobu diskretne slučajne varijable $\rvar x$ onda možemo predstaviti funkcijom gustoće vjerojatnosti 
\begin{align} \label{eq:dirac-density}
p_{\rvar x}(x)=\sum_{x'\in\set X} \P(\rvar x=x) \dirac(x-x')  \text{,}
\end{align}
gdje je $\set X$ prostor elementarnih događaja slučajne varijable $\rvar x$. Diracova funkcija se može promatrati kao limes funkcije gustoće Gaussove razdiobe:
\begin{align*}
\dirac(x)=\lim_{\sigma\to 0}\frac{1}{\sqrt{2\pi}\sigma}\exp\del{\frac{x^2}{2\sigma^2}}.
\end{align*}
Ako je argument Diracove funkcije vektor vektor $\vec x=(x_1,..,x_n)$, onda Diracovu funkciju definiramo umnoškom Diracovih funkcija njegovih elemenata:
\begin{align} \label{eq:dirac-vektor}
\dirac(\vec x)\coloneqq\prod_i\dirac(x_i) \text{.}
\end{align}
Takva definicija omogućuje da $n$-struki integrali funkcija definiranih izrazima \eqref{eq:dirac-density} ili \eqref{eq:dirac-vektor} imaju vrijednost $1$.

%npr. definirati i funkciju gustoće vjerojatnosti $p_{\rvar x}(x) = \frac{1}{2}\dirac(x)+\frac{1}{2}$ definiranom na domeni $\intcc{0,1}$.

Razdioba slučajne varijable $\rvar x$ će se u ovom radu označavati s $\P(\rvar x)$ ako je diskretna, a s $\p(\rvar x)$ ako je kontinuirana ili ju nismo definirali. Funkcija (gustoće) vjerojatnosti će se označavati bez oznake slučajne varijable u indeksu ako je po slovu vrijednosti jasno o kojoj se varijabli radi. Druge oznake koje se koriste opisane su u popisu oznaka na početku rada. Na nekim mjestima će, radi kratkoće, riječ \textit{razdioba} imati značenje \textit{funkcija gustoće} ili \textit{funkcija vjerojatnosti}.

\subsection{Združena, uvjetna i marginalna vjerojatnost i osnovna pravila vjerojatnosti}

Dvije razdiobe su iste ako imaju iste funkcije gustoće vjerojatnosti. Dvije slučajne varijable koje imaju istu razdiobu ne moraju biti iste jer se mogu razlikovati po odnosima s drugim slučajnim varijablama.

Možemo razmatrati više slučajnih varijabli zajedno (združenu slučajnu varijablu ili slučajni vektor) i njihovu \emphasize{združenu razdiobu}, npr. $\p(\rvar x,\rvar y)$. Događaji onda imaju oblik $\cbr{R(\rvar x,\rvar y)}$, gdj je $R$ neki predikat. Elementarni događaj onda ima oblik $\cbr{\rvar x=x, \rvar y=y}$. Često ćemo $\cbr{\rvar x=x, \rvar y=y}$ skraćeno označavati s $x, y$ ako je jasno po slovima o kojim se slučajnim varijablama radi. U ovom odjeljku će pravila vjerojatnosti biti opisana za elementarne događaje, ali ista pravila vrijede i za općenitije događaje jer za svaki događaj kojemu možemo definirati indikatorsku slučajnu varijablu kojoj je taj događaj elementarni događaj.

\emphasize{Uvjetna vjerojatnost} je vjerojatnost nekog događaja ako je poznato da se neki drugi događaj ostvario. Ovako je definirana uvjetna vjerojatnost događaja $\cbr{\rvar x=x}$ ako je poznato da se ostvario događaj $\cbr{\rvar y=y}$:
\begin{align} \label{eq:uvjetna-vj}
\p(x\mid y) \coloneqq \frac{\p(x,y)}{\p(y)}  \text{.}
\end{align}

Združena vjerojatnost se može rastaviti \emphasize{pravilom umnoška}: 
\begin{align}  \label{eq:pravilo-umnoska-bin}
\p(x,y) = \p(x\mid y)\p(y) \text{.}
\end{align}
Općenitije, pravilo umnoška za $n$ slučajnih varijabli $\rvar x_1,..,\rvar x_n$ izgleda ovako:
\begin{align} \label{eq:pravilo-umnoska}
\p(x_1,..,x_n) 
&=\p(x_1)\p(x_2\mid x_1)\cdots\p(x_n\mid x_1,..,x_{n-1})  \\
&=\p(x_1)\prod_{i=2\bidot n}\p(x_i\mid x_1,..,x_{i-1})  \text{.}
\end{align}

\emphasize{Marginalna vjerojatnost} slučajne varijable $\rvar x$ je $\p(x)=\p(\rvar x=x,\rvar y\in\set Y)$, gdje je $\set Y$ prostor elementarnih događaja slučajne varijable $\rvar y$. Izraženo gustoćom vjerojatnosti (\emphasize{pravilo zbroja}, \emphasize{marginalizacija}):
\begin{align}
\p(x) = \int_{\set Y}\p(x,y)\dif y = \int_{\set Y}\p(x\mid y)\p(y)\dif y \text{.}
\end{align}

Dvije slučajne varijable koje imaju istu razdiobu ne moraju biti u istom odnosu prema drugim slučajnim varijablama. Npr. ako $\rvar x_1\sim q_1$, $\rvar x_2\sim q_1$ i $\rvar y\sim q_2$, tj. slučajne varijable $\rvar x_1$ i $\rvar x_2$ imaju razdiobu $q_1$, a $\rvar y$ razdiobu $q_2$, ne mora vrijediti $\p(\rvar x_1, \rvar y) = \p(\rvar x_2, \rvar y)$.

Rastavljanjem lijeve strane jednadžbe~\eqref{eq:pravilo-umnoska-bin} na umnožak $\p(x\mid y)\p(y)$ dobivamo \emphasize{Bayesovo pravilo}:
\begin{align}
\p(x\mid y) = \frac{\p(y\mid x)\p(x)}{\p(y)} \text{,}
\end{align}
što možemo i ovako zapisati:
\begin{align}
\p(x\mid y) = \frac{\p(y\mid x)\p(x)}{\int\p(y\mid x)\p(x)\dif x} \text{,}
\end{align}
gdje se nazivnik integrira po svim vrijednostima.

\subsection{Nezavisnost, uvjetna nezavisnost i uvjetna zavisnost}

Kada su dvije slučajne varijable $\rvar x$ i $\rvar y$ \emphasize{zavisne}, što se označava $\rvar x\not\perp\rvar y$, znanje o ishodu jedne utječe na znanje o ishodu druge, tj. uvjetna razdioba $\p\del{\rvar x\mid\rvar y = y}$ ovisi o ishodu $y$. \textit{Znanje o ishodu} ne mora značiti da je ishod poznat. Dovoljna je promjena znanja o razdiobi koja može biti posljedica opažanja neke treće slučajne varijable. Slučajne varijable $\rvar x$ i $\rvar y$ su \emphasize{nezavisne}, što se označava $\rvar x\perp\rvar y$, akko za svaki par $(x, y)$ vrijedi
\begin{align}
\p(x,y)=\p(x)\p(y) \text{,}
\end{align}
ili, ekvivalentno,
\begin{align}
\p(x\mid y) = \p(x) \text{.}
\end{align}
Znanje o ishodu jedne slučajne varijable onda ne utječe na znanje o ishodu druge.

Slučajne varijable $\rvar x$ i $\rvar y$, koje mogu biti zavisne, su uz znanje o ishodu slučajne varijable $\rvar z$ \emphasize{uvjetno nezavisne}, što se označava $\rvar x\perp\rvar y\mid\rvar z$, akko su slučajne varijable $\del{\rvar x\mid\rvar z=z}$ i $\del{\rvar y\mid\rvar z=z}$ nezavisne za svaki mogući ishod $z$. Onda za svaku trojku $(x,y,z)$ vrijedi
\begin{align}
\p(x,y\mid z) = \p(x\mid z)\p(y\mid z) \text{,}
\end{align}
 ili, ekvivalentno,
\begin{align}
\p(x\mid y,z) = \p(x\mid z) \text{.}
\end{align}

Isto tako, slučajne varijable $\rvar x$ i $\rvar y$ koje su nezavisne mogu biti \emphasize{uvjetno zavisne} uz znanje o ishodu neke slučajne varijable $\rvar z$. Općenito, dvije slučajne varijable ne moraju biti ni uvjetno zavisne ni uvjetno nezavisne jer uz neke ishode treće slučajne varijable po kojoj se uvjetuje one mogu biti zavisne, a uz neke nezavisne. Također se može govoriti i o zavisnosti ili nezavisnosti događaja.

\subsection{Očekivanje, varijanca i kovarijanca}

\emphasize{Očekivanje} (prvi moment) slučajne varijable definirano je ovako:
\begin{align}
\E\rvar x \coloneqq \int x\p(x)\dif x \text{,}
\end{align}
gdje se integrira po prostoru elementarnih događaja. Još se označava ovako: $\mu_{\rvar x}$. Očekivanje funkcije slučajne varijable zapisujemo ovako:
\begin{align}
\E_{x\sim\rvar x} f(x) \coloneqq \E f(\rvar x) = \int f(x)\p(x)\dif x \text{.}
\end{align}
Ako je po oznaci jasno o kojoj se slučajnoj varijabli radi, možemo kraće pisati $\E_{\rvar x} f(x)$. Očekivanje ima svojstvo linearnosti:
\begin{align}
\E\del{\alpha f(\rvar x)+\beta g(\rvar x)} = \alpha\E f(\rvar x)+\beta\E g(\rvar x) \text{.}
\end{align}

\emphasize{Varijanca} (disperzija, drugi centralni moment) slučajne varijable definirana je ovako:
\begin{align}
\D\rvar x \coloneqq \E\sbr{\del{\rvar x-\E \rvar x}^2} = \int (x-\E \rvar x)^2 \p(x)\dif x \text{.}
\end{align}
Varijanca se može izraziti preko drugog momenta $\E{\rvar x}^2$ i kvadrata očekivanja $\del{\E\rvar x}^2$:
\begin{align}
\D\rvar x 
&= \E\del{\del{\rvar x-\E \rvar x}^2} \\
&= \E\del{{\rvar x}^2-2x\E \rvar x+\del{\E\rvar x}^2} \\
&= \E{\rvar x}^2-2\del{\E\rvar x}^2+\del{\E\rvar x}^2 \\
&= \E{\rvar x}^2 - \del{\E\rvar x}^2  \text{.} \label{eq:varijanca-izrazavanje-momenti}
\end{align}
Drugi korijen varijance je standardna devijacija $\sigma_{\rvar x}$.

\emphasize{Kovarijanca} para slučajnih varijabli definirana je ovako:
\begin{align}
\Cov\del{\rvar x,\rvar y} \coloneqq \E\sbr{\del{\rvar x-\E\rvar x}\del{\rvar y-\E\rvar y}} = \E{\rvar x\rvar y} - \del{\E\rvar x}\del{\E\rvar y} \text{.}
\end{align}
\emphasize{Kovarijacijska matrica} slučajnog vektora $\rvec x\in\R^n$ je matrica tipa $n\times n$ takva da:
\begin{align}
\Cov\del{\rvec x}_{\ind{i,j}} = \Cov\del{\rvec x_\ind{i}, \rvec x_\ind{j}} \text{.}
\end{align}
Dijagonalni elementi te matrice su $\Cov\del{\rvec x}_\ind{i,i} = \D\rvec x_\ind{i}$.

\subsection{Funkcije slučajnih varijabli}

Neka je odnos između slučajnih varijabli $\rvar x$ i $\rvar y$ definiran funkcijom $f$ koja ishode jedne slučajne varijable deterministički preslikava u ishode druge, što se označava ovako: $\rvar y = f(\rvar x)$.  Ako su $\rvar x$ i $\rvar y$ diskretne slučajne varijable, onda je razdioba slučajne varijable $\rvar y$ definirana ovako:
\begin{align}
	P_{\rvar y}(y) = \sum_{x\colon f(x)=y} P_\rvar{x}(x) \text{.}
\end{align} 
Ako su $\rvar x$ i $\rvar y$ kontinuirane slučajne varijable s vrijednostima iz $\R$ i $f$ je injektivna, može se pokazati \citep{Elezovic:2007:VSSV} da vrijedi
\begin{align} \label{eq:gustoca-funkcije-sv}
p_{\rvar y}(y) = p_\rvar{x}(x) \envert{\od{x}{y}} \text{.}
\end{align} 
Neka je $C_{\rvar x}(x) := \int_{-\infty}^{x} p_{\rvar x}(x') \dif{x'}$. Vrijednosti iz intervala $\intoo{x, x+\epsilon}$ na kojem je $f$ monotono rastuća preslikavaju se u interval $\intoo{f(x), f(x+\epsilon)}$. Granice su obrnute ako je $f$ monotono padajuća na tom intervalu. Budući da događaji $\cbr{\rvar x\in\intoo{x, x+\epsilon}}$ i $\cbr{\rvar y\in\intoo{f(x), f(x+\epsilon)}}$ imaju istu vjerojatnost, vrijedi
\begin{align}
C_{\rvar x}(x+\epsilon)-C_{\rvar x}(x) = 
C_{\rvar y}(f(x+\epsilon))-C_{\rvar y}(f(x)) \text{.}
\end{align}
Ako obje strane jednadžbe dijelimo s $\epsilon$ i pustimo $\epsilon\to0$, 
\begin{align}
	\lim_{\epsilon\to 0}\frac{C_{\rvar x}(x+\epsilon)-C_{\rvar x}(x)}{\epsilon} = \lim_{\epsilon\to 0}\frac{C_{\rvar y}(f(x+\epsilon))-C_{\rvar y}(f(x))}{\epsilon} \text{.}
\end{align}
Redom prema definiciji derivacije, pravilu derivacije složene funkcije i definiciji funkcija $C_\rvec{x}$ i $C_\rvec{y}$ kao integrala gustoće vjerojatnosti slijedi:
\begin{align}
\od{}{x}C_{\rvar x}(x) &= \od{}{x}C_{\rvar y}(f(x)) \text{,}\\
\od{}{x}C_{\rvar x}(x) &= \od{}{f(x)}C_{\rvar y}(f(x))\od{}{x}f(x) \text{,}\\
p_{\rvar x}(x) &= p_{\rvar y}(f(x))\od{}{x}f(x) \text{.} \label{eq:gustoca-funkcije-sv-dokaz-rastuci}
\end{align}
Može se pokazati da je za monotono padajuće intervale desna strana jednadžbe~\eqref{eq:gustoca-funkcije-sv-dokaz-rastuci} pomnožena s $-1$, iz čega uz jednadžbu~\eqref{eq:gustoca-funkcije-sv-dokaz-rastuci} slijedi
\begin{align}
p_{\rvar x}(x) &= p_{\rvar y}(y)\envert{\od{y}{x}} \text{,} \label{eq:gustoca-funkcije-sv-dokaz-xy}
\end{align}
gdje je $f(x)$ zamijenjen s $y$. Množenjem toga s $\envert{\od{x}{y}}=\envert{\od{y}{x}}^{-1}$ slijedi jednadžba~\eqref{eq:gustoca-funkcije-sv}. To pravilo se može poopćiti i na vektore. Onda je $p_{\rvec y}(\vec y)=p_\rvec{x}(\vec x)\envert{\det\pd{\vec x}{\vec y}}$ \citep{Murphy:2012:MLPP}.

Neka je $\rvar z$ zbroj slučajnih varijabli $\rvar x$ i $\rvar y$. Onda vrijedi
\begin{align}
	p_{\rvar z}(z) = \int p_{\rvar x,\rvar y}(x, z-x)\dif x \text{.}
\end{align}
Ako su $\rvar x$ i $\rvar y$ nezavisne, onda to postaje konvolucija:
\begin{align} \label{eq:nezavisne-gustoce-konvolucija}
p_{\rvar z}(z) = \int p_{\rvar x}(x)p_{\rvar y}(z-x)\dif x \eqqcolon (p_{\rvar x}*p_{\rvar y})(z) \text{.}
\end{align}

\subsection{Primjeri razdioba}

\emphasize{Bernoullijeva razdioba} je binarna razdioba s prostorom elementarnih događaja koji je obično $\{0,1\}$. Ona je onda određena parametrom $\mu\in\intcc{0,1}$ i ima ova svojstva:
\begin{align}
	\P(x) &= \mu \enbbracket{x=1} + (1-\mu) \enbbracket{x=0} = \mu^x(1-\mu)^{1-x}, \\
	\E \rvar x &= \mu, \\
	\D \rvar x &= \mu(1-\mu) \text{.}
\end{align}

\emphasize{Kategorička razdioba} je poopćenje Bernoullijeve razdiobe na konačan prostor elementarnih događaja koji može imati više od $2$ vrijednosti. Ako prostor elementarnih događaja ima kardinalitet $n$, razdioba je određena vektorom $\vec p\in\intcc{0,1}^{n-1}$ za koji vrijedi $\sum_i p_\ind{i}\leq 1$. Prostor elementarnih događaja ne mora biti skup $\cbr{1\bidot n}$, pa je kategorička razdioba najopćenitija diskretna razdioba nad konačnim skupom elementarnih događaja.

\emphasize{Eksponencijalna razdioba} je kontinuirana razdioba s domenom $\R_{\geq0}$. Ona je definirana parametrom $\lambda\in\R_{>0}$ ili $\beta=\lambda^{-1}$ i ima ova svojstva:
\begin{align}
\p(x) &= \lambda\exp(-\lambda x) \\
\E \rvar x &= \lambda^{-1}, \\
\D \rvar x &= \lambda^{-2} \text{.}
\end{align}

\emphasize{Laplaceova razdioba} je kontinuirana razdioba definirana parametrima $\beta\in\R_{>0}$ i $\mu \in \R$ i ima ova svojstva:
\begin{align}
\p(x) &= \frac{1}{2\beta}\exp\del{-\frac{\envert{x}}{\beta}} \\
\E \rvar x &= \mu, \\
\D \rvar x &= \beta^2 \text{.}
\end{align}

\emphasize{Gaussova (normalna) razdioba} $\mathcal{N}(\mu,\sigma^2)$ je kontinuirana razdioba definirana parametrima $\mu\in\R$ i $\sigma \in \R_{>0}$ i ima ova svojstva:
\begin{align}
\p(x) &= \frac{1}{\sqrt{2\pi\sigma^2}}\exp\del{\frac{\del{x-\mu}^2}{2\sigma^2}} \\
\E \rvar x &= \mu, \\
\D \rvar x &= \sigma^2 \text{.}
\end{align}
Neka je 
\begin{align} \label{eq:normalizirani-zbroj}
\rvar z_n = \frac{\sum_{i=1}^n \del{\rvar x_i-\mu}}{\sigma\sqrt{n}}
\end{align}
normalizirani zbroj $n$ nezavisnih slučanih varijabli $\rvar x_i$ koje imaju jednaku razdiobu s očekivanjem $\mu$ i varijancom $\sigma^2$. Prema \emphasize{centralnom graničnom teoremu}, $\rvar z_n$ u razdiobi konvergira prema Gaussovoj razdiobi kada $n\to\infty$, tj.
\begin{align}
\lim_{n\to\infty} \P(\rvar z_n<z) = \int_{-\infty}^{z} p_{\mathcal{N}(0,1)}(z')\dif{z'} \text{.}
\end{align}
$p_{\mathcal{N}(0,1)}$ označava funkciju gustoće normalne razdiobu s $\mu=0$ i $\sigma^2=1$. To je detaljnije objašnjeno i dokazano npr. u \citet{Elezovic:2007:VSSV}. Centralni granični teorem je ilustriran na slici~\ref{fig:clt}.

\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{clt}
	\caption{Ilustracija centralnog graničnog teorema. Grafovi za različite brojeve pribrojnika $n$ prikazuju funkcije gustoće vjerojatnosti normaliziranih zbrojeva (kao u je jednadžbi~\eqref{eq:normalizirani-zbroj}) nezavisnih slučajnih varijabli s razdiobom prikazanom prvim grafom. Zadnji graf prikazuje funkciju gustoće Gaussove razdiobe s očekivanjem $0$ i varijancom $1$. Slika je dobivena ponavljanom konvolucijom (jednadžba~\eqref{eq:nezavisne-gustoce-konvolucija}) funkcije gustoće vjerojatnosti uz primjenu jednadžbe~\eqref{eq:gustoca-funkcije-sv} za normalizaciju.
	%Normalizirani zbroj slučajnih varijabli $\rvar x_1,\bidot,\rvar x_n$ je $\frac{1}{\sqrt{n}}\sum_i \frac{\rvar x_i-\E\rvar x_i}{\sqrt{\D\rvar x_i}}$. 
	}
	\label{fig:clt}
\end{figure}

\emphasize{Višedimenzionalna Gaussova razdioba} je kontinuirana razdioba definirana parametrima $\vec\mu\in\R^n$ i pozitivno definitnom matricom $\vec\Sigma$ i ima ova svojstva:
\begin{align}
\p(\vec x) &= \frac{1}{(2\pi)^{\frac{n}{2}}\det(\vec\Sigma)^\frac{1}{2}} \exp\del{-\frac{1}{2}\del{\vec x-\vec\mu}^\tp \vec\Sigma^{-1} \del{\vec x-\vec\mu}^\tp} \\
\E \rvec x &= \vec\mu, \\
\Cov(\rvec x) &= \vec\Sigma \text{.}
\end{align}
Ako su $\rvec x_\ind{i}$ nezavisne, $\vec\Sigma$ će biti dijagonalna matrica, ali mora vrijediti obrnuto.

\section{Teorija informacije} \label{sec:teorija-informacije}

Jedan od osnovnih pojmova u teoriji informacije \citep{Shannon:1948:MTC} je \emphasize{sadržaj informacije} koji događaj preslikava u nenegativan realni broj:
\begin{align}
\I(x\in\set A)\coloneqq\log_b \frac{1}{\P(x\in\set A)} = -\log_b \P(x\in\set A) \text{.}
\end{align}
Događaji koji imaju manju vjerojatnost sadrže više informacije. Ako je vjerojatnost nekog događaja $1$, njegov sadržaj informacije je $0$. $b$ je najčešće $2$ ili $e$.

Sadržaj informacije odgovara minimalnom broju simbola (bitova ako $b=2$) potrebnih za kodiranje elementarnih događaja prefiksnim kodom za koji je očekivanje duljine poruke minimalno \citep{Olah:2015:VIT}. Kod prefiksnog koda nijedna kodna riječ nije prefiks neke druge kodne riječi. Takav kod se može prenositi kao niz združenih kodnih riječi bez posebnog simbola za označavanje granica između kodnih riječi. Donja granica očekivanja duljine poruke kod optimalnog koda naziva se \emphasize{entropija}:
\begin{align}\label{eq:entropy}
\H(\rvar x) \coloneqq  \E_{\rvar x}\I(\rvar x=x) = -\E_{\rvar x}\log_b \P(x) \text{.}
\end{align}
Kažemo \textit{donja granica} zato što kodne riječi ili poruke mogu imati samo cjelobrojne duljine, a sadržaj informacije pojedinih poruka ne mora biti cjelobrojan, pa optimalno kodirana poruka mora imati najbliži cijeli broj simbola koji je veći ili jednak sadržaju informacije. U nastavku se, radi jednostavnosti i na račun preciznosti, to neće spominjati kod opisivanje drugih informacijsko-teorijskih veličina. Entropija iskazuje neizvjesnost diskretne slučajne varijable. Ona će biti $0$ ako je vjerojatnost nekog elementarnog događaja $1$, a najveća će biti kada svi elementarni događaji imaju istu vjerojatnost: $\H(\rvar x)=\log_b n$, gdje je $n$ broj elementarnih događaja. 

Entropija kontinuirane slučajne varijable je beskonačna. Ako se u izrazu \eqref{eq:entropy} vjerojatnost zamijeni gustoćom vjerojatnosti, onda on predstavlja \emphasize{diferencijalnu entropiju}
\begin{align}\label{eq:diff-entropy}
\h(\rvar x) \coloneqq -\E_{\rvar x}\log_b \p(x) \text{,}
\end{align}
jedan od analoga\footnote{\url{https://en.wikipedia.org/wiki/Differential_entropy}} entropije za kontinuirane varijable koji nema neka od svojstava koja ima entropija.

\emphasize{Unakrsna entropija} je mjera koja iskazuje očekivanje duljine poruke kodirane optimalnim kodom za razdiobu $\P(\rvar y)$ ako izvor poruka ima razdiobu $\P(\rvar x)$. Ovako je definirana:
\begin{align}
\H_{\rvar y}(\rvar x)\coloneqq \E_{\rvar x}\I(\rvar y=x) = -\E_{\rvar x}\log_b P_{\rvar y}(x) \text{.}
\end{align}
Za $\P(\rvar y) = \P(\rvar x)$ je $\H_{\rvar y}(\rvar x) = \H_{\rvar x}(\rvar x)=\H(\rvar x)$. Za unakrsnu entropiju se često koristi oznaka $\H(\rvar x,\rvar y)$, ali ista oznaka se koristi i za entropiju para slučajnih varijabli $(\rvar x,\rvar y)$. Po uzoru na \citet{Olah:2015:VIT}, ovdje koristimo oznaku $\H_{\rvar y}(\rvar x)$.

Kao mjera razlike između dviju razdioba često se koristi \emphasize{relativna entropija} ili \emphasize{Kullback-Leiblerova divergencija} (KL-divergencija):
\begin{align}
	\Dkl{\rvar x}{\rvar y} \coloneqq \H_{\rvar y}(\rvar x) - \H(\rvar x) = \E_{\rvar x} \log_b\frac{P_{\rvar x}(x)}{P_{\rvar y}(x)} \text{.}
	\label{eq:dkl}
\end{align}
Ona je uvijek pozitivna i mjeri koliko simbola više se u prosjeku koristi ako se opaža razdioba $\P(\rvar x)$, a događaji se kodiraju kodom optimalnim za razdiobu $\P(\rvar y)$. KL-divergencija će biti $0$ akko $\rvar x$ i $\rvar y$ imaju iste razdiobe. To je ilustrirano slikom~\ref{fig:dkl}. KL-divergencija, kao ni unakrsna entropija, nije simetrična (slika~\ref{fig:dkl-asymmetry}), tj. općenito $\Dkl{\rvar x}{\rvar y}\neq\Dkl{\rvar y}{\rvar x}$ i $\H_{\rvar y}(\rvar x)\neq\H_{\rvar x}(\rvar y)$. KL-divergencija je izrazom \eqref{eq:dkl} definirana i za kontinuirane slučajne varijable ako se funkcije vjerojatnosti zamijene funkcijama gustoće vjerojatnosti. Ona divergira kada postoji $x$ za koji $P_{\rvar x}(x)>0$ i $P_{\rvar y}(x)=0$ ili, u slučaju kontinuiranih razdioba, $p_{\rvar x}(x)>0$ i $p_{\rvar y}(x)=0$.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\draw[thick] (0,0) rectangle (8,3.5ex) node[pos=.5] {$\H_{\rvar y}(\rvar x)$};
	\draw[thick] (0,3.5ex) rectangle (5,7ex) node[pos=.5] {$\H(\rvar x)$};
	\draw[thick] (5,3.5ex) rectangle (8,7ex) node[pos=.5] {$\Dkl{\rvar x}{\rvar y}$};
	\end{tikzpicture}
	\caption{Odnos entropije, unakrsne entropije i KL-divergencije: $\H_{\rvar y}(\rvar x)=\H(\rvar x)+\Dkl{\rvar x}{\rvar y}$.}
	\label{fig:dkl}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{dkl-asymmetry}
	\caption{Asimetričnost KL-divergencije. $p$ je fiksna razdioba (funkcija gustoće), a $q*$ je Gaussova razdioba koja ju aproksimira minimizacijom KL-divergencije $\Dkl{q}{p}$ (lijevo) ili $\Dkl{p}{q}$ (desno). U donjem retku grafovi prikazuju podintegralne funkcije odgovarajućih KL-divergencija. Kod njih zbrojevi predznačenih površina obojanih područja odgovaraju KL-divergencijama $\Dkl{q}{p}$ (zeleno) ili $\Dkl{p}{q}$ (crveno). Optimalna aproksimirajuća razdioba desno ima veliku gustoću gdje god razdioba $p$ ima veliku gustoću. Lijevo optimalna aproksimirajuća razdioba nema veliku gustoću gdje razdioba $p$ nema veliku gustoću. Da je razmak između komponenata razdiobe $p$ malo manji, i lijeva razdioba $q^*$ bi pokrila oba moda i bila sličnija desnoj. Slika je napravljena po uzoru na sliku~3.6 u \citet{Goodfellow:2016:DL}.}
	\label{fig:dkl-asymmetry}
\end{figure}

\emphasize{Međusobna informacija} je mjera zavisnosti između slučajnih varijabli. Definirana je ovako:
\begin{align} \label{eq:mutinf}
\I\del{\rvar x;\rvar y} \coloneqq \E_{\rvar x, \rvar y} \log_b\frac{P_{\rvar x, \rvar y}(x, y)}{P_{\rvar x}(x)P_{\rvar y}(y)} \text{,}
\end{align}
a može se i na ove načine izraziti:
\begin{align}
\I(\rvar x;\rvar y)
&= \H(\rvar x)+\H(\rvar y)-\H(\rvar x, \rvar y) \label{eq:mutinf-hhh}\\
&= \H(\rvar x)-\H(\rvar x\mid \rvar y) \\
&= \H(\rvar y)-\H(\rvar y\mid\rvar x) \text{,} \label{eq:mutinf-zadnja}
\end{align}
gdje je
\begin{align}
\H(\rvar x\mid \rvar y) \coloneqq \E_{\rvar x} \H(\rvar y\mid \rvar x=x)
\label{eq:condentropy}
\end{align}
\emphasize{uvjetna entropija}. Ako su $\rvar x$ i $\rvar y$ nezavisne, njihova međusobna informacija će biti $0$. Ako npr. postoji surjekcija $f$ tako da $\rvar y=f(\rvar x)$, tj. poznavanje ishoda varijable $\rvar x$ jednoznačno određuje ishod varijable $\rvar y$, onda $\H(\rvar y\mid\rvar x)=0$ i $\I(\rvar x;\rvar y) = \H(\rvar y)$. Ako je $f$ bijekcija, onda $\I(\rvar x;\rvar y) = \H(\rvar x) = \H(\rvar y)$. Definirane veličine mogu se prikazati kao na slici~\ref{fig:entropije}. Isti odnosi vrijede ako se entropija zamijeni diferencijalnom entropijom.

\begin{figure}
\centering
\begin{tikzpicture}
\draw[thick] (0,10.5ex) rectangle (5,14ex) node[pos=.5] {$\H(\rvar x)$};

\draw[thick] (0,7ex) rectangle (3,10.5ex) node[pos=.5] {$\H(\rvar x\mid\rvar y)$};	
\draw[thick] (3,7ex) rectangle (5,10.5ex) node[pos=.5] {$\I(\rvar x,\rvar y)$};
\draw[thick] (5,7ex) rectangle (8,10.5ex) node[pos=.5] {$\H(\rvar y\mid\rvar x)$};	
	
\draw[thick] (3,3.5ex) rectangle (8,7ex) node[pos=.5] {$\H(\rvar y)$};
\draw[thick] (0,0) rectangle (8,3.5ex) node[pos=.5] {$\H(\rvar x,\rvar y)$};
\end{tikzpicture}
\caption{Odnosi informacijsko-teorijskih veličina dviju slučajnih varijabli, prema jednadžbama~\eqref{eq:mutinf-hhh}-\eqref{eq:mutinf-zadnja}.}
\label{fig:entropije}
\end{figure}


\section{Optimizacija temeljena na gradijentu}

U ovom odjeljku su opisani osnovni optimizacijski algoritmi temeljeni na gradijentu i neki izvedeni algoritmi koji koriste dodatne heuristike. Oni su bitni u strojnom učenju (poglavlje \ref{chap:nadzirano-strojno-ucenje}), posebno u dubokom učenju (poglavlje \ref{chap:duboko-ucenje-i-konvolucijske-mreze}). Primjena optimizacijskih algoritama u dubokom učenju opisana je u pododjeljku \ref{subsec:dukn-stoh-optimizacija}.

Neka je $\funcdef{f}{\R^n}{\R}$ funkcija čiji minumum s obzirom na parametre $\vec x$ želimo naći. Ona se u okolini točke $\vec x$, ako je dovoljno (beskonačno) puta derivabilna može izraziti Taylorovim redom:
\begin{align}
f(\vec x+\vec d) = f(\vec x) + \pd{}{\vec x}f(\vec x)\vec d + \frac{1}{2}\vec d^\tp{\tfrac{\partial^2y}{\partial\vec x\partial\vec x^\tp}}{\vec x}f(\vec x)\vec d + \cdots \text{.}
\end{align}
S drugačijim oznakama:
\begin{align} \label{eq:taylorov-red}
f(\vec x+\vec d) = f(\vec x) + \nabla_{\vec x}f(\vec x)^\tp\vec d + \frac{1}{2}\vec d^\tp\vec H_f(\vec x)\vec d + \cdots \text{.}
\end{align}

\subsection{Gradijentni spust i još neki algoritmi koje se temelje na njemu} \label{subsec:gradijenti-spust}

Ako je $\vec d$ ima malu normu, funkciju $f$ u okoline neke točke možemo dobro aproksimirati s prvih nekoliko članova Taylorovog reda. \emphasize{Gradijentni spust} je optimizacijski algoritam koji koristi linearnu aproksimaciju i iterativnim ažuriranjem parametara u smjeru gradijenta (\textit{najstrmijem} smjeru) traži minimum. Iteracija gradijentnog spusta ima ovakav oblik:
\begin{align} \label{eq:gs}
\vec x_i = \vec x_{i-1} - \eta\nabla_{\vec x}f(\vec x_{i-1}) \text{,}
\end{align}
gdje je $i$ redni broj iteracije, a $\eta$ \emphasize{veličina koraka} (\emphasize{stopa učenja} kod strojnog učenja) koja može biti konstanta ili može ovisiti o $i$.

Neka $\vec g=\nabla_{\vec x}f(\vec x)$ i $\vec H=\vec H_f(\vec x)$. Za dovoljno mali $\eta$
\begin{align} \label{eq:grad-delta-approx}
f(\vec x-\eta\vec g) = f(\vec x) - \eta\vec g^\tp\vec g - \frac{1}{2}\eta^2\vec g^\tp\vec H\vec g + \cdots
\end{align}
Uz neke blage uvjete koje mora zadovoljavati $f$ i dovoljno mali $\eta$, gradijentni spust konvergira, tj. proizvoljno se približi nekom lokalnom minimumu ili stacionarnoj točki koja nije lokalni minimum, u kojoj je isto $\nabla_{\vec x}f(\vec x)=\cvec 0$, ovisno o $\eta$. Jedan blagi uvjet može biti \emphasize{Lipschitz-kontinuiranost} funkcije $f$ ili njene derivacije \citep{Goodfellow:2016:DL}. Funkcija $f$ je Lipschitz-kontinuirana ako postoji konstanta $\lambda$ za koju za svaki par $(\vec x,\vec y)$ vrijedi:
\begin{align}
\envert{f(\vec x)-f(\vec y)} < \lambda\enVert{\vec x-\vec y} \text{.}
\end{align}
Najmanji takav $\lambda$ naziva se \emphasize{Lipschitzova konstanta}.

\subsubsection{Gradijentni spust s inercijom}

Jedna heuristika koja je često korisna kod optimizacije funkcija koje su nam zanimljive je simuliranje inercije. Jedan korak \emphasize{gradijentnog spusta s inercijom} (engl. \textit{momentum gradient descent}) ima ovakav oblik:
\begin{align}
\vec v_i &= \beta\vec v_{i-1} + \nabla_{\vec x}f(\vec x_{i-1}), \label{eq:gs-inercija-v}\\
\vec x_i &= \vec x_{i-1} - \eta\vec v_i \text{,}
\end{align}
gdje je $\beta\in\intco{0,1}$ faktor kojim se određuje \textit{otpor} proporcionalan \textit{brzini} $\vec v$, tj. otpor je proporcionalan faktoru $(1-\beta)$, što se bolje vidi ako se jednadžba~\eqref{eq:gs-inercija-v} izrazi ovako: 
\begin{align}
\vec v_i = \vec v_{i-1} - (1-\beta)\vec v_{i-1} + \nabla_{\vec x}f(\vec x_{i-1}) \text{.}
\end{align}
$\beta$ se obično odabire da bude bliže $1$. Uz $\beta=1$ dobiva se obični gradijentni spust, a uz $\beta=0$ čestica koja klizi bez trenja. Uz dobro odabran $\beta$ prigušuju se pomaci koji nisu u smjeru gibanja $\vec v$. To omogućuje bržu konvergenciju i izbjegavanje malih lokalnih optimuma i drugih stacionarnih točaka. Svojstva gradijentnog spusta s inercijom su dobro objašnjena u \citet{GOH:2017:WMRW}.

Jedno poboljšanje gradijentnog spusta s inercijom je \emphasize{Nesterovljev postupak} \citep{Nesterov:2014:ILCOBC,Sutskever:2013:TRNN}:
\begin{align}
\vec v_i &= \beta\vec v_{i-1} + \nabla_{\vec x}f(\vec x_{i-1} - \eta\vec v_{i-1}), \\
\vec x_i &= \vec x_{i-1} - \eta\vec v_i \text{.}
\end{align}
Brzina se ažurira uz procjenu gradijenta u budućoj točki na temelju brzine iz prethodne iteracije. Onda se izračuna novi pomak uz tako ažuriranu brzinu.

\subsubsection{Primjeri algoritama koji koriste još neke heuristike}

Kod opisanih algoritama konvergenciju mogu usporavati područja u kojima gradijent ima male vrijednosti. Način na koji se ta pojava može poništiti je npr. da se gradijent podijeli s njegovom normom. Na taj način će pomaci ovisiti samo o stopi učenja, a ne o strmosti funkcije koja se minimizira. Algoritam \emphasize{RMSProp} (opisan npr. u \citet{Hinton:2012:NNMLLOMBG} ili \citet{Ruder:2016:OGDOA}) ostvaruje nešto slično. Iteracija RMSPropa izgleda ovako:
\begin{align}
\vec g_i &= \nabla_{\vec x}f(\vec x_{i-1}), \\
\vec r_i &= \rho\vec r_{i-1} + (1-\rho)\vec g_i^{\odot 2}, \\
\vec x_i &= \vec x_{i-1} - \eta\del{\epsilon\cvec 1+\vec r_i}^{\odot-\frac{1}{2}} \odot \vec g_i \text{,}
\end{align}
gdje je $\rho\in\intco{0,1}$ faktor koji određuje koliko se brzo ažurira pokretni prosjek gradijenta kvadriranog po elementima, a $\epsilon$ neka mala konstanta. $\rho$ se obično odabire da bude blizu $1$. Za $\rho=0$, ako se $\epsilon$ zanemari, dobiva se iteracija algoritma \emphasize{Rprop} \citep{Hinton:2012:NNMLLOMBG}: $\vec x_i = \vec x_{i-1} - \sgn\del{\nabla_{\vec x}f(\vec x_{i-1})}$. RMSPropu se još može dodati inercija.

Jedan algoritam koji često ubrzava učenje je \emphasize{Adam} \citep{Kingma:2014:AMSO}. On uključuje i inerciju i skaliranje. Ime Adam izvedeno je iz \textit{adaptive moment estimation}. Jedna iteracija tog algoritma izgleda ovako:
\begin{align}
\vec g_i &= \nabla_{\vec x}f(\vec x_{i-1}), \\
\vec v_i &= \beta_1\vec v_{i-1} + (1-\beta_1)\vec g_i, \\
\vec r_i &= \beta_2\vec r_{i-1} + (1-\beta_2)\vec g_i^{\odot 2}, \\
\vec v'_i &= \frac{1}{1-\beta_1^i}\vec v_i, \\
\vec r'_i &= \frac{1}{1-\beta_2^i}\vec r_i, \\
\vec x_i &= \vec x_{i-1} - \eta\del{\epsilon\cvec 1+\vec r_i^{\odot\frac{1}{2}}}^{\odot-1} \odot \nabla_{\vec x}f(\vec x_{i-1}) \text{,}
\end{align}
gdje je $\vec v_i$ pomični prosjek gradijenta, $\vec r_i$ pokretni prosjek kvadrata gradijenta po elementima, a $\epsilon$ mala konstanta. Parametar $\beta_1$ ima ulogu kao $\beta$ kao gradijentnog spusta s inercijom, a $\beta_2$ kao $\rho$ kod RMSPropa. Brzina $\vec v_i$ i pokretni prosjek kvadrata $\vec r_i$ se inicijaliziraju u $\cvec 0$ i u svakom koraku se skaliraju obrnuto proporcionalno udjelu gradijenta u odnosu na inicijalnu vrijednost $\cvec 0$ u pokretnom prosjeku radi poništavanja pristranosti procjena. Za faktore skaliranja vrijedi $\lim_{i\to\infty}\frac{1}{1-\beta^i}=1$.

\subsection{Postupci drugog reda}

Ovaj pododjeljak se temelji na \citet[pododjeljak 4.3.1]{Goodfellow:2016:DL}.

Ako koristimo kvadratnu aproksimaciju~\eqref{eq:grad-delta-approx}, možemo pokušati pronaći optimalni $\eta$ koji ju minimizira. $\eta$ za koji $\pd{}{\eta}f(\vec x-\eta\vec g)=0$ će, ako $\vec g^\tp\vec H\vec g>0$ dati minimum u smjeru gradijenta kvadratne aproksimacije funkcije $f$ u točki $\vec x$. Dobije se:
\begin{align}
\eta = \frac{\vec g^\tp \vec g}{\vec g^\tp\vec H\vec g} \text{.}
\end{align}
Ako je $\funcdef{f}{\R^n}{\R}$ konveksna (pozitivno definitna) kvadratna funkcija, izmijenjeni algoritam gradijentnog spusta, koji ovako određuje veličinu koraka, minimum pronalazi u najviše $n$ koraka. 

Postupak drugog reda koji se ne ograničava na pomake u smjeru gradijenta je \emphasize{Newton-Raphsonov postupak}. Deriviranjem desne strane jednadžbe~\eqref{eq:taylorov-red} po $\vec d$ i izjednačavanjem s $\cvec 0$ dobiva se:
\begin{align}
\cvec 0 = \nabla_{\vec x}f(\vec x)^\tp + \vec d^\tp\vec H_f(\vec x) + \cdots \text{.}
\end{align}
Uz kvadratnu aproksimaciju i kraće oznake $\vec g=\nabla_{\vec x}f(\vec x)$ i $\vec H=\vec H_f(\vec x)$: $\vec H\vec d = \vec g$. Slijedi da je pomak $\vec d$ koji daje stacionarnu točku aproksimacije
\begin{align}
\vec d = \vec H^{-1}\vec g \text{.}
\end{align}
Za nekvadratne funkcije, koje imaju pozitivno definitnu Hesseovu matricu u svakoj točki, može se iterativno primjenjivati
\begin{align}
\vec x_{i+1} = \vec x_i - \eta\vec H_f(\vec x_i)\nabla_{\vec x}f(\vec x_i)
\end{align}
s $\eta<1$.


\iffalse
%\section{Računski grafovi}

Ovaj odjeljak definira \emphasize{računski graf} i opisuje grafički jezik za prikaz računskih grafova koji će se koristiti od poglavlja~\ref{chap:duboko-ucenje-i-konvolucijske-mreze}.

Računaski graf neke funkcije je usmjereni aciklički graf gdje čvorovi koji nemaju djecu predstavljaju varijable (parametre), ostali čvorovi predstavljaju operacije koje ovise varijablama ili rezultatima drugih operacija, a bridovi povezuju ulaze operacija s operacijama.

Ako je funkcija koju prikazujemo $f\colon x\mapsto y$ kompozicija $n$ funkcija: $f=f_n\circ\dots\circ f_2\circ f_1$, nju možemo prikazati
\fi



\chapter{Statističko zaključivanje} \label{chap:statisticko-zakljucivanje}

U ovom poglavlju su opisane neke od osnovnih ideja koje omogućuju efikasno \emphasize{statističko zaključivanje}, tj. optimalno procjenjivanje nesigurnosti i svojstava neopaženih slučajnih varijabli na temelju pravila vjerojatnosti, opažanja i pretpostavki. Zbog nedostatka vremena, ovdje nije obrađeno statističko testiranje, koje je jedno važno područje statističkog zaključivanja.

Neka su $\rvar x_1, .., \rvar x_n$ slučajne varijable čiju združenu razdiobu razmatramo. Želimo na temelju opeženih varijabli korištenjem pravila vjerojatnosti \emphasize{zaključivati} o razdiobama nekih neopaženih varijabli. Općenito, zaključivanje se provodi uvjetovanjem po opaženim varijablama i marginalizacijom po varijablama koje nas ne zanimaju izravno \citep{Murphy:2012:MLPP}:
\begin{align}
\p(\vec x_\text{q}\mid\vec x_\text{o}) 
= \frac{\p(\vec x_\text{q},\vec x_\text{o})}{\p(\vec x_\text{o})} 
= \frac{\int\p(\vec x_\text{q},\vec x_\text{n},\vec x_\text{o})\dif\vec x_\text{n}}{\int\p(\vec x_\text{q},\vec x_\text{n},\vec x_\text{o})\dif(\vec x_\text{q},\vec x_\text{n})} \text{.}
\label{eq:pgm-zakljucivanje-bayes}
\end{align}
Ovdje je $\rvec x_\text{q}$ niz varijabli o kojima želimo zaključivati (varijable upita), $\rvec x_\text{o}$ niz opaženih varijabli, a $\rvec x_\text{n}$ niz varijabli \textit{smetnje} (\textit{nuisance}).


\section{Probabilistički grafički modeli}

Zavisnosti između slučajnih varijabli otežavaju modeliranje i zaključivanje --- potrebno je više podataka i zaključivanje je računski zahtjevnije ako postoji puno zavisnosti. Obično možemo pretpostaviti uvjetne zavisnosti između slučajnih varijabli, što se može predstaviti neusmjerenim ili usmjerenim grafom. Prema definiciji na Wikipediji \footnote{\url{https://en.wikipedia.org/wiki/Graphical_model}}, \emphasize{probabilistički grafički model} ili \emphasize{grafički model} je probabilistički model koji se može prikazati grafom koji izražava strukturu uvjetnih zavisnosti među slučajnim varijablama. U tom grafu čvorovi označavaju slučajne varijable, a bridovi izravne odnose između varijabli. Ako je graf grafičkog modela usmjeren i acikličan, on se naziva \emphasize{Bayesova mreža} ili \emphasize{Bayesovski model}, a ako je neusmjeren, naziva se \emphasize{Markovljeva mreža} ili \emphasize{Markovljevo slučajno polje} (engl. \textit{Markov random field}, \textit{MRF}). Neki odnosi uvjetnih (ne)zavisnosti mogu se modelirati jednom, a neki drugom vrstom grafičkih modela. U nastavku ovog odjeljka naglasak će biti na Bayesovim mrežama.

Združena razdioba se prema pravilu umnoška (jednadžba~\eqref{eq:pravilo-umnoska}) može npr. ovako izraziti:
\begin{align}
\p(x_1,..,x_n) 
&= \p(x_1)\p(x_2\mid x_1)\cdots\p(x_n\mid x_1,..,x_{n-1}) \\
&= \prod_i\p(x_i\mid x_1,\bidot,x_{i-1}) \text{.}
\label{eq:pgm-pravilo-umnoska}
\end{align} 
Ako uzmemo $n=4$, graf koji odgovara toj faktorizaciji je prikazan na slici~\ref{fig:bayesova-mreza}.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\node[pnode] (x1) [] {$\rvar x_1$};
	\node[pnode] (x2) [right=of x1] {$\rvar x_2$};
	\node[pnode] (x3) [above=of x2] {$\rvar x_3$};
	\node[pnode] (x4) [above=of x1] {$\rvar x_4$};
	\path (x1) edge [dedge] (x2);	
	\path (x1) edge [dedge] (x3);	
	\path (x1) edge [dedge] (x4);
	\path (x2) edge [dedge] (x3);	
	\path (x2) edge [dedge] (x4);
	\path (x3) edge [dedge] (x4);	
	\end{tikzpicture}
	\caption{Prikaz grafičkog modela s faktorizacijom $\p(x_1,x_2,x_3,x_4)=\p(x_1)\p(x_2\mid x_1)\p(x_3\mid x_1,x_2)\p(x_4\mid x_1,x_2,x_3)$.}
	\label{fig:bayesova-mreza}
\end{figure}
Pretpostavljanjem uvjetnih nezavisnosti, neki bridovi grafa $G$ se mogu ukloniti, pa za varijable (čvorove grafa) vrijedi \emphasize{uređajno Markovljevo svojstvo}, tj. slučajna varijabla je nezavisna o precima u grafu uz opažene roditelje. To se može ovako izraziti:
\begin{align}
\rvar x\perp \pred_G(\rvar x) \setminus \pa_G(\rvar x) \mid \pa_G(\rvar x) \text{,}
\end{align}
Gdje je $\pred_G(\rvar x)$ skup predaka, a $\pa_G(\rvar x)$ skup roditelja slučajne varijable $\rvar x$ u grafu $G$.
Jednadžba~\eqref{eq:pgm-pravilo-umnoska} onda prelazi u 
\begin{align}
\p(x_1,..,x_n) 
= \prod_i\p\del{x_i \midmid \bigcap_{\rvar x_j\in\pa_G(\rvar x_i)}\cbr{\rvar x_j=x_j}} \text{.}
\end{align} 
To omogućuje primjenu efikasnijih algoritama za zaključivanje \citep{Murphy:2012:MLPP}.
Na slici~\ref{fig:bm-kanonski} prikazani su osnovni slučajevi odnosa između triju slučajnih varijabli povezanih zavisnostima koje mogu biti dio većeg grafa. Oni su detaljnije objašnjeni npr. u \citet{Bishop:2006:PRML,Alpaydin:2014:IML}. 

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\node[pnode] (x) [] {$\rvar x$};
		\node[pnode] (y) [below left=of x] {$\rvar y$};
		\node[pnode] (z) [below right=of x] {$\rvar z$};
		\path (x) edge [dedge] (y);	
		\path (x) edge [dedge] (z);
		\path (y) edge [dedge] (z);
		\end{tikzpicture}
		\caption{Grafički model s faktorizacijom $\p(x,y,z) = \p(x)\p(y\mid x)\p(z\mid x,y)$.}
		\label{subfig:bm-kanonski-a}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\node[pnode] (x) [] {$\rvar x$};
		\node[pnode] (y) [right=of x] {$\rvar y$};
		\node[pnode] (z) [right=of y] {$\rvar z$};
		\path (x) edge [dedge] (y);	
		\path (y) edge [dedge] (z);
		\end{tikzpicture}
		\caption{Uz $\rvar x\perp\rvar z\mid\rvar y$ faktorizacija postaje $\p(x,y,z) = \p(x)\p(y\mid x)\p(z\mid y)$ (lanac).}
		\label{subfig:bm-kanonski-head-to-tail}
	\end{subfigure}
	\vskip\baselineskip
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\node[pnode] (x) [] {$\rvar x$};
		\node[pnode] (y) [below left=of x] {$\rvar y$};
		\node[pnode] (z) [below right=of x] {$\rvar z$};
		\path (x) edge [dedge] (y);	
		\path (x) edge [dedge] (z);
		\end{tikzpicture}
		\caption{Uz $\rvar y\perp\rvar z\mid\rvar x$ faktorizacija postaje $\p(x,y,z) = \p(x)\p(y\mid x)\p(z\mid x)$ (račvanje).}
		\label{subfig:bm-kanonski-tail-to-tail}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\node[pnode] (z) [] {$\rvar z$};
		\node[pnode] (x) [above left=of z] {$\rvar x$};
		\node[pnode] (y) [above right=of z] {$\rvar y$};
		\path (x) edge [dedge] (z);	
		\path (y) edge [dedge] (z);
		\end{tikzpicture}
		\caption{Uz $\rvar x\perp\rvar y$ faktorizacija postaje $\p(x,y,z) = \p(x)\p(y)\p(z\mid x,y)$ (sraz). Ovdje također vrijedi $\rvar x\not\perp\rvar y\mid \rvar z$.}
		\label{subfig:bm-kanonski-head-to-head}
	\end{subfigure}
	\caption{Osnovni slučajevi uvjetne nezavisnosti. Slike \subref{subfig:bm-kanonski-head-to-tail}, \subref{subfig:bm-kanonski-tail-to-tail} i \subref{subfig:bm-kanonski-head-to-head} prikazuju grafove dobivene uvođenjem pretpostavki uvjetne nezavisnosti za grafički model s $3$ slučajne varijable prikazan na slici \subref{subfig:bm-kanonski-a}.}
	\label{fig:bm-kanonski}
\end{figure}

Na slici~\ref{fig:bm-regresija} prikazan je primjer na kojem se koriste još neke oznake: sivi čvorovi označavaju opažene varijable, četverokut označava veći broj podgrafova s istom strukturom.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\node[pnode] (t) [] {$\rvec \theta$};
	\node[textnode] (a) [right=of t] {$\alpha$};
	\node[pnode] (e) [below=of t] {$\rvar\epsilon$};
	\node[greypnode] (yi) [left=of t] {$\rvar y_i$};
	\node[greypnode] (xi) [left=of yi] {$\rvec x_i$};
	\node[pnode] (y) [left=of e] {$\rvar y$};	
	\node[greypnode] (x) [left=of y] {$\rvec x$};
	\path (a) edge [dedge] (t);	
	\path (t) edge [dedge] (yi);	
	\path (t) edge [dedge] (y);
	\path (e) edge [dedge] (yi);	
	\path (e) edge [dedge] (y);
	\path (xi) edge [dedge] (yi);
	\path (x) edge [dedge] (y);
	\plate{}{(xi)(yi)}{$i \in \cbr{1\bidot N}$};
	\end{tikzpicture}
	\caption{Primjer grafičkog modela s faktorizacijom 
		$\p(\vec x, y,\vec x_1\bidot\vec x_N,y_1\bidot y_N,\vec\theta,\epsilon) 
		= \p(\vec\theta)\p(\epsilon)p_{\rvec x}(\vec x)p_{\rvec y\mid\rvec x,\rvec\theta,\rvar\epsilon}(y\mid\vec x,\vec\theta,\epsilon) \prod_i\del{p_{\rvec x}(\vec x_i)p_{\rvec y\mid\rvec x,\rvec\theta,\rvar\epsilon}(y_i\mid\vec x_i,\vec\theta,\epsilon)}$. Graf prikazuje model regresije, gdje su $\rvec\theta$ nepoznati parametri, $\rvec x_i$ i $\rvec y_i$ opaženi parovi ulaza i izlaza, $\rvec x$ opaženi ulaz s nepoznatim izlazom $\rvar y$, a $\rvar\epsilon$ homoskedastički šum, tj. šum koji ne ovisi o ulazu. Na slici je još eksplicitno prikazana deterministička varijabla $\alpha$ koja je parametar razdiobe $\p(\rvec\theta)=\p(\rvec\theta\mid\alpha)$. Slika je napravljena po uzoru na sliku~14.7 u \citet{Alpaydin:2014:IML}.}
	\label{fig:bm-regresija}
\end{figure}

Općenitije, o uvjetnoj nezavisnosti podskupova varijabli govori svojstvo \emphasize{d-separacije}. Kažemo da je staza (podgraf sa strukturom lanca) $P$ grafa $G$ \emphasize{d-odvojena} skupom čvorova $\set E$ akko $P$ sadrži barem jedno od sljedećeg \citep{Murphy:2012:MLPP}:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item lanac $\rvar a\rightarrow\rvar b\rightarrow\rvar c$, gdje $\rvar b\in E$
	\item račvanje $\rvar a\leftarrow\rvar b\rightarrow\rvar c$, gdje $\rvar b\in E$
	\item sraz $\rvar a\rightarrow\rvar b\leftarrow\rvar c$, gdje $\forall \rvar b'\in\cbr{\rvar b}\cup\succ_G(\rvar b), \rvar b'\notin E$.
\end{enumerate}
Kažemo da skup čvorova $\set E$ d-odvaja čvorove $\rvar x$ i $\rvar y$ akko su sve staze između njih d-odvojene. Vrijedi $\rvar x\perp\rvar y \mid \set E$ akko skup čvorova $\set E$ d-odvaja čvorove $\rvar x$ i $\rvar y$. To se može poopćiti na skupove čvorova. Skup čvorova opažanjem kojega neki čvor postaje neovisan o ostatku grafa naziva se \emphasize{Markovljev pokrivač} (engl. \textit{Markov blanket}). Markovljev pokrivač čvora $\rvar x$ je
\begin{align}
\pa_G(\rvar x)\cup\ch_G(\rvar x)\cup\bigcup_{\rvar y\in\ch_G(\rvar x)}\pa_G(\rvar y)
\end{align}

U knjigama navedenim u ovom odjeljku opisani su algoritmi koji se koriste za efikasno zaključivanje iskorištavanjem strukture grafa.


\section{Procjena parametara i zaključivanje}

\subsection{Procjenitelji i točkaste procjene parametara}

Ovaj pododjeljak se temelji na \citet{Elezovic:2007:VSSV}.

Neka je $\rvar x$ slučajna varijabla i $\p(\rvar x)$ njena razdioba s nama nepoznatim parametrom $\theta$. Taj parametar možemo procijeniti na temelju opaženih vrijednosti $x_1,..,x_N$ slučajne varijable $\rvar x$, za što definiramo funkciju $f$ koja daje procjenu parametara
\begin{align}
\hat{\theta}=f(x_1,..,x_N) \text{.}
\end{align}
Ako kao parametre takve funkcije uzmemo \emphasize{uzorak}, tj. skup slučajnih varijabli $\rset D=\del{\rvar x_1,..,\rvar x_N}$, gdje pretpostavljamo da su $\rvar x_1,..,\rvar x_N$ međusobno nezavisne i imaju istu razdiobu kao $\rvar x$, dobivamo slučajnu varijablu
\begin{align}
\hat{\rvar\theta}=f(\rset D) \text{.}
\end{align}
Takva slučajna varijabla naziva se \emphasize{statistika}. Ako je $\theta$ nepoznati parametar razdiobe $\p(\rvar x)$, onda kažemo da je ta statistika $\hat{\rvar\theta}$ \emphasize{procjenitelj} parametra $\theta$, a njen ishod $\hat{\theta}$ \emphasize{procjena} parametra $\theta$.

\subsection{Svojstva i pogreška procjenitelja}

\emphasize{Pristranost} procjenitelja $\hat{\rvar\theta}$ je definirana izrazom $\E\hat{\rvar\theta} - \theta$, gdje je $\theta$ stvarna vrijednost parametra koji se procjenjuje. Ona mjeri koliko procjenitelj griješi neovisno o ishodu uzorka. Kažemo da je procjenitelj parametra $\theta$ \emphasize{nepristran} ako je njegovo očekivanje jednako parametru koji procjenjuje:
\begin{align}
\E\hat{\rvar\theta} = \theta \text{.}
\end{align}

\emphasize{Varijanca} procjenitelja $\hat{\rvar\theta}$ je definirana izrazom $\D\hat{\rvar\theta}$. Ona mjeri koliko procijenitelj griješi ovisno o variranju uzorka. 
%Neka je $\rset D$ uzorak od $n$ slučajnih varijabli. Ako su $\hat{\rvar\theta}_1(\rset D)$ i $\hat{\rvar\theta}_2(\rset D)$ dva nepristrana procjenitelja za $\theta$, kažemo da je $\hat{\rvar\theta}_1$ \emphasize{bolji} od $\hat{\rvar\theta}_2$ ako
%\begin{align}
%\D \hat{\rvar\theta}_1 < \D\hat{\rvar\theta}_2 \text{.}
%\end{align}
Neka $N$ u oznaci ${\rset D}_N$ označava veličinu uzorka. Nepristrani procjenitelj $\hat{\rvar\theta}$ je \emphasize{valjan} ako 
\begin{align}
\lim_{N\to\infty} \D\sbr{\hat{\rvar\theta}(\rset D_N)} = 0  \text{.}
\end{align}

Očekivanje srednje kvadratne pogreške procjenitelja je jednako zbroju njegove varijance i kvadrata njegove pristranosti tj. 
\begin{align}
\E\del{\del{\hat{\rvar\theta}-\theta}^2} 
= \D\hat{\rvar\theta} + \del{\E\hat{\rvar\theta}-\theta}^2  \text{,}
\end{align}
što možemo pokazati uz korištenje linearnosti očekivanja i izražavanja varijance prema jednadžbi~\eqref{eq:varijanca-izrazavanje-momenti}:
\begin{align}
\E\del{\del{\hat{\rvar\theta}-\theta}^2} 
&= \E\del{\hat{\rvar\theta}^2-2\theta\hat{\rvar\theta}+\theta^2} \\
&= \E\hat{\rvar\theta}^2-2\theta\E\hat{\rvar\theta}+\theta^2 \\
&= \underbrace{\E\hat{\rvar\theta}^2 -\del{\E\hat{\rvar\theta}}^2}_{\D\hat{\rvar\theta}} + \underbrace{\del{\E\hat{\rvar\theta}}^2 -2\theta\E\hat{\rvar\theta}+\theta^2}_{\del{\E\hat{\rvar\theta}-\theta}^2}  \text{.}
\end{align}


\subsection{Procjenitelj maksimalne izglednosti}

\emphasize{Procjenitelj maksimalne izglednosti} (\emphasize{ML-procjenitelj}, engl. \textit{maximum likelihood}) uzorku dodjeljuje parametre maksimiziraju vjerojatnost uzorka, tj. imaju najveću \emphasize{izglednost}:
\begin{align}
\rvec\theta_\text{ML} = \argmax_{\vec\theta} \p(\rset{D}\mid\vec\theta) \text{.}
\end{align}
Zbog pretpostavke međusobne nezavisnosti primjera vrijedi
\begin{align}
 \p(\set{D}\mid\vec\theta) = \prod_{\vec d\in\set{D}} \p(\vec d\mid\vec\theta) \text{.}
\end{align}

Za razliku od generativnih, diskriminativni modeli ne modeliraju razdiobu ulaznih primjera, nego samo uvjetnu razdiobu $\p(\vec y\mid \vec x, \set{D})$, pa kod njih razdioba ulaznih primjera ne ovisi o $\vec\theta$, tj. $\p(\vec x\mid\vec\theta) = \p(\vec x)$. Onda je izglednost
\begin{align}\label{eq:izglednost-diskr}
\p(\set{D}\mid\vec\theta) 
= \prod_{(\vec x,\vec y)\in\set{D}} \p(\vec y\mid\vec x,\vec\theta)\p(\vec x\mid\vec\theta) 
= \p(\vec x) \prod_{(\vec x,\vec y)\in\set{D}} \p(\vec y\mid\vec x,\vec\theta) \text{.}
\end{align}
Faktor $\p(\vec x)$ ne ovisi o parametrima i može se zanemariti pri optimizaciji.

\subsection{Procjenitelj maksimalne aposteriorne vjerojatnosti}

\emphasize{Procjenitelj maksimalne aposteriorne vjerojatnosti} (\emphasize{MAP-procjenitelj}, engl. \textit{maximum a posteriori estimator}) u obzir uzima \emphasize{apriornu razdiobu} $\p(\rvec\theta)$ koja predstavlja dodatne pretpostavke za razdiobu parametara. Apriorna razdioba parametara pojednostavljuje model dajući prednost nekim hipotezama i posebno je korisna kada ima malo podataka. Apriorna razdioba može biti definirana nekim hiperparametrima ali oni ovdje nisu prikazani. Po Bayesovom pravilu, \emphasize{aposteriorna vjerojatnost} parametara je
\begin{equation} \label{eq:posterior-bayes}
\p(\vec\theta\mid\set D) 
 = \frac{\p(\set{D}\mid\vec\theta)\p(\vec\theta)}{\p(\set{D})}
 = \frac{\p(\set{D}\mid\vec\theta)\p(\vec\theta)}{\int \p(\set{D}\mid\vec\theta')\p(\vec\theta')\dif\vec\theta'} \text{.}
\end{equation}
Maksimizacijom aposteriorne vjerojatnosti dobivaju se parametri
\begin{equation}
 \rvec\theta_\text{MAP} = \argmax_{\vec\theta} \p(\vec\theta\mid\rset D) = \argmax_{\vec\theta} \p(\rset{D}\mid\vec\theta)\p(\vec\theta) \text{.}
\end{equation}
Ovdje nije potrebno normalizirati aposteriornu vjerojatnost izračunavanjem \emphasize{marginalne izglednosti} (engl. \textit{marginal likelihood}, \textit{evidence}) $\p(\set{D})$ u nazivniku na desnoj strani jednadžbe~\eqref{eq:posterior-bayes} jer ona ne ovisi $\vec\theta$, nego samo o modelu $\set H$. Odabirom uniformne (neinformativne) apriorne razdiobe MAP-procjenitelj postaje ekvivalentan ML-procjenitelju.

Poželjno je da $\p(\set{D}\mid\vec\theta)$ i $\p(\vec\theta)$ kao funkcije parametra $\vec\theta$ imaju takav algebarski oblik da njihov umnožak ima sličan oblik i može se analitički izračunati. Ako $\p(\rvec\theta)$ i $\p(\rvec\theta\mid\set D)$ imaju isti algebarski oblik, nazivaju se \emphasize{konjugatne razdiobe} \citep{Snajder:2014:SU}.
% TODo ^^

\subsection{Bayesovski procjenitelj i zaključivanje} \label{subsec:bayesovski procjenitelj}

Prethodno opisani procjenitelji daju točkastu procjenu parametara i ne izražavaju nesigurnost procjene kojoj uzrok može biti npr. nedovoljna količina podataka ili šum u podacima za učenje. \emphasize{Bayesovski procjenitelj} prema jednadžbi~\eqref{eq:posterior-bayes} kao procjenu daje razdiobu nad hipotezama $\p(\rvec\theta\mid\set D)$ za koju je integriranjem po svim mogućim parametrima potrebno izračunati marginalnu izglednost $\p(\set{D})=\int\p(\set{D}\mid\vec\theta')\p(\vec\theta')\dif{\vec\theta'}$ u nazivniku. 

Kod složenijih modela često ne možemo odabrati konjugatnu apriornu razdiobu, a i funkcija izglednosti je sama po sebi već dovoljno složena da se, neovisno o apriornoj razdiobi, marginalna izglednost $\p(\set{D})$ ne može ni analitički ni numerički traktabilno računati. 

Vjerojatnost nekog primjera $\vec d$ procjenjuje se marginalizacijom po parametrima \citep{Neal:1995:BLNN}:
\begin{align}
\p(\vec d\mid\set D) 
= \int\p(\vec d\mid\vec\theta)\p(\vec\theta\mid\set D) \dif{\vec\theta}
= \E_{\rvec\theta\mid\set D}\p(\vec d\mid\vec\theta) \text{,}
\end{align}
gdje je korištena uvjetna nezavisnost $\rvec d\perp\rset D\mid\rvec\theta$ (zbog čega $\p(\vec d\mid\vec\theta,\rset D)=\p(\vec d\mid\vec\theta)$).

Kada se parametri točkasto procjenjuju, npr. MAP-procjeniteljem, točkasta procjena parametara $\hat{\vec\theta}$ aproksimira cijelu aposteriornu razdiobu, tj. $\p(\vec\theta\mid\set{D}) \approx \dirac(\hat{\vec\theta}-\vec\theta)$. Onda je
\begin{align}
\p(\vec d\mid\set D) 
\approx \int\p(\vec d\mid\vec\theta) \dirac(\hat{\vec\theta}-\vec\theta) \dif{\vec\theta} 
=\p(\vec d\mid\hat{\vec\theta}) \text{.}
\end{align}

Za diskriminativne modele se zaključivanje može izraziti ovako:
\begin{align} \label{eq:zakljucivanje-y}
\p(\vec y\mid \vec x, \set{D})
= \int\p(\vec y\mid \vec x,\vec\theta)\p(\vec\theta\mid\set D) \dif{\vec\theta}
= \E_{\rvec\theta\mid\set D}\p(\vec y\mid\vec x,\vec\theta) \text{,}
\end{align}
gdje je korištena uvjetna nezavisnost $\rvec y\perp\rset D\mid\rvec\theta$ --- ako su nam poznati parametri ili njihova razdioba dobivena na temelju uzorka, uvjetna razdioba $\p(\rvec y\mid \vec x,\vec\theta,\set D)$ ne ovisi o uzorku $\set D$.

Kod regresije je često, ako pretpostavljamo da pogreška izlaza ima Gaussovu razdiobu, najbolja procjena hipoteze očekivanje po naučenoj razdiobi parametara: 
\begin{align}
h(\vec x)
= \E_{\rvec\theta\mid\set D} h(\vec x; \vec\theta)
= \int h(\vec x; \vec\theta)\p(\vec\theta\mid\set D) \dif{\vec\theta} \text{,}
\end{align}
koje je ujedno i MAP-hipoteza. U tom slučaju se nesigurnost može izraziti varijancom $\D_{\rvec\theta\mid\set D} h(\vec x; \vec\theta)$.

 
\section{Monte Carlo aproksimacija}

Ovaj odjeljak se temelji na \citet[pododjeljak 17.1.2]{Goodfellow:2016:DL}.

\emphasize{Monte Carlo aproksimacija} je postupak procjenjivanja vrijednosti koje se mogu izraziti kao očekivanje neke funkcije neke slučajne varijable na temelju uzoraka. Ponekad nije moguće analitički ili numerički traktabilno ili efikasno izračunati neki integral (ili zbroj). Ako taj integral ili zbroj može ovako izraziti:
\begin{align}
s = \int\p(x)f(x)\dif x = \E f(\rvar x) \text{,}
\end{align}
možemo ga procijeniti uzorkovanjem:
\begin{align}
\hat{\rvar s}_n = \frac{1}{n}\sum_{i=1}^n f(\rvar x_i) \text{.}
\end{align}
Procjenitelj $\hat{\rvar s}_n$ je nepristran ako su $\rvar x_i$ nezavisne i imaju istu razdiobu kao $\rvar x$. On je i valjan ako su varijance $f(\rvar x_i)$ ograničene. Ako su sve varijance jednake, vrijedi $\D\hat{\rvar s}_n = \frac{1}{n} \D f(\rvar x)$.

U širem smislu, postupci \textit{Monte Carlo} obuhvaćaju i generiranje uzoraka slučajne varijable čije se očekivanje procjenjuje.


\section{Aproksimacija razdioba i aproksimacijsko zaključivanje} \label{sec:aproksimacija-razdioba}

Ovaj odjeljak se uglavnom temelji na \citet{Blei:2017:VIRS} i malo na \citet{Yang:2017:UVLB}.

Važan problem u bayesovskoj statistici, gdje se zaključivanje temelji na izračunima koji uključuju aposteriornu razdiobu, je aproksimacija razdioba koje su zahtjevne za računanje. Kod složenijih Bayesovskih modela aposteriorna razdioba se ne može lako izračunati i treba koristiti aproksimacijske postupke od kojih su glavni \emphasize{varijacijski} postupci \citep{Jordan:1999:IVMGM} i postupci \emphasize{Monte Carlo} aproksimacije s uzorkovanjem pomoću \emphasize{Markovljevog lanca} (MCMC, engl. \textit{Markov chain Monte Carlo}). MCMC-postupci temelje se na definiranju stohastičkog procesa koji ima stacionarnu razdiobu jednaku razdiobi koja se aproksimira, omogućuju asimptotski egzaktno uzorkovanje velike klase razdioba. Varijacijski postupci temelje se na aproksimaciji razdiobe nekom jednostavnijom koja se pronalazi rješavanjem optimizacijskog problema, brži su i jednostavniji za ostvariti za složenije modele.

Razmatramo bayesovski model koji ima latentnu varijablu $\rvec\theta$ i vidljivu varijablu $\rvec x$. Model je prikazan na slici~\ref{fig:pgmzx} i opisan je ovom jednadžbom združene vjerojatnosti:
\begin{align*}
\p(\vec x, \vec\theta) = \p(\vec\theta)\p(\vec x\mid\vec\theta) \text{.}
\end{align*}
Zaključivanjem se određuje aposteriorna razdioba latentne varijable:
\begin{align} \label{eq:posterior-inference}
\p(\vec\theta\mid\vec x) = \frac{\p(\vec x,\vec\theta)}{\p(\vec x)} = \frac{\p(\vec x,\vec\theta)}{\int\p(\vec x, \vec\theta) \dif{\vec\theta}} \text{.}
\end{align}
na temelju opaženih vrijednosti slučajne varijable $\rvec x$ (podataka). Kod složenijih modela integriranje marginalne izglednosti u nazivniku nije traktabilno i aposteriorna razdioba se mora aproksimirati \emphasize{približnim (aproksimacijskim) zaključivanjem}.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\node[pnode] (t) [] {$\rvec \theta$};
	\node[greypnode] (x) [right=of t] {$\rvec x$};
	\path (t) edge [dedge] (x);
	\end{tikzpicture}
	\caption{Prikaz grafičkog modela sa skrivenom varijablom $\rvec \theta$ i opaženom varijablom $\rvec x$.}
	\label{fig:pgmzx}
\end{figure}


%\section{Postupci uzorkovanja}
%TODO
%1.3.1 \citet{Neal:1995:BLNN}.


\section{Varijacijsko zaključivanje} \label{sec:varijacijsko-zakljucivanje}

Za razliku od uzorkovanja kod MCMC-postupaka, osnovna ideja kod varijacijskog zaključivanja je optimizacija. Prvo se odabire familija razdioba $\set{Q}=\cbr{q_{\vec\phi}}_{\vec\phi}$ koje su lakše za računanje. Razdiobe iz $\set{Q}$ su parametrizirane tzv. \emphasize{varijacijskim parametrima} $\vec\phi$. Cilj je na temelju podataka kao zamjenu za aposteriornu razdiobu $\p(\vec\theta\mid\vec x)$ pronaći razdiobu iz $\set{Q}$ koja ju što bolje aproksimira. To možemo ostvariti minimizacijom Kullback-Leiblerove (KL) divergenciju s obzirom na stvarnu aposteriornu razdiobu po varijacijskim parametrima $\vec\phi$:
\begin{align} \label{eq:vz-argmin-dkl}
q^* =\argmin_{q_{\vec\phi}} \Dkl{q_{\vec\phi}}{\p(\rvec\theta\mid\vec x)}
\text{,}
\end{align}
Naziv \emphasize{varijacijsko zaključivanje} dolazi od varijacijskog računa\footnote{\url{https://en.wikipedia.org/wiki/Calculus_of_variations}}, gdje se koriste varijacije, tj. male promjene u funkcijama i funkcionalima\footnote{Funkcionali su preslikavanja iz skupa funkcija u $\R$. Oni su često izraženi kao integrali koji uključuju funkcije i njihove derivacije.}, kako bi se pronašli minimumi ili maksimumi funkcionala. 

Ako ciljnu funkciju ovako izrazimo:
\begin{align}
\Dkl{q_{\vec\phi}}{\p(\rvec\theta\mid\vec x)} 
&= \E_{\tilde{\vec\theta}\sim q_{\vec\phi}} \ln\frac{q_{\vec\phi}\del{\tilde{\vec\theta}}}{p_{\rvec\theta\mid \vec x}\del{\tilde{\vec\theta}}} \nonumber \\
&= \E_{\tilde{\vec\theta}\sim q_{\vec\phi}}\ln q_{\vec\phi}\del{\tilde{\vec\theta}} - \E_{\tilde{\vec\theta}\sim q_{\vec\phi}}\ln \p\del{\rvec\theta=\tilde{\vec\theta},\vec x} + \ln\p(\vec x) \text{,} \label{eq:dkl-split}
\end{align}
vidi se da se ona ne može lako izračunati jer zahtijeva računanje marginalne izglednosti $\p(\vec x)$ iz nazivnika u jednadžbi~\eqref{eq:posterior-inference} marginalizacijom po $\rvec\theta$. Marginalna izglednost ne ovisi o varijacijskim parametrima, pa ju možemo zanemariti i maksimiziramo funkciju koja se naziva \emphasize{varijacijska donja granica} (engl. \textit{variational lower bound}) ili \emphasize{donja granica (logaritma) marginalne izglednosti} (engl. \textit{(log) evidence lower bound}, \textit{ELBO}) \citep{Jordan:1999:IVMGM}:
\begin{align}
L_{\vec x}\del{q_{\vec\phi}} 
&\coloneqq \ln\p(\vec x) - \Dkl{q_{\vec\phi}}{\p(\rvec\theta\mid\vec x)} \label{eq:donja-varijacijska-granice}\\
&= \E_{\tilde{\vec\theta}\sim q_{\vec\phi}} \ln \p\del{\rvec\theta 
=\tilde{\vec\theta},\vec x} - \E_{\tilde{\vec\theta}\sim q_{\vec\phi}} \ln q_{\vec\phi}\del{\tilde{\vec\theta}}  \text{.} \label{eq:elbo}
\end{align}
Naziv \textit{donja granica logaritma marginalne izglednosti} dolazi od toga što vrijedi $L_{\vec x}\del{q_{\vec\phi}} \leq \ln\p(\vec x)$. To slijedi iz jednadžbe~\eqref{eq:donja-varijacijska-granice} i nenegativnosti KL-divergencije:
\begin{align}
\ln\p(\vec x) = L_{\vec x}\del{q_{\vec\phi}} + \Dkl{q_{\vec\phi}}{\p(\rvec\theta\mid\rvec x)} \geq L_{\vec x}\del{q_{\vec\phi}} \text{.}
\end{align}
\textit{Donja granica marginalne izglednosti} se može i ovako izraziti:
\begin{align}
L_{\vec x}\del{q_{\vec\phi}}
= \E_{\tilde{\vec\theta}\sim q_{\vec\phi}} \ln\p\del{\vec x\midmid\rvec\theta=\tilde{\vec\theta}} - \Dkl{q_{\vec\phi}}{\p(\rvec\theta)}  \text{.}
\end{align}
Maksimiziranje takve ciljne funkcije s obzirom na varijacijske parametre daje razdiobu koja dobro objašnjava podatke jer se potiče veće očekivanje logaritma izglednosti (prvi član), a ne razlikuje se previše od apriorne razdiobe jer se potiče manja KL-divergencija između varijacijske razdiobe i apriorne razdiobe \citep{Gal:2015:DBAA}.



\subsection{Metoda srednjeg polja}

Dodatno pojednostavljenje koje pomaže u modeliranju i optimizaciji je pretpostavljanje nezavisnosti između latentnih varijabli. Onda za varijacijsku razdiobu vrijedi ovakva faktorizacija:
\begin{align}
q_{\vec\phi}\del{\tilde{\vec\theta}} = \prod_i q_{\vec\phi,i}\del{\tilde{\vec\theta}_\ind{i}},
\end{align}
gdje su $q_{\vec\phi,i}$ funkcije gustoće pojedinih slučajnih varijabli. Kod \emphasize{metode srednjeg polja} pretpostalja se takva razdioba i obično se primjenjuje koordinatni spust za optimizaciju. To je detaljnije objašnjeno npr. u \citet{Murphy:2012:MLPP}.

\iffalse
Neka je, radi kraćeg zapisa, $t\del{\tilde{\vec\theta}} \coloneqq \p(\rvec\theta=\tilde{\vec\theta},\rvec x=\vec x)$. Uz aproksimaciju srednjeg polja donja varijacijska granica postaje
\begin{align}
L_{\vec x}\del{\tilde{\rvec\theta}} 
&= \E_{\tilde{\vec\theta}\sim q_{\vec\phi}}\del{\ln t\del{\tilde{\vec\theta}} - \ln q\del{\tilde{\vec\theta}}}
\\
&= \int\dif{\tilde{\vec\theta}} \del{\prod_i q_i(\tilde{z}_i)}\del{\ln t\del{\tilde{\vec\theta}} - \sum_j \ln q_j(\tilde{z}_j)}
\text{.}
\end{align}
\fi



\chapter{Nadzirano strojno učenje} \label{chap:nadzirano-strojno-ucenje}

Ovo poglavlje se uglavnom temelji na \citet{Snajder:2014:SU,Goodfellow:2016:DL}.

Zadatak algoritama \emphasize{nadziranog učenja} je preslikavanje \emphasize{ulaznih primjera} $\vec x$ iz \emphasize{ulaznog prostora} $\set{X}$ u \emphasize{izlaze} (\emphasize{oznake}) $\vec y\in\set{Y}$ na temelju konačnog skupa označenih primjera $\set{D} = \cbr{\del{\vec x_i,\vec y_i}}_{i}$. Algoritmima strojnog učenja pretražuje se \emphasize{model} ili \emphasize{prostor hipoteza} u cilju pronalaska \emphasize{hipoteze} koja osim primjera iz skupa za učenje, u izlaze dobro preslikava i primjere koji nisu u skupu za učenje. Sposobnost postizanja dobre performanse na neviđenim primjerima naziva se \emphasize{generalizacija}.

Neka je $\set{D}=\cbr{\vec d_i}_i$ skup nezavisnih primjera izvučenih iz neke razdiobe $\distrib{D}$. Možemo definirati \emphasize{probabilistički model} $\set H$ s nepoznatim parametrima $\vec\theta$ kojem je cilj što bolje modelirati tu razdiobu pronalaskom najbolje hipoteze na temelju podataka: $\p(\vec{d}\mid\set{D},\set H)$. Model koji modelira razdiobu primjera nazivamo \emphasize{generativnim modelom}. U nastavku ćemo izostavljati oznaku modela radi kraćeg zapisa.

Ako su primjeri parovi $\vec d_i = \del{\vec x_i, \vec y_i} \in \set{X}\times\set{Y}$, može nam biti cilj ulaznim primjerima iz $\set{X}$ dodjeljivati oznake iz $\set Y$. Ako je problem koji rješavamo dodjeljivanje oznaka ulaznim primjerima, onda su često prikladniji \emphasize{diskriminativni modeli}. Probabilistički diskriminativni modeli izravno modeliraju uvjetne razdiobe $\p(\rvec y\mid \vec x)$ hipotezom koja ulazni primjer $\vec x$ preslikava u razdiobu $\p(\rvec y\mid\vec x,\set{D})$. Neprobabilistički diskriminativni modeli modeliraju funkciju dodjeljivanja oznaka hipotezom $\funcdef{h}{\set{X}}{\set{Y}}$. Modeliranje zajedničke razdiobe $\p(\rvec x,\rvec y)$ obično zahtijeva više računalnih resursa i podataka \citep{Bishop:2006:PRML}.

Modeli se još mogu podijeliti na \emphasize{parametarske} i \emphasize{neparametarske}. Kod parametarskih modela broj parametara je unaprijed određen, dok kod neparametarskih on ovisi o podacima za učenje.


\section{Induktivna pristranost}

Uz zadani skup hipoteza koji dopušta model, \emphasize{algoritam strojnog učenja} traži parametre koji definiraju jednu hipotezu. Učenje hipoteze je loše definiran (engl. \textit{ill-posed}) problem jer skup podataka $\set{D}$ nije dovoljan za jednoznačan odabir hipoteze. Osim dobrog opisivanja podataka za učenje, naučena hipoteza mora dobro generalizirati. Kako bi učenje i generalizacija bili mogući, potreban je skup pretpostavki koji se naziva \emphasize{induktivna pristranost}. Razlikujemo dvije vrste induktivne pristranosti \citep{Snajder:2014:SU}:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item \emphasize{pristranost ograničavanjem} ili \emphasize{pristranost jezika} --- ograničavanje skupa hipoteza koje se mogu prikazati modelom
	\item \emphasize{pristranost preferencijom} ili \emphasize{pristranost pretraživanja} --- dodjeljivanje različitih prednosti različitim hipotezama.
\end{enumerate}
Većina algoritama strojnog učenja kombinira obje vrste induktivne pristranosti. 


\section{Komponente algoritma strojnog učenja}

Prema \citet{Snajder:2014:SU}, kod većine algoritama strojnog učenja možemo razlikovati $3$ osnovne komponente, od kojih prva predstavlja pristranost ograničavanjem, a druge dvije obično pristranost preferencijom:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item \emphasize{Model} ili prostor hipoteza. Model $\set H$ je skup funkcija $h$  parametriziranih parametrima $\vec\theta$: $\set H=\cbr{h(\vec x;\vec{\theta})}_{\vec{\theta}}$.
	\item \emphasize{Funkcija pogreške} ili ciljna funkcija. Funkcija pogreške $E(\vec{\theta,\set D})$ na temelju parametara modela (hipoteze) i skupa podataka izračunava broj koji izražava procjenu dobrote hipoteze. Obično pretpostavljamo da su primjeri iz skupa za učenje nezavisni i definiramo \emphasize{funkciju gubitka} $\funcdef{L}{\set Y\times\set Y}{\R}$, kojoj je prvi parametar predikcija hipoteze, a drugi ciljna oznaka koja odgovara ulaznom primjeru. Funkciju pogreške možemo definirati kao prosječni gubitak na skupu za učenje:
	\begin{align}
	E(\vec{\theta,\set D})=\frac{1}{\envert{\set D}}\sum_{(\vec x,\vec y)\in\set D} L(\vec y,h(\vec x;\vec{\theta})) \text{.}
	\end{align}
	Obično joj dodajemo \emphasize{regularizacijski} član kojim unosimo dodatne pretpostavke radi postizanja bolje generalizacije. Više o funkciji pogreške u smislu smanjivanja empirijskog i strukturnog rizika piše u odjeljku~\ref{sec:minimizacija-rizika}.
	\item \emphasize{Optimizacijski postupak}. Optimizacijski postupak je algoritam kojim pronalazimo hipotezu koja minimizira pogrešku:
	\begin{align}
	\vec\theta^* = \argmin_{\vec{\theta}} E(\vec{\theta,\set D}) \text{.}
	\end{align}
	Kod nekih jednostavnijih modela minimum možemo odrediti analitički. Inače moramo koristiti neki iterativni optimizacijski postupak. Kod nekih složenijih modela, kao što su neuronske mreže, funkcija pogreške nije unimodalna i vjerojatnost pronalaska globalnog optimuma je zanemariva, ali ipak se mogu pronaći dobra rješenja.
\end{enumerate}

U literaturi riječ \textit{model} često ima šire značenje. Uz skup hipoteza obično obuhvaća i induktivnu pristranost ili dio nje. Model u tom smislu bi se formalno mogao definirati kao par $(\set H, B)$, gdje je $\set H$ skup mogućih hipoteza, a $B$ induktivna pristranost koja hipotezama dodjeljuje različite važnosti. Npr. za regresiju $\set H$ može biti skup polinoma stupnja $4$, a $B$ pretpostavka da primjeri imaju razdiobu $\p(\rvar y\mid x)=\mathcal{N}(h(x),1)$, gdje je $h$ nepoznata hipoteza. Ovdje će se u nastavku koristiti takvo značenje riječi \textit{model}, a riječ \textit{prostor hipoteza} će se koristiti sa značenjem modela u užem smislu.


\section{Kapacitet modela, podnaučenost i prenaučenost}

Cilj algoritama strojnog učenja je postići malu \emphasize{pogrešku generalizacije}, tj. malo očekivanje pogreške na primjera koji nisu korišteni za učenje i odabir modela. Generalizacijska pogreška se procjenjuje pogreškom na skupu podataka koji nije korišten za učenje. Obično pretpostavljamo da su skupovi primjera koje koristimo za učenje, odabir modela i testiranje generirani međusobno nezavisno i iz iste razdiobe.

\emphasize{Kapacitet} ili složenost modela je svojstvo koje opisuje njegovu sposobnost prilagodbe podacima. Model koji se previše prilagođava podacima za učenje (i statističkom šumu u njima) obično ima slabu prediktivnu moć. Treba odabrati model (ili hipotezu) koji dobro objašnjava podatke, ali nije previše složen. O tome govori i načelo \emphasize{Occamove oštrice} prema kojem među hipotezama konzistentnima s opažanjem treba odbaciti sve osim najjednostavnije od njih. Postoje formalizacije Occamove oštrice \citep{Blumer:1987:OR,Blumer:1989:LVCD,Gruenwald:2005:TIMDL,Ratmanner:2011:PTUI}. Na ograničavanje složenosti modela možemo utjecati ograničavanjem prostora hipoteza i regularizacijom (\textit{mekim} ograničavanjem).

Model s većim kapacitetom (složeniji model) može postići manju pogrešku na skupu za učenje. Prevelik kapacitet povećava pogrešku generalizacije. Za model koji daje veliku pogrešku generalizacije kažemo da je \emphasize{prenaučen}. Kod takvog modela hipoteze će jako varirati u ovisnosti o skupu za učenje i zato kažemo da složeni modeli imaju visoku varijancu. Model premalog kapaciteta (prejednostavan model) ima manju razliku između pogreške na skupu za učenje i pogreške na skupu za testiranje, ali su obje pogreške veće od optimalnih. Za model koji ne postiže malu pogrešku na skupu za učenje kažemo da je \emphasize{podnaučen}. U jednostavan model ugrađene su jače pretpostavke i kažemo da on ima jaču pristranost. Uobičajena ovisnost pogrešaka na skupovima za učenje i testiranje o kapacitetu ilustrirana je slikom~\ref{fig:generalizacija}.

\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{generalizacija}
	\caption{Ovisnost pogrešaka na skupovima za učenje i testiranje o kapacitetu modela. Povećavanjem kapaciteta povećava se razlika između pogrške ne skupu za testiranje i pogreške na skupu za učenje.}
	\label{fig:generalizacija}
\end{figure}


\section{Rizik i funkcija pogreške} \label{sec:minimizacija-rizika}

Dijelovi ovog odjeljka temelje se na \citet[podjeljak 6.5]{Murphy:2012:MLPP}.

\subsection{Rizik i empirijski rizik}

Zadatak nadziranog strojnog učenja može se formulirati kao optimizacijski problem minimizacije \emphasize{rizika}. Neka su $\vec\theta$ odabrani parametri. Definiramo \emphasize{funkciju gubitka} $\funcdef{L}{\set{Y}\times\set{Y}}{\R}$ koja kažnjava neslaganje izlaza sa stvarnom oznakom. \emphasize{Rizik} definiramo kao očekivanje funkcije gubitka:
\begin{align}
R(\vec\theta; \mathcal{D}) = \E_{(\vec x,\vec y)\sim\mathcal{D}} L(\vec y,h(\vec x;\vec\theta)) \text{.}
\end{align}
Razdioba koja generira podatke nije poznata, pa se koristi \emphasize{empirijski rizik} koji \emphasize{prirodnu razdiobu} $\mathcal{D}$ procjenjuje \emphasize{empirijskom razdiobom}, tj. uzorkom $\set{D}$:
\begin{align}
R_\text{E}(\vec\theta;\set{D}) 
= \E_{(\vec x,\vec y)\sim\set D} L(\vec y,h(\vec x;\vec\theta)) 
= \frac{1}{\envert{\set{D}}} 
\sum_{(\vec x, \vec y)\in\set{D}} L(\vec y,h(\vec x;\vec\theta)) \text{.}
\end{align}
Što je uzorak veći $\set D$, sličniji je prirodnoj razdiobi i procjena rizika je bolja. U slučaju nenadziranog učenja, kada se hipoteza sastoji od kodera $E$ i dekodera $D$, tj. $h(\vec x;\theta) = E(D(\vec x;\theta);\theta)$, ili generativnog modela, kada je $h(\vec x;\theta) = \p(\vec x\mid\theta)$, gubitak mjeri \emphasize{pogrešku rekonstrukcije} i izraz za rizik je \citep{Murphy:2012:MLPP}:
\begin{align}
R(\rvec\theta;\mathcal{D}) = \E_{\vec d\sim\mathcal{D}} L(\vec d,h(\vec d;\vec\theta)) \text{.}
\end{align}

Kod probabilističkih modela empirijski rizik se može definirati kao \emphasize{negativni logaritam izglednosti} parametara:
\begin{align}
R_\text{E}(\vec\theta;\set D) 
= -\frac{1}{\envert{\set D}}\ln\p(\set{D}\mid\vec\theta) 
= -\frac{1}{\envert{\set D}}\sum_{\vec d\in\set{D}} \ln\p(\vec d\mid\vec\theta) \text{,}
\end{align}
gdje je korištena pretpostavka međusobne nezavisnosti primjera. Gubitak je onda $L(\vec d,h(\vec d;\vec\theta)) = -\ln\p(\vec d\mid\vec\theta)$. U slučaju diskriminativnog modela, uz zanemarivanja faktora izglednosti koji ne ovisi o $\vec\theta$ (jednadžba~\eqref{eq:izglednost-diskr}), vrijedi $L(\vec d,h(\vec x;\vec\theta)) = -\ln\p(\vec y\mid\vec x,\vec\theta)$. Minimizacija gubitka definiranog kao negativni logaritam izglednosti ekvivalentna je minimizaciji KL-divergencije ili unakrsne entropije (odjeljak~\ref{sec:teorija-informacije}) s obzirom na empirijsku razdiobu. Zbog toga se takav gubitak još naziva \emphasize{gubitak unakrsne entropije}.

\subsection{Strukturni rizik i regularizacija}

Kada ima malo podataka ili je model previše složen, minimizacija empirijskog rizika dovodi do velike varijance i slabe generalizacije. Procjenitelj koji minimizira empirijski rizik ne uzima u obzir apriornu razdiobu parametara. Radi postizanja bolje generalizacije, funkciji pogreške dodaje se \emphasize{regularizacijski gubitak} $\lambda R_\text{R}(\vec\theta)$, $\lambda\geq0$, koji predstavlja \emphasize{strukturni rizik} koji daje prednost jednostavnijim hipotezama. Funkcija pogreške onda ima ovakav oblik:
\begin{align}
E(\vec\theta;\set{D}) = R_\text{E}(\vec\theta;\set{D}) + \lambda R_\text{R}(\vec\theta) \text{.}
\end{align}
Regularizacijski gubitak obično ovisi samo o parametrima, ali može ovisiti i o podacima \citep{Goodfellow:2016:DL}. 

Ako kao funkciju pogreške koristimo negativni logaritam aposteriorne vjerojatnosti uz pretpostavku međusobne nezavisnosti primjera, funkcija pogreške je
\begin{align}
E(\vec\theta;\set{D}) 
&= -\frac{1}{\envert{\set D}}\ln\p(\vec\theta\mid\set{D}) \\
&= 
\underbrace{-\frac{1}{\envert{\set D}}\ln\p(\set{D}\mid\vec\theta)}_{R_\text{E}(\vec\theta;\set{D})}
\underbrace{-\frac{1}{\envert{\set D}}\ln\p(\vec\theta)}_{\lambda R_\text{R}(\vec\theta)} + C_1
\text{,}
\end{align}
gdje je $C_1=\frac{1}{\envert{\set D}}\ln\p(\set D)$ konstanta koja ne ovisi o $\vec\theta$. Hiperparametar $\lambda$ je onda parametar apriorne razdiobe. Možemo ga ovako izlučiti:
\begin{align}
\ln\p(\vec\theta) \eqqcolon \lambda \ln p_0(\vec\theta) +C_2 = \ln p_0(\vec\theta)^\lambda +C_2 \text{,}
\end{align}
gdje je $p_0$ neka razdioba (funkcija gustoće), a $C_2=-\ln\del{\int_{\vec{\theta'}}p_0(\vec\theta')\dif\vec{\theta'}}$ konstanta koja ne ovisi o $\vec\theta$. Vidi se da $\lambda$ određuje koncentraciju apriorne razdiobe. Povećanje $\lambda$ smanjuje entropiju apriorne razdiobe. Ona postaje koncentriranija i regularizacija jača. Jačom regularizacijom se povećava pristranost i smanjuje varijanca.

Optimalne hiperparametre tražimo postupcima odabira modela (odjeljak~\ref{sec:su-odabir-modela}) kod kojih se za procjenu generalizacije koriste podaci koji nisu korišteni za učenje.


\section{Odabir modela} \label{sec:su-odabir-modela}

Ovaj odjeljak se temelji na \citet[odjeljak 2.6]{Snajder:2014:SU}. 

Performansa modela se mjeri nekom evaluacijskom mjerom. Ona omogućuje usporedbu hipoteza ili modela na nekom skupu podataka. Budući da nas zanima generalizacija, za procjenu generalizacije trebamo koristiti podatke koji nisu korišteni za učenje. Odabir modela se obično svodi na traženje optimalnih \emphasize{hiperparametara}.

\subsection{Unakrsna validacija}

Najjednostavniji način procjenjivanja generalizacije je \emphasize{unakrsna validacija}. Kod unakrsne validacije, skup podatakama dijelima na \emphasize{skup za učenje} i \emphasize{skup za validaciju}. Ako se unakrsna validacija ne koristi za odabir modela, nego za konačnu procjenu generalizacije, onda se skup na kojem se model evaluira naziva \emphasize{skup za testiranje}.

Za dobivanje bolje procjene generalizacije često se koristi $K$-struka unakrsna validacija. Kod \emphasize{$K$-struke unakrsne validacije} skup podataka $\set D$ se podijeli na $K$ dijelova $\set D_i$, $i=1\bidot K$. Model se uči $K$ puta tako da se u $i$-toj iteraciji za skup za validaciju odabere $\set D_i$, a za skup za učenje ostali podaci, $\set D\setminus\set D_i$. Kao konačna procjena generalizacije uzima se prosjek evaluacija iz svih iteracija.

%TODo: bootstrap, MCCV
%\subsection{Bayesovski odabir modela}
% MacKay, Ghahramani
%Neke modele probabilističke moguće je evaluirati bez ponavljanja učenja. 
%TODo
%https://en.wikipedia.org/wiki/Variational_Bayesian_methods
%MLPP 5.3 Bayesian model selection
%\citet{Murray:2005:NEBOR} MacKay % MLPP! 5.3.1 Bayesian Occam’s razor

\subsection{Bayesovska usporedba modela}

Ovaj pododjeljak se temelji na \cite{Murray:2005:NEBOR} i \cite[odjeljak 5.3]{Murphy:2012:MLPP}.

Ako u izraz s desne strane jednadžbe~\ref{eq:posterior-bayes} eksplicitno uključimo ovisnost parametara o modelu, imamo ovo:
\begin{align}
\p(\vec\theta\mid\set D,\set H) 
= \frac{\p(\set{D}\mid\vec\theta,\set H)\p(\vec\theta\mid\set H)}{\p(\set D,\set H)} \text{,}
\end{align}
gdje je $\set D$ skup podataka, $\set H$ model, a $\vec\theta$ parametri. Kao za parametre modela, možemo imati i aposteriornu razdiobu modela:
\begin{align}
\p(\set H\mid\set D) 
= \frac{\p(\set{D}\mid\set H)\p(\set H)}{\p(\set D)} \text{,}
\end{align}
gdje je $\p(\set D)$ konstanta neovisna o modelu. Ako pretpostavimo neinformativnu apriornu razdiobu $\p(\set H)$, modele možemo uspoređivati na temelju marginalnih izglednosti integriranjem po svim mogućim parametrima: $\p(\set{D}\mid\set H)=\int_{\vec\theta}\p(\set{D}\mid\vec\theta,\set H)\p(\vec\theta\mid\set H)\dif\vec\theta$. Složeniji modeli vjerojatnost raspoređuju po većem broju skupova podataka i, ako je model presložen, marginalna izglednost na promatranom skupu će biti mala. To se naziva \emphasize{bayesovska Occamova oštrica} \citep{MacKay:1992:BMAM}.


\section{Osnovni zadaci nadziranog učenja}

Osnovni zadaci nadziranog učenja su \emphasize{klasifikacija} i \emphasize{regresija}. Zadatak klasifikacije je svakom ulaznom primjerima dodjeljivati oznake iz konačnog skupa oznaka, npr. $\cbr{1\bidot C}$, gdje svaka oznaka predstavlja jednu \emphasize{klasu} (\emphasize{razred}). Zadatak regresije je ulaznim primjerima dodjeljivati vrijednosti iz kontinuiranog skupa (obično $\R$ ili $\R^n$). Ulazni primjeri su obično realni vektori. Klasifikacijska hipoteza se može definirati preko funkcije s kontinuiranom kodomenom. Ako $C=2$, ta funkcija može biti $\funcdef{h}{\set X}{\R}$, a hipoteza $h_\text{c}(\vec x)=\enbbracket{h(\vec x)>0}$. Ako $C>2$, onda to može biti npr. $h_\text{c}(\vec x)=\argmax_i h_i(\vec x)$, gdje $\funcdef{h}{\set X}{\R^C}$ i $h(\vec x)=\sbr{h_i(\vec x)}_{i=1\bidot C}^\tp$. Kod nekih zadataka ulazi ili izlazi imaju složeniju strukturu i ona se može razlikovati između različitih primjera.

\iffalse
%klasifikacija, odnos mF1 i mIoU
%https://www.wolframalpha.com/input/?i=z+%3D+2%2F(1%2Fx%2B1%2Fy)+for+x+in+%5B0,1%5D,+y+in+%5B0,1%5D
%https://www.wolframalpha.com/input/?i=z+%3D+1%2F(1%2Fx%2B1%2Fy-1)+for+x+in+%5B0,1%5D,+y+in+%5B0,1%5D
%https://www.wolframalpha.com/input/?i=z+%3D+2%2F(1%2Fx%2B1%2Fy)%2F(1%2F(1%2Fx%2B1%2Fy-1))+for+x+in+%5B0,1%5D,+y+in+%5B0,1%5D
%https://www.wolframalpha.com/input/?i=z+%3D+2%2F(1%2Fx%2B1%2Fy)-(1%2F(1%2Fx%2B1%2Fy-1))+for+x+in+%5B0,1%5D,+y+in+%5B0,1%5D
% IoU i F1 su ekvivalnetne mjera ako se radi mikro usrednjavanje, 
%https://stats.stackexchange.com/questions/273537/f1-dice-score-vs-iou
\subsection{Primjeri evaluacijskih mjera}

%TODO

\subsubsection{Klasifikacija}

%TODO
\fi

\section{Primjeri modela: poopćeni linearni modeli} \label{sec:poopceni-linearni-modeli}

Ovaj odjeljak se temelji na \citet[odjeljak 6.1]{Snajder:2014:SU} i \citet{Snajder:2017:SULR2}.

\emphasize{Linearni modeli} su modeli kod kojih je hipoteza definirana afinom transformacijom:
\begin{align}
h(\vec x) = h(\vec x;\vec\theta) = \vec w^\tp\vec x + b \text{,}
\end{align}
gdje je $\vec w$ vektor \emphasize{težina}, $b$ \emphasize{pomak} (engl \textit{bias}), a $\vec\theta=(\vec w, b)$. Kod linearnih modela je, u slučaju klasifikacije, granica $(n-1)$-dimenzionalna hiperravnina s normalom $\vec w$. Obično se na ulazne primjere primjenjuje neka nelinearna transformacija
\begin{align*}
\phi \colon \R^n &\to \R^m \\
\vec x &\mapsto \sbr{\phi_1(\vec x),\bidot,\phi_m(\vec x)}^\tp
\end{align*}
koja predstavlja preslikavanje ulaznog prostora u \emphasize{prostor značajki}. Funkcije $\funcdef{\phi_i}{\R^n}{\R}$ nazivaju se \emphasize{bazne funkcije}. Hipoteza linearnog modela onda ima oblik
\begin{align}
h(\vec x) = \vec w^\tp\phi(\vec x) \text{.}
\end{align}
Ovdje je izostavljen pomak $b$ jer jedan od izlaza transformacije $\phi$ može biti konstanta $1$ koja se množi s jednom težinom iz $\vec w$. 

\emphasize{Poopćeni linearni modeli} su modeli kod kojih je hipoteza ovako definirana:
\begin{align} \label{eq:poopceni-linearni-model}
h(\vec x) = f(\vec w^\tp\phi(\vec x)) \text{.}
\end{align}
U odnosu na linearne modele, oni još imaju \emphasize{prijenosnu} (\emphasize{aktivacijsku}) funkciju $\funcdef{f}{\R}{\R}$. Ako je $f$ nelinearna, model je nelinearan u parametrima, ali granica klasifikacijskog modela je i dalje hiperravnina.

Slijedi pregled nekih linearnih modela prema \citet{Snajder:2017:SULR2}:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
\item \emphasize{Linearna regresija}:
\begin{align*}
h(\vec x;\vec w) &= \vec w^\tp\phi(\vec x), \\
\p(y\mid\vec x,\vec w) &= \mathcal{N}(h(\vec x),\sigma^2)(y), \\
L(y, h(\vec x)) &= \del{h(\vec x)-y}^2, \\
\nabla_{\vec w}L(y, h(\vec x)) &= \del{h(\vec x)-y}\phi(\vec x),
\end{align*}
gdje $y\in\R$.
\item \emphasize{Logistička regresija}:
\begin{align*}
h(\vec x;\vec w) &= \sigma(\vec w^\tp\phi(\vec x)) = \P(\rvar y=1\mid\vec x,\vec w), \\
\P(y\mid\vec x,\vec w) &= h(\vec x)^y(1-h(\vec x))^{1-y}, \\
L(y, h(\vec x)) &= -y\ln h(\vec x)^y-(1-y)\ln(1-h(\vec x)), \\
\nabla_{\vec w}L(y, h(\vec x) &= \del{h(\vec x)-y}\phi(\vec x),
\end{align*}
gdje $y\in\cbr{0,1}$, a $\sigma(s)\coloneqq\frac{1}{1+\exp\del{s}}$ \emphasize{logistička funkcija}.
\item \emphasize{Višeklasna logistička regresija}:
\begin{align*}
h(\vec x;\vec W) &= \softmax(\vec W\phi(\vec x)) = \sbr{\P(y=k\mid\vec x,\vec w)}_{k=1\bidot C}^\tp, \\
\P(y\mid\vec x,\vec w) &= h_y(\vec x) = \prod_k h_k(\vec x)^\enbbracket{y=k}, \\
L(y, h(\vec x)) &= -\sum_k \enbbracket{y=k}\ln h(\vec x)^\enbbracket{y=k}, \\
\nabla_{\del{\vec W_\ind{k,:}}^\tp}L(y, h_k(\vec x)) &= \del{h_k(\vec x)-y_k}\phi(\vec x) \\
\nabla_{\vec W}L(y, h(\vec x)) &= \phi(\vec x)^\tp \del{h(\vec x)-\cvec e_y} \text{,}
\end{align*}
gdje $y\in\cbr{1\bidot C}$, $\softmax(\vec s)\coloneqq\frac{1}{\cvec 1^\tp\exp(\vec s)}\exp(\vec s)$, $h(\vec x)=\sbr{h_k(\vec x)}_{k=1\bidot C}^\tp$, $\funcdef{h_i}{\R^n}{\R}$, a $\cvec e_k$ označava jednojedinični vektor (vektor kanonske baze) s elementima $\cvec {e_k}_\ind{i}\coloneqq\enbbracket{i=k}$.
\end{enumerate}
Funkcije gubitka su definirane kao negativni logaritam izglednosti, $L(y, h(\vec x))=-\ln\P(y\mid\vec x,\vec w)$, i konveksne su. Optimalne težine linearne regresije mogu se analitički izračunati, logistička regresija i višeklasna logistička regresija se obično uče optimizacijskim postupcima temeljenim na gradijentu.

Razdiobe $\P(\rvec y\mid\vec x,\vec w)$ poopćenih linearnih modela spadaju u \emphasize{eksponencijalnu familiju razdioba}. Može se pokazati da je to jedina familija razdioba za koje postoje konjugatne apriorne razdiobe, što pojednostavljuje računanje aposteriorne razdiobe \citep{Murphy:2012:MLPP}. Opći oblik ekponencijalne familije i više o njenim svojstvima i svojstvima poopćenih linearnih modela može se naći u \citet{Murphy:2012:MLPP}.



\chapter{Duboko učenje i konvolucijske mreže} \label{chap:duboko-ucenje-i-konvolucijske-mreze}

Na ovaj odjeljak imaju utjecaj \citet{Goodfellow:2016:DL} i predavanja iz predmeta \textit{\href{http://www.zemris.fer.hr/~ssegvic/du/}{Duboko učenje}}.

Klasični (plitki) modeli strojnog učenja (npr. poopćeni linearni modeli) oslanjaju se na kvalitetne značajke, tj. funkciju $\phi$ koja transformira ulazne primjere u vektore značajki. Za neke zadatke koji uključuju visokodimenzionalne primjere sa složenom strukturom (npr. slike, tekst i zvuk) ručno konstruiranje transformacije koja bi bila dovoljno dobra nije izvedivo. Ni jezgrene metode kod kojih se preslikavanje temelji na pretpostavci sličnosti primjera bliskih u ulaznom prostoru ne generaliziraju dobro zbog \emphasize{prokletstva dimenzionalnosti} \citep{Bengio:2005:CDLKM}. Kod \emphasize{dubokog učenja} \citep{LeCun:2015:DL,Goodfellow:2016:DL} transformacija $\phi$ se uči.

Odabirom 
\begin{align}
\phi(\vec x) 
= \phi(\vec x;\vec \theta_\text{h})
= f(\vec W_\text{h}\vec x + \vec b_\text{h}) \text{,}
\end{align}
gdje je $\vec W_\text{h}$ matrica težina, $\vec b_\text{h}$ vektor pomaka, $\vec\theta_\text{h}=(\vec W_\text{h},\vec b_\text{h})$ a $f$ nelinearna prijenosna (aktivacijska) funkcija koja se primjenjuje na svaki element vektora posebno, dobiva se jednostavna \emphasize{umjetna neuronska mreža} (ovdje će se koristiti kraći nazivi: \textit{neuronska mreža} ili \textit{mreža}) s jednim \emphasize{skrivenim slojem} kojem odgovara funkcija $\phi$. Ako to uvrstimo u jednadžbu poopćenog linearnog modela (jednadžba~\eqref{eq:poopceni-linearni-model}):
\begin{align}
h(\vec x; \vec{\theta}) 
= f(\vec w^\tp f(\vec W_\text{h}\vec x + \vec b_\text{h})+b) \text{,}
\end{align}
ili, ako je izlaz vektor,
\begin{align} \label{eq:jednonslojna-nm}
h(\vec x; \vec{\theta}) 
= f(\vec W_\text{o} f(\vec W_\text{h}\vec x + \vec b_\text{h})+\vec b_\text{o}) \text{,}
\end{align}
gdje $\vec\theta=(\vec W_\text{h},\vec b_\text{h}, \vec W_\text{o},\vec b_\text{o})$. Jedinice neuronske mreže kojima odgovaraju operacije oblika $\vec x \mapsto f(\vec w_i^\tp\vec x+b_i)$ nazivaju se \emphasize{umjetni neuroni}. Uz taj naziv, ovdje će se još koristiti naziv \emphasize{jedinica}. Model umjetnog neurona prikazan je na slici~\ref{fig:umjetni-neuron}.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\def\inp{\_}
	
	\node[nrect] (x1) {$x_1$};
	\node[nrect] (x2) [below=of x1] {$x_2$};
	\node[nrect,draw=none] (xdots) [below=of x2] {};
	\node[nrect] (xn) [below=of xdots] {$x_n$};
	\path (x2) -- node[auto=false]{\vdots} (xn);
	
	\node[nrect] (w1) [right=of x1] {$w_1\inp$};
	\node[nrect] (w2) [below=of w1] {$w_2\inp$};
	\node[nrect,draw=none] (wdots) [below=of w2] {};
	\node[nrect] (wn) [below=of wdots] {$w_n\inp$};
	\path (w2) -- node[auto=false]{\vdots} (wn);	
	\foreach \i in {1,2,n}
	\path (x\i) edge [dedge] (w\i);
	\node[nrect] (b) [below=of wn] {$b$};
	
	\node[nrect] (+) [right=15mm of wdots] {$+$};	
	\foreach \i in {1,2,n}
	\path (w\i) edge [dedge] (+);
	\path (b) edge [dedge] (+);
	
	\node[nrect] (f) [right=of +] {$f$};
	\path (+) edge [dedge] (f);
	\node[above=0 of f] {$y$};
	\end{tikzpicture}
	\caption{Grafički prikaz umjetnog neurona. $w\_$ označava da se u $w$ množi s ulazom čvora.}
	\label{fig:umjetni-neuron}
\end{figure}

Za razliku od modela opisanih u odjeljku~\ref{sec:poopceni-linearni-modeli}, za ovakav i dublje modele opisane u sljedećim odjeljcima ciljna funkcija nije konveksna (ni unimodalna), pa nije garantirano da će postupak učenja pronaći dobru hipotezu. Empirijski rezultati ipak pokazuju da duboke mreže uz neke prilagodbe uspješno uče i generaliziraju. Algoritmi koji se koriste za učenje modela dubokog učenja temelje se na gradijentnom spustu. Oni su opisani u odjeljku~\ref{sec:du-ucenje}.


\section{Duboke unaprijedne mreže}

Može se pokazati da model mreže s jednim skrivenim slojem opisan jednadžbom~\eqref{eq:jednonslojna-nm}, ako je dimenzija skrivenog sloja dovoljno velika, može s proizvoljno malom greškom aproksimirati svaku neprekinutu funkciju kojoj je domena konveksni podskup od $\R$. O tome govori teorem o univerzalnoj aproksimaciji \citep{Cybenko:ASSF:1989,Leshno:1993:MFFNWNPA}. Aktivacijska funkcija mora biti nelinearna jer kompozicija linearnih funkcija je linearna funkcija. Teorem o univerzalnoj aproksimaciji ne govori o tome hoće li takav model generalizirati. Dodavanjem jedinica u skriveni sloj povećava se kapacitet modela.

Obična neuronska mreža može imati više skrivenih slojeva, što se može prikazati kao na slici~\ref{fig:neuronska-mreza} ili apstraktnije, kao na slici~\ref{fig:racunski-graf}. Povećavanjem broja skrivenih slojeva svaka jedinica u nekom sloju može koristiti izlaze svih jedinica prethodnog sloja kao značajke, što mreži omogućuje da, u odnosu na mrežu s $1$ skrivenim slojem, s manje jedinica modelira funkcije u kojima postoje uzorci koji se ponavljaju i imaju hijerarhijsku strukturu \citep{Goodfellow:2016:DL}. Posebne vrste dubokih modela koji uz to iskorištavaju još neke pretpostavke su zato jako uspješne u zadacima u vezi slika, zvuka, teksta i drugih signala. Niži slojevi služe višim slojevima kao značajke transformiranjem kojih se dobivaju značajke više razine.

\begin{figure}
\centering
\begin{tikzpicture}[->,draw=black!100, node distance=\layersep]
	\definecolor{lcolor}{RGB}{210,230,230}
	\definecolor{inputcolor}{RGB}{0,0,0}	
	\pgfdeclarelayer{background}
	\pgfsetlayers{background,main}
	\tikzstyle{every pin edge}=[<-,shorten <=1pt]
	\tikzstyle{neuron}=[circle, minimum size=7mm, draw=black!100, fill=white]
	\tikzstyle{layer}=[rectangle, fill=lcolor, minimum size=17pt, inner sep=3pt, outer sep=0pt]
	\def\layersep{2cm}
	\def\inputsize{3}
	\def\hiddensize{4}
	
	% Draw the input layer nodes
	\foreach \name/\y in {1,...,\inputsize} % the same as \foreach \name / \y in {1/1,2/2,3/3,4/4}
	\node[neuron, pin=left:$x_\y$] (I-\name) at (0,-\y) {};
	% Draw the hidden layer nodes
	\foreach \layer in {1,2}
	 \foreach \name/\y in {1,...,\hiddensize}
	  \path[yshift=0.5cm] node[neuron] (H-\layer-\name) at (\layer*\layersep,-\y cm) {};
	% Draw the output layer nodes
	\foreach \name/\y in {1,2}
	 \path[yshift=-0.5cm] node[neuron,pin={[pin edge={->}]right:$\hat{y}_\y$}] (O-\name) at (3*\layersep,-\y cm) {};
	% Connect every node in the input layer with every node in the hidden layer.
	\foreach \source in {1,...,\inputsize}
	 \foreach \dest in {1,...,\hiddensize}
	  \path (I-\source) edge (H-1-\dest);
	% Connect every node in the input layer with every node in the hidden layer.
	\foreach \source in {1,...,\hiddensize}
	 \foreach \dest in {1,...,\hiddensize}
	  \path (H-1-\source) edge (H-2-\dest);
	% Connect every node in the hidden layer with the output layer
	\foreach \source in {1,...,\hiddensize}
	 \foreach \dest in {1,2}
	  \path (H-2-\source) edge (O-\dest);
	
	\begin{pgfonlayer}{background}
	 \node[layer, fit=(H-1-1) (H-1-\hiddensize)] {};
	 \node[layer, fit=(H-2-1) (H-2-\hiddensize)] {};
	 \node[layer, fit=(O-1) (O-2)] {}; 
	\end{pgfonlayer}
\end{tikzpicture}
\caption{Prikaz primjera troslojne mreže. Svakom bridu odgovara jedna težina (pomaci nisu prikazani). Slojevi su označeni plavim četverokutima. Čvorovi koji su unutar četverokuta mreže predstavljaju umjetne neurone. Slika je napravljena prema \url{http://www.texample.net/tikz/examples/neural-network/}.}
\label{fig:neuronska-mreza}
\end{figure}

\begin{figure}
	\centering
	\begin{tikzpicture}
	\def\inp{\_}
	\node[nrect] (x) {$\vec x$};
		\node[above=0 of x] {$\vec x$};
	\node[nrect] (h1a) [right=of x] {$\vec W_1\inp+\vec b_1$};
		\node[above=0 of h1a] {$\vec a_1$};
	\node[nrect] (h1f) [right=of h1a] {$f_\text{h}$};
		\node[above=0 of h1f] {$\vec h_1$};
	\node[nrect] (h2a) [right=of h1f] {$\vec W_2\inp+\vec b_2$};
		\node[above=0 of h2a] {$\vec a_2$};
	\node[nrect] (h2f) [right=of h2a] {$f_\text{h}$};
		\node[above=0 of h2f] {$\vec h_2$};
	\node[nrect] (oa) [right=of h2f] {$\vec W_3\inp+\vec b_3$};
	\node[nrect] (y) [right=of oa] {$f_\text{o}$};
		\node[above=0 of oa] {$\vec a_3$};
	\node[above=0 of y] {$\hat{\vec y}=h(\vec x)$};
	\path (x) edge [dedge] (h1a);	
	\path (h1a) edge [dedge] (h1f);
	\path (h1f) edge [dedge] (h2a);
	\path (h2a) edge [dedge] (h2f);
	\path (h2f) edge [dedge] (oa);
	\path (oa) edge [dedge] (y);
	\end{tikzpicture}
	\caption{Prikaz troslojne mreže kao računskog grafa. Čvorovi predstavljaju funkcije s parametrima, a bridovi podatke (vektore) čije su oznake prikazane uz neke od čvorova iz kojih izlaze. Funkcije su označene oznakom funkcije (aktivacijska funkcija) ili definicijom (afina transformacija). Ulaz sloja označen je s $\_$, a oznake varijabli koje pripadaju čvorovima (ulaz u ulaznom čvoru i parametri u čvorovima afine transformacije) nisu podvučene.}
	\label{fig:racunski-graf}
\end{figure}

Kao prijenosna funkcija skrivenih slojeva često se koristi \emphasize{zglobnica} (\emphasize{ReLU}, engl. rectified linear unit) $\ReLU(x)=\max(0, s)$ za koju se empirijski pokazalo da ima prednosti nad funkcijama koju su prije bile češće korištene \citep{Glorot:2011:DSRNN}. Prije su češće bile korištene \emphasize{logistička funkcija}, $\sigma(s)=\frac{\exp(s)}{1+\exp(s)}$, i \emphasize{tangens hiperbolni}, $\tanh(x)=\frac{\exp(s)-\exp(-s)}{\exp(s)+\exp(-s)}$. Na slici \ref{fig:prijenosne-funkcije} prikazani su grafovi nekih prijenosnih funkcija.

U izlaznom sloju obično se koriste funkcije korištene kod poopćenih linearnih modela (odjeljak~\ref{sec:poopceni-linearni-modeli}) uz istu probabilističku interpretaciju --- identitet za regresiju, logistička funkcija za binarnu klasifikaciju, a softmaks, $\softmax(\vec s)=\frac{1}{\cvec 1^\tp\exp(\vec s)}\exp(\vec s)$, koji kao izlaz daje normalizirani vektor koji predstavlja razdiobu, za višeklasnu klasifikaciju. 

\begin{figure}
	\centering
	\includegraphics[width=1\linewidth]{transfer-functions}
	\caption[s]{Primjeri prijenosnih funkcija.}
	\label{fig:prijenosne-funkcije}
\end{figure}

Dosad opisivane mreže nazivaju se \emphasize{unaprijedne mreže} (engl. \textit{feedforward networks}) zato što se pri izračunu informacija propagira od ulaza prema izlazu, bez povratnih veza. Za mrežu kažemo da je duboka ako ime veći broj slojeva. Struktura duboke unaprijedne mreže ne mora se sastojati samo od niza afinih transformacija i nelinearnosti. Općenito, mrežu možemo predstaviti \emphasize{računskim grafom}, tj. usmjerenim acikličkim grafom kod kojega čvorovi predstavljaju varijable ili računske operacije i njihove izlaze, a bridovi označavaju ovisnosti, tj. koji čvor je ulaz kojeg čvora. Svaki čvor koji nije ulazni čvor predstavlja funkciju koju ostvaruje podgraf koji čine njegovi preci, pa ga možemo poistovjetiti s funkcijom čiji su parametri svi ulazni čvorovi iz skupa čvorova predaka. Čvorovi koji nemaju roditelje su varijable koje čine ulazi i parametri. Parametri se mogu dijeliti, tj. mogu biti ulaz većem broju čvorova kao i svi drugi čvorovi. Čvorovi koji nemaju djecu su izlazi računskog grafa. Na slici \ref{fig:umjetni-neuron} i \ref{fig:racunski-graf} su prikazani takvi grafovi s različitim razinama apstrakcije. U njima, radi sažetosti, parametri nemaju zasebne čvorove, nego su označeni unutar čvorova koji o njima ovise.

\section{Učenje} \label{sec:du-ucenje}

Cilj učenja je pronaći parametre $\vec\theta$ koji minimiziraju pogrešku
\begin{align}
E(\vec\theta;\set D) = \frac{1}{\envert{\set D}}\sum_{(\vec x_i,\vec y_i)\in\set D} L(\vec y_i,h(\vec x_i;\vec\theta)) + \lambda R_\text{R}(\vec\theta)
\end{align}
i postići dobru generalizaciju. Duboki modeli se obično uče algoritmima koji se temelje na gradijentnom spustu. Gradijent pogreške s obzirom na parametre je
\begin{align} \label{eq:gs-ucenje}
\nabla_{\vec\theta}E(\vec\theta;\set D) = \frac{1}{\envert{\set D}}\sum_{(\vec x_i,\vec y_i)\in\set D} \nabla_{\vec\theta}L(\vec y_i,h(\vec x_i;\vec\theta)) + \lambda \nabla_{\vec\theta}R_\text{R}(\vec\theta) \text{.}
\end{align}
Kod dubokih mreža, tj. usmjerenih acikličkih računskih grafova, gradijent se računa \emphasize{algoritmom propagacije pogreške unatrag} \citep{Rumelhart:1986:LIREP} koji se temelji na \emphasize{pravilu deriviranja kompozicije funkcija} i \emphasize{dinamičkom programiranju}. 

U ovom odjeljku su kratko opisane ideje korištene za efikasno računanje gradijenta i optimizacijski postupci koji se koriste za pronalaženje dobrih parametara kod dubokih mreža.

\subsection{Algoritam propagacije pogreške unatrag}

Na ovaj pododjeljak ima utjecaj \cite{Olah:2015:CCGB}.

Gradijent gubitka nije potrebno analitički računati za svaki parametar posebno. Primjenom pravila deriviranja složene funkcije, derivacija vrijednosti nekog čvora $b$ s obzirom na čvor vrijednost nekog čvora $a\in\pred_G(b)$ jednaka je zbroju umnožaka parcijalnih derivacija svakog djeteta s obzirom na roditelja po svakom putu između $a$ i $b$. Pri tome je put definiran kao niz takav da sljedeći (usmjereni) brid počinje u čvoru u kojem je prethodni završio. Svakom bridu $(p,c)$ odgovara derivacija $\pd{c}{p}$. Derivacije između susjednih čvorova ne moraju se računati za svaki put posebno. Već izračunate derivacije se mogu ponovo koristiti. Isto vrijedi ako su vrijednosti čvorova vektori (ako su višedimenzionalni nizovi, možemo ih svesti na vektore) i ako računamo Jakobijeve matrice. Dalje će se za Jakobijeve matrice isto koristiti riječ \textit{derivacija}.

Algoritam propagacije pogreške unatrag se tako naziva zato što se izračun gradijenta širi od izlaznog čvora (ili čvora koji predstavlja gubitak ili funkciju pogreške) prema njegovim roditeljima, pa prema roditeljima roditelja itd. uz primjenu pravila deriviranja kompozicije funkcija. Pri tome se ne moraju računati gradijenti s obzirom na čvorove koji ne ovise o varijablama za koje se računa gradijent.

Neka je $L$ vrijednost čvora gubitka, a $\vec\theta$ neki parametar. Želimo izračunati gradijent $\nabla_{\vec\theta_i}L=\pd{L}{\vec\theta}^\tp$. Derivacija gubitka s obzirom na čvoru $u$ se može rekurzivno izraziti: 
\begin{align} \label{eq:gradijent-rekurzivno}
\pd{L}{u} = \sum_{c\in\ch_G(u)} \pd{L}{c}\pd{c}{u}	\text{,}
\end{align}
gdje su $c$ djeca čvora $u$. Ako $\pd{L}{c}$ nije izračunat za trenutni ulaz, izračuna se, a inače se koristi prethodno izračunata vrijednost. Ista jednadžba vrijedi za čvorove parametara.

Neka je zadatak nadzirano učenje, $\set D=\cbr{\vec x_i, \vec y_i}_i$ skup podataka za učenje, a $L_i=L(\vec y_i, h(\vec x_i,\vec \theta))$ gubitak para $(\vec x_i, \vec y_i)$. Neka je pogreška npr. $E=\sum_i L_i + R_\text{R}(\vec\theta)$. Onda
\begin{align}
\pd{E}{\vec\theta} 
= \sum_{i} \pd{L_i}{\vec\theta} + \pd{R_\text{R}}{\vec\theta}\del{\vec\theta} \text{,}
\end{align}
gdje se izrazi na desnoj strani računaju rekurzivno uz pamćenje izračunatih gradijenata (ili unaprijed izračunate gradijente koji odgovaraju bridovima u podgrafu koji se sastoji od čvorova potomaka) prema jednadžbi~\ref{eq:gradijent-rekurzivno}.

\subsection{Gradijenti nekih osnovnih operacija}

U tablici~\ref{tab:derivacije} prikazane su parcijalne derivacije (Jakobijeve matrice) nekih operacija s obzirom na njihove ulaze. Korištenjem pravila deriviranja kompozicije funkcija mogu se izračunati derivacije složenijih funkcija. Radi efikasnosti se izračunavanje vrijednosti u računskom grafu i algoritam propagacije pogreške unatrag provodi paralelno za više ulaza odjednom. Izvodi gradijenata nekih operacija uz višestruke ulaze mogu vidjeti npr. ovdje: \url{http://www.zemris.fer.hr/~ssegvic/du/lab0.shtml}. 

\begin{table}
	\centering
	\begingroup
	%\renewcommand*{\arraystretch}{1.4}
	\newcommand{\vertspace}{\rule{0pt}{3ex}}
	\begin{tabular}{l P{0.31\textwidth}}
	%\begin{tabular}{ll}
		\toprule
		\bfseries Operacija & \bfseries Derivacije 
		\\\midrule
		$\vec y = \vec W \vec x + \vec b$,
		& $\pd{\vec y}{\vec x} = \vec W$, \newline
		$\pd{\vec y_\ind{i}}{\del{\vec W_\ind{j,:}}^\tp} = \enbbracket{i=j}\vec x^\tp$, \newline
		$\pd{\vec y}{\vec b} = \cvec I$
		\\\vertspace%\hline
		$\vec y = \vec a \odot \vec b$,
		& $\pd{\vec y}{\vec a} = \diag(\vec b)$, \newline
		$\pd{\vec y}{\vec b} = \diag(\vec a)$
		\\\vertspace%\hline
		$\vec y = \ReLU(\vec x)$
		& $\pd{\vec y_\ind{i}}{\vec x_\ind{j}} = 
		 \enbbracket{i=j} \enbbracket{\vec x_\ind{j}>0} $
		\\\vertspace%\hline
		$\vec y = \sigma(\vec x)$
		& $\pd{\vec y}{\vec x} =
		 \diag\del{\vec y\odot\del{\cvec1-\vec y}}$
		\\\vertspace%\hline
		$\vec y = \tanh(\vec x)$
		& $\pd{\vec y}{\vec x} =	
		 \diag\del{1 - \vec y\odot\vec y}$
		\\\vertspace%\hline
		$\vec y = \softmax(\vec x)$
		& $\pd{\vec y}{\vec x_\ind{j}} = \vec y\odot\del{\cvec e_j-\vec y}$
		\\\vertspace%\hline
		$y = -t\ln\sigma(x)-(1-t)\ln\del{1-\sigma(x)}$
		& $\pd{y}{x} = \sigma(x)-t$
		\\\vertspace%\hline
		$y = -\ln\softmax(\vec x)_\ind{j}$
		& $\pd{y}{\vec x} = \del{\softmax(\vec x)-\cvec e_j}^\tp$
		\\\bottomrule
	\end{tabular}
	\endgroup
	\caption{Parcijalne derivacije (Jakobijeve matrice) nekih operacija po njihovim ulazima. Zadnja sva retke predstavljaju gubitak unakrsne entropije (negativni logaritam izglednosti) za binarnu i višeklasnu klasifikaciju, gdje je $t$ indeks ciljne klase. $\cvec e_t$ označava jednojedinični vektor s elementima ${\cvec e_j}_\ind{i}\coloneqq\enbbracket{i=j}$.}
	\label{tab:derivacije}
\end{table}


\subsection{Stohastička optimizacija} \label{subsec:dukn-stoh-optimizacija}

U pododjeljku~\ref{subsec:gradijenti-spust} opisan je gradijentni spust i neki izvedeni algoritmi koji koriste neke dodatne heuristike. U ovom pododjeljku opisana je primjena tih algoritama u dubokom učenju. Kod učenja dubokih modela se obično koristi puno podataka i iteracija optimizacije se provodi procjenjivanjem gradijenta funkcije pogreške na temelju manjeg dijela skupa za učenje.

Kod \emphasize{stohastičkog gradijentnog spusta} se u nekoj iteraciji gradijentnog spusta umjesto gradijenta pogreške koristi gradijent procjene pogreške na temelju nekog podskupa skupa za učenje ili samo jednog primjera. Takav algoritam naziva se \emphasize{stohastički gradijentni spust}. Moguće je podskupove u svakoj iteraciji ponovo slučajno izvlačiti iz cijelog skupa za učenje $\set D$, ali obično se iteracije podijele na \emphasize{epohe} od kojih se svaka sastoji od $B$ iteracija, u svakoj epohi se skup za učenje slučajno podijeli na $B$ nepreklapajućih podskupova $\set D_i$ jednake veličine, od kojih se svaki koristi u jednoj iteraciji unutar epohe. Skupove $\set D_i$ nazivamo \emphasize{mini-grupe}. U iteraciji $i$ u nekoj epohi koristi se procjena gradijenta
\begin{align} \label{eq:sgs-ucenje}
\nabla_{\vec\theta}E(\vec\theta;\set D_i) = \frac{1}{\envert{D_i}}\sum_{(\vec x_i,\vec y_i)\in\set D_i} \nabla_{\vec\theta}L(\vec y_i,h(\vec x_i;\vec\theta)) + \lambda \nabla_{\vec\theta}R_\text{R}(\vec\theta) \text{.}
\end{align}
i iteracija (prema jednadžbi~\eqref{eq:gs}) ima oblik
\begin{align} \label{eq:sgs}
\vec \theta_i = \vec \theta_{i-1} - \eta\nabla_{\vec\theta}E(\vec\theta;\set D_{i})\text{,}
\end{align}
gdje je $e$ broj epohe, a $i+1$ broj trenutne iteracije unutar epohe.

Prema \citet{Goodfellow:2016:DL}, na odabir veličine mini-grupe utječu:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item Kvaliteta procjene gradijenta. Veće minigrupe daju točniju procjenu gradijenta.
	\item Računska efikasnost. Premale mini-grupe ne iskorištavaju potpuno mogućnost paralelizacije izračuna, a prevelike grupe ne stanu u memoriju.
	\item Optimizacija s manjim mini-grupama ima učinak regularizacije \citep{Wilson:2003:GIBTGDL}, ali zahtijeva manju stopu učenja i sporije konvergira.
\end{enumerate}

Kako bi optimizacijski algoritam konvergirao, treba se smanjivati stopa učenja ovisno o iteraciji (epohi). Prema \cite{Goodfellow:2016:DL}, dovoljan uvjet za konvergenciju gradijentnog spusta je
\begin{align}
\sum_{k=1}^\infty \eta_k=\infty \wedge \sum_{k=1}^\infty \eta_k^2<\infty \text{,}
\end{align}
gdje je $k$ broj iteracije od početka učenja.

Kako bi se ublažio šum procjene gradijenta i ubrzalo učenje, obično se upotrebljava inercija, kao što je opisano u pododjeljku~\ref{subsec:gradijenti-spust}. Empirijski se pokazuje da stohastički gradijentni spust s momentom postiže dobru generalizaciju. U pododjeljku~\ref{subsec:gradijenti-spust} su opisana i dva algoritma koja koriste pokretne prosjeke momenata gradijenta i prilagođeni su stohastičkom učenju s mini-grupama. RMSProp skalira gradijent po elementima korištenjem pokretnog prosjeka kvadrata gradijenta tako da norma elemenata pomaka ne ovisi jako o prosječnoj normi gradijenta u zadnjim iteracijama. Adam koristi inerciju i obavlja skaliranje slično kao RMSProp.


\subsection{Inicijalizacija parametara}

Kod učenja dubokih modela jako je bitna inicijalizacija parametara. Sve težine mreže (ili dijela nje), npr. kao na slici~\ref{fig:neuronska-mreza}, se ne smiju se inicijalizirati konstantnom vrijednošću. Zamjenom dvaju jedinica istog sloja, npr. kao na slici~\ref{fig:neuronska-mreza}, dobiva se ista mreža i gradijent je jednak za sve težine unutar istog sloja, osim za zadnji sloj. To se rješava inicijalizacijom težina nasumičnim vrijednostima. Ako su inicijalizirane težine manje, sporije će se \textit{razbijati} simetrija, a ni prevelike težine nisu dobre. Ako se koriste prijenosne funkcije sa zasićenjem problem mogu biti težine s prevelikom apsolutnim vrijednostima jer mogu uzrokovati zasićenje i tako onemogućavati učenje. Taj problem rješava zglobnica, ali množenjem velikih težina kroz više slojeva daje sve veće izlaze, što kod linearnih slojeva daje prevelik gradijent, što se vidi u tablici~\ref{tab:derivacije}.

Heuristike korištene za inicijalizaciju težina se temelje na aproksimiranju mreže nizom matričnih množenja i postizanju da varijance gradijenata (i izlaza) budu otprilike konstantne kroz mrežu \citep{Goodfellow:2016:DL}. Otprilike konstantna varijanca gradijenta može se ostvariti inicijalizacijom slučajnim vrijednostima iz Guassove ili unifomne razdiobe s varijancom $\frac{1}{n}$, gdje je $n$ broj ulaza. \citet{Glorot:2010:UDTDFNN} kao kompromis između jednake varijance gradijenta i jednake varijance izlaza slojeva predlažu varijancu $\frac{1}{n+m}$, gdje je $m$ broj izlaza \citep{Goodfellow:2016:DL}.

Pomaci se obično inicijaliziraju na neku konstantu.

\subsection{Problem nekonveksnosti funkcije pogreške}

\citet{Goodfellow:2016:DL} navode sljedeće probleme koji se javljaju kod nekonveksne optimizacije:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item \emphasize{Loše kondicioniranje Hesseove matrice}. Loše kondicioniranje Hesseove matrice može biti razlog da i s jako malim korakom učenje funkcija pogreške raste u smjeru gradijenta zato što kvadratni član u Taylorovom rezvoju u jednadžbi~\eqref{eq:grad-delta-approx}  bude pozitivan i prevlada linearni član.
	\item \emphasize{Lokalni minimumi}. I ako se zanemare ekvivalentni lokalni minimumi koji postoje zbog simetričnosti zamjenjivosti položaja neurona u istom sloju i drugih simetričnosti u neurnoskim mrežama, funkcija pogreške ima velik broj lokalnih minimuma. Empirijski se pokazuje da loši lokalni minimumi nisu problem i da nije potrebno pronaći globalni minimum kako bi se dobili dobri rezultati.
	\item \emphasize{Ostale stacionarne točke}. Kod visokodimenzionalnih optimizacijskih problema lokalni minimumi i maksimumi su obično rijetki zato što bi onda sve vlastite vrijednosti Hesseove matrice morale biti istog predznaka. Zato su češće sedlaste točke kod kojih se predznak barem jedne vlastite vrijednosti razlikuje od predznaka ostalih. Empirijski se pokazuje da sedlaste točke kod dubokih mreža nisu velik problem za optimizacijske postupke prvog reda koje ne privlače sedlaste točke. I ako se parametri nalaze točno u sedlastoj točki tako da je gradijent $\cvec 0$, stohastički gradijentni spust može imati drugačije gradijente.
	\item \emphasize{Litice i eksplodirajući gradijenti}. Kod nekih modela javlja se problem velikih vrijednosti gradijenta u nekim točkama. To se može riješiti ograničavanjem norme gradijenta.
\end{enumerate}


\section{Regularizacija i poboljšavanje učenja}

U ovom pododjeljku opisani su neki od češćih postupaka koji se koriste za poboljšavanje učenja, tj. postizanja bolje generalizacije i bržeg učenja. Dijelovi ovog pododjeljka temelje se na \citet{Goodfellow:2016:DL}, gdje se može naći opširniji i dublji pregled.

\subsection{Kažnjavanje norme težina}

Najjednostavniji način regularizacije je kažnjavanje norme težina. Regularizacijski dio funkcije pogreške $R_\text{R}$ se najčešće definira kao kvadrat $L^2$ norme, tj. koristi se \emphasize{$L^2$ regularizacija} koja odgovara apriornoj pretpostavci Gaussove razdiobe težina s dijagonalnom kovarijacijskom matricom i očekivanjem $\vec 0$. Može se koristiti i \emphasize{$L^1$ regularizacija} koja potiče rijetkost težina, tj. postavlja minimum funkcije pogreške u ovisnosti o nekim težinama točno u $0$. To je detaljnije objašnjeno npr. u \citet{Goodfellow:2016:DL}. $L^1$ regularizacija odgovara Laplaceovoj apriornoj razdiobi.  Općenito, gubitak $L^p$ regularizacije ima oblik:
\begin{align}
	R_\text{R}(\vec\theta) 
	= \frac{\lambda}{p}\enVert{\vec\theta}_p^p 
	= \frac{\lambda}{p}\sum_i \envert{\vec\theta_\ind{i}}^p \text{,}
\end{align}
gdje $\lambda$ određuje jačinu regularizacije, tj. koncentraciju apriorne razdiobe. Gustoći apriorne razdiobe odgovara
\begin{align}
\p(\vec\theta) &= \frac{1}{Z}\exp(-R_\text{R}(\vec\theta)) \\
&= \frac{1}{Z}\prod_i\exp\del{-\frac{\lambda}{p}\envert{\vec\theta_\ind{i}}^p} \text{,}
\end{align}
gdje je $Z$ normalizacijska konstanta. Gradijent regularizacijskog gubitka s obzirom na $\vec\theta_\ind{i}$ je $\lambda\sgn(\vec\theta_\ind{i})\envert{\vec\theta_\ind{i}}^{p-1}$. Posebno, to je  $\lambda\vec\theta_\ind{i}$ za $p=2$ i  $\lambda\sgn(\vec\theta_\ind{i})$ za $p=1$.

\subsection{Rano zaustavljanje učenja}

Regularizacijski učinak koji se može usporediti s $L^p$ regularizacijom ima \emphasize{rano zaustavljanje} učenja zato što ograničava koliko se parametri mogu udaljiti od početne vrijednosti. Ako se model predugo uči, može se dogoditi da se težine modela s velikim kapacitetom previše prilagode skupu za učenje i zato dođe do loše generalizacije.

\subsection{Generiranje podataka} \label{subsec:du-generiranje-podataka}

Postupci koji značajno mogu utjecati na generalizaciju su postupci \emphasize{proširivanja skupa podataka}, što znači da se tijekom učenja obično provode jednostavne slučajne transformacije nad primjerima prije nego što se daju kao ulaz modelu. Primjeri transformacija koje se mogu koristiti u računalnom vidu, ovisno o zadatku, su reflektiranje, translacija i rotacija. Generiranje podataka kod zadataka koji imaju veze sa zvukom isto može biti korisno \cite{Goodfellow:2016:DL}.

Dodavanje šuma ulazu isto može biti korisno \citep{Goodfellow:2016:DL}. To odgovara pretpostavci da primjeri koji su slični u ulaznom prostoru trebaju biti slični i u izlaznim prostoru.

\subsection{Isključivanje neurona --- dropout} \label{subsec:dropout}

\emphasize{Dropout} \citep{Hinton:2012:INNPCAFD,Srivastava:2014:DASWPNNO} je postupak regularizacije koji unosi šum u izlaze skrivenih slojeva tijekom učenja. Obično se ostvaruje tako da se tijekom učenja za svaki primjer svaka jedinica mreže isključi s vjerojatnošću $1-p$, koja je hiperparametar. Tijekom testiranja, tj. zaključivanja, sve se jedinice skaliraju s $p$, tj. očekivanjem skaliranja koje je tijekom učenja $0$ s vjerojatnošću $1-p$, a $1$ s vjerojatnošću $p$. \textit{Dropout} se obično primjenjuje nakon afine transformacije (ne nakon aktivacije).

Učenje s \textit{dropoutom} se može interpretirati kao učenje eksponencijalnog broja modela koji dijele parametre, a zaključivanje kao aproksimacija usrednjavanja modela ili aproksimacija bayesovskog zaključivanja. Vremenski zahtjevniji, ali ispravniji postupak usrednjavanja modela bio bi uzorkovanje \citep{Srivastava:2014:DASWPNNO}, tj. \textit{Monte Carlo} aproksimacija izlaza. \citet{Gal:2015:DBA} su dali bayesovsku interpretaciju takvog usrednjavanja. 

Umjesto Bernoullijeve razdiobe, skaliranje ili izlazi jedinica mogu imati npr. Gaussovu razdiobu ili neku drugu.

\subsection{Normalizacija po grupama}

Normalizacija po grupama (engl. \textit{batch normalization}) \citep{Ioffe:2015:BNADNTRUCS} je postupak koji ublažava probleme pri učenju i omogućuje uspješno učenje jako dubokih modela. Prema \citet{Goodfellow:2016:DL}, problem kod učenja jako dubokih modela je što se se sastoje od kompozicije velikog broja funkcija, zbog čega je velika međuzavisnost između parametara različitih slojeva, a u koraku gradijentnog spusta parametri svih funkcija ažuriraju se istovremeno. Gradijenti spust pretpostavlja da je utjecaj svakog parametra lokalno nezavisan, tj. svaka se funkcija (sloj afine transformacije) prilagođava ostatku mreže kakav je u trenutnom koraku, tj. očekuje da se prethodni slojevi neće promijeniti.

U \cite{Goodfellow:2016:DL} je to objašnjeno na pojednostavljenom primjeru $\hat y=xw_1w_2,\bidot,w_j$, gdje su elementi gradijenta $g_i=\nabla_{\vec w_i}\hat y=x\prod_{j\neq i}w_j$. Novi izlaz nakon koraka gradijentnog spusta je $x\prod_i(w_i-\epsilon g_i)$ gdje članovi uz više potencije $\epsilon$ mogu imati utjecaj koji raste eksponencijalno s dubinom $l$.

Sloj normalizacije po grupama se dodaje nakon sloja linearne transformacije (prije prijenosne funkcije). On kod učenja obavlja ovakvu operaciju:
\begin{align} \label{eq:bn}
	\vec Y = \del{\vec X-m(\vec X)}\oslash s(\vec X) \text{,}
\end{align}
gdje je $\vec X=\sbr{\vec x_i}_{i=1\bidot N}^\tp\in\R^{N\times n}$ matrica kojoj su reci vektori značajki pojedinih primjera, $\vec Y=\sbr{\vec y_i}_{i=1\bidot N}^\tp\in\R^{N\times n}$ matrica kojoj su reci značajke normalizirane ulazne značajki, $m(\vec X)\coloneqq\frac{1}{N}\sum_i\vec X_\ind{i,:}\in\R^{1\times n}$ srednja vrijednost vektora značajki, $s(\vec X)\coloneqq\del{\frac{1}{N}\sum_i\del{\vec X_\ind{i,:}-m(\vec X)}^{\odot 2}}^{\odot\frac{1}{2}}\in\R^{1\times n}$ standardna devijacija vektora značajki po elementima. Oduzimanje u jednadžbi~\eqref{eq:bn} je definirano tako da se od svakog retka $\vec X$ oduzima $m(\vec X)$. Takvo značenje ima i dijeljenje. Izlaz sloja normalizacije po grupama tijekom učenja je invarijantan na skaliranje i pomak ulaza $\vec X$, kao i skaliranje težina linearne transformacije koja prethodi normalizaciji po grupama.

Statistike grupe, tj. srednje vrijednosti i standardne devijacije od grupe za koju se provodi zaključivanje, se koriste samo kod učenja. Inače se koriste statistike skupa za učenje koje se mogu procjenjivati pokretnim prosjekom tijekom učenja. Računski graf normalizacije po grupama kod učenja i kod ispitivanja je prikazan na slici \ref{fig:bn-graf}.

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\def\inp{\_}
		\node[nrect] (x) [] {$\vec X$};
		\node[nrect] (s) [above right=0mm and 5mm of x] {$s(\inp)$};
		\node[nrect] (m) [above=of s] {$m(\inp)$};
		\node[above=0 of m] {$\vec\mu$};		
		\node[above=0 of s] {$\vec\sigma$};
		\node[nrect] (bn) [below right=0 and 5mm of s] {$(\vec X-\vec\mu)\oslash\vec\sigma$};
		
		\path (x) edge [dedge] (m);
		\path (x) edge [dedge] (s);
		
		\path (s) edge [dedge] (bn);
		\path (m) edge [dedge] (bn);
		\path (x) edge [dedge] (bn);
		\end{tikzpicture}
		\caption{Graf normalizacije po grupama kod učenja.}
		\label{subfig:bn-ucenje}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\begin{tikzpicture}
		\def\inp{\_}
		\node[nrect] (x) [] {$\vec X$};
		\node[nrect] (s) [above right=0mm and 5mm of x] {$\overline{\vec\sigma}$};
		\node[nrect] (m) [above=of s] {$\overline{\vec\mu}$};

		\node[nrect] (bn) [below right=0 and 5mm of s] {$(\vec X-\overline{\vec\mu})\oslash\overline{\vec\sigma}$};
		
		\path (s) edge [dedge] (bn);
		\path (m) edge [dedge] (bn);
		\path (x) edge [dedge] (bn);
		\end{tikzpicture}
		\caption{Graf normalizacije po grupama kod ispitivanja.}
		\label{subfig:bn-ispitivanje}
	\end{subfigure}
	\caption{Grafovi normalizacije po grupama kod učenja i kod ispitivanja. $m$ i $s$ su funkcije koje računaju srednju vrijednost i standardnu devijaciju grupe. $\overline{\vec\mu}$ je srednja vrijednost, a $\overline{\vec\sigma}$ standardna devijacija ulaza kod skupa za učenje.}
	\label{fig:bn-graf}
\end{figure}

Kako se ne bi izgubila ekspresivnost, nakon sloja normalizacije po grupama obično se dodaje pomak $\vec\beta\in\R^{1\times n}$ i skaliranje $\vec\gamma\in\R^{1\times n}$ svake značajke. $\vec\beta$ i $\vec\gamma$ su parametri koji se uče. Kod ispitivanja je normalizacija po grupama uz skaliranje i pomak samo drugačija parametrizacija koja je uz prethodni sloj linearne transformacije s težinama $\vec W$ može svesti na sloj afine transformacije s težinama $\vec W\oslash\vec\sigma^\tp\odot\vec\gamma^\tp$ i pomacima $-\vec\mu\oslash\sigma\odot\vec\gamma+\vec\beta$.

Kod konvolucijskih mreža se normalizacija po grupama ne provodi samo po dimenziji grupe, nego i po dimenzijama konvolucije, po kojima treba vrijediti translacijska ekvivarijantnost. Npr. ako je ulazni niz dimenzija $N\times H\times W\times C$, gdje je $N$ veličina grupe, $H$ visina slike, $W$ širina slike, a $C$ broj značajki, tj. broj filtara zadnje konvolucije, vektor srednjih vrijednosti i vektor standardnih devijacija je dimenzije $C$, tj. $1\times 1\times 1\times C$.

\subsubsection{Normalizacija po grupama i regularizacija}

Pokazuje se da normalizacija po grupama ima i regularizacijski učinak, vjerojatno zbog stohastičnosti mini-grupa i same reparametrizacije. Zbog neovisnosti izlaza normalizacijskog sloja o skaliranju težina linearnog sloja koji mu prethodi tijekom učenja, $L^2$ regularizacija nema regularizacijski utjecaj na linearne slojeve, ali ima na veličinu koraka učenja u odnosu na težine \citep{Twan:2017:LRBWN}. Pokazuje se da \textit{dropout} uz normalizaciju po grupama često ima slab ili negativan učinak na učenje. \cite{Xiang:2018:UDBDBNVS} to objašnjavaju manjom varijancom tijekom testiranja u odnosu na varijancu tijekom učenja i predlažu izmjene za smanjivanje negativnog učinka.

%\subsection{Dijeljenja parametara, pomoćni gubici i višezadaćno učenje}
%višezadaćno učenje, pomoćni gubici, dijeljenje parametara

\subsection{Neprijateljski primjeri i regularizacija za postizanje otpornosti na njih} \label{subsec:neprijateljski-primjeri}

Ovaj odjeljak se temelji na \cite{Grubisic:2018:IPM}.
 
Pokazalo se da se mogu pronaći ulazni primjeri (npr. slike) koji su u ljudskoj percepciji slični prirodnim primjerima, ali i modeli koji na neizmjenjenim primjerima ostvaruju rezultate usporedive s rezultatima ljudi daju krive predikcije \citep{Szegedy:2013:IPNN,Goodfellow:2014:EHAE}. Takvi ulazni primjeri se nazivaju \emphasize{neprijateljski primjeri}. Oni se mogu dobiti i pomoću jednog koraka gradijentnog spusta pomicanjem ulaznog primjera u smjeru povećavanja gubitka. Na slici~\ref{fig:neprijateljski-primjer} je prikazano generiranje neprijateljskog primjera malom izmjenom izvorne slike.

\begin{figure}
	\centering
	\begin{tabular}{>{\centering\arraybackslash}m{.22\textwidth}m{.5in}>{\centering\arraybackslash}m{.22\textwidth}m{.1in}>{\centering\arraybackslash}m{.22\textwidth}}
		\centering\arraybackslash
		%abs max for panda was 138, eps was 1., so relative eps is ~.007
		\includegraphics[width=.22\textwidth]{adversarial-examples/panda_577.png} &%
		\centering\arraybackslash%
		$ +\ 0.007\ \cdot$ &%
		\includegraphics[width=.22\textwidth]{adversarial-examples/nematode_082.png} &%
		$=$ & %
		\includegraphics[width=.22\textwidth]{adversarial-examples/gibbon_993.png} \\
		$\centering \vec x$     &%
		& $\sgn \nabla_{\vec x} L(y,h(\vec x))$ & & $\tilde{\vec x}$ \\
		\emph{panda} (0.577) & & & & \emph{gibon} (0.993) 
	\end{tabular}
	\caption{Prilagođeni prikaz dobivanja neprijateljskog primjera FGSM-om iz \cite{Goodfellow:2014:EHAE}. Nakošene riječi predstavljaju klase, a brojevi u zagradama vjerojatnosti koje im mreža dodjeljuje.}
	\label{fig:neprijateljski-primjer}
\end{figure}

Neka je $d:\set{X}\times\set{X}$ funkcija udaljenosti u ulaznom prostoru. Za svaki primjer $\vec x$ možemo definirati susjedstvo $B_\epsilon(\vec x) = \cbr{\vec x' \colon d(\vec x',\vec x)\leq\epsilon}$. Pronalaženje neprijateljskih primjera se može definirati kao optimizacijski problem pronalaženja primjera $\tilde{\vec x}$ koji maksimizira gubitak uz ograničenje da se nalazi u susjedstvu $B_\epsilon$ prirodnog primjera $\vec x$:
\begin{equation} \label{eq:neprijateljski-primjer}
\tilde{\vec x} = \argmax_{\tilde{\vec x}\in B_\epsilon(\vec x)} L(y,h(\tilde{\vec x})) \text{.}
\end{equation}
Za funkciju udaljenosti $d$ se obično uzima neka $L^p$-norma razlike. Npr. za $L^\infty$-normu je $B_\epsilon(\vec x) = \{\tilde{\vec x} : \lVert \tilde{\vec x}-\vec x\rVert_\infty\leq\epsilon\}$.

Neprijateljski primjeri mogu se pronaći iterativnim optimizacijskim postupcima prvog reda uz održavanje ograničenja susjedstva. Pokazuje se da je neprijateljske primjere moguće pronaći već samo jednim korakom u smjeru predznaka gradijenta. Jedna vrsta takvog napada je \emph{\textit}{fast gradient sign method} (FGSM) \cite{Goodfellow:2014:EHAE}. Neprijateljskom primjeru koji se pronalazi FGSM-om odgovara sljedeći izraz:
\begin{equation} \label{eq:FGSM}
\tilde{\vec x} = \vec x + \epsilon\sgn \nabla_{\vec x} L(y,h(\vec x)) \text{.}
\end{equation}
\citet{Madry:2017:TDLMRAA} definiraju iterativni postupak koji se temelji na FGSM-u i nazivaju ga \emph{projected gradient descent} (PGD):
\begin{equation} \label{eq:pgd}
\tilde{\vec x}_i = \Pi_{B_\epsilon(\vec x)} \del{\tilde{\vec x}_{i-1} + \alpha\sgn\nabla_{\tilde{\vec x}_{i-1}} L(y,h(\tilde{\vec x}_{i-1}))} \text{.}
\end{equation}
Početni $\tilde{\vec x}$ se bira nasumično unutar $B_\epsilon(\vec x)$. $\alpha$ je veličina koraka optimizacije, a $\Pi_{B_\epsilon(\vec x)}$ označava projekciju na zatvorenu $\epsilon$-kuglu oko prirodnog primjera $\vec x$ uz $L^\infty$-normu. Npr. projekcijom vektora $\vec v$ na susjedstvo vektora $\vec x$, $\Pi_{B_\epsilon(\vec x)}(\vec v) = \argmin_{\vec v'\in B_\epsilon(\vec x)}\lVert \vec v'-\vec v\rVert_\infty$, svakoj komponenti $\vec v_\ind{i}$ se dodjeljuje najbliža vrijednost unutar intervala $\intcc{\vec x_\ind{i}-\epsilon, \vec x_\ind{i}+\epsilon}$.

Mogući su i napadi bez uvida u strukturu modela, npr. genetskim algoritmom. Također, pokazuje se da su neprijateljski primjeri u velikoj mjeri prenosivi između različitih modela \citep{Szegedy:2013:IPNN,Goodfellow:2014:EHAE, Moosavi:2016:UAP,Liu:2016:DITAEBBA}.

Možemo definirati oblik rizika koji se može nazvati \emphasize{neprijateljski rizik} \citep{Madry:2017:TDLMRAA}:
\begin{equation}\label{eq:adv-risk}
R_\text{A}(\vec\theta;d,\epsilon) = \E_{(\vec x,y)\sim\mathcal{D}}\del{
\max_{\tilde{\vec x} \in B_\epsilon(\vec x)} L(y,h(\tilde{\vec x};\vec\theta))} \text{.}
\end{equation}
Mali neprijateljski rizik predstavlja dobru lokalnu generalizaciju u susjedstvu prirodnih primjera. Jedan od najuspješnijih postupaka za postizanje otpornosti na neprijateljske primjere je \emphasize{učenje s neprijateljskim primjerima} (engl. \textit{adversarial training}). Kod učenja s neprijateljskim primjerima skup za učenje se proširuje neprijateljskim primjerima koji se tijekom učenja prilagođavaju parametrima mreže \citet{Goodfellow:2014:EHAE}. Umjesto prirodne razdiobe $\mathcal{D}$ u jednadžbi~\ref{eq:adv-risk}, koriste se podaci za učenje, tj. empirijska razdioba. 

\citet{Kurakin:2016:AMLS} primjećuju da korištenja stvarne ciljne oznaka u gubitku koji se maksimizira kako bi se dobio neprijateljski primjer unosi informacije o pravim oznakama u neprijateljske primjere koji se koriste tijekom učenja, na što se model može prenaučiti i može biti neotporan na neprijateljske primjere dobivene postupcima koji ne koriste stvarnu oznaku. Zato predlažu da se umjesto ciljne oznake u gubitku koji se maksimizira koristi oznaka koja odgovara predikciji modela. Onda izrazu~\eqref{eq:neprijateljski-primjer} odgovara ovaj izraz:
\begin{equation} \label{eq:neprijateljski-primjer-p}
\tilde{\vec x} = \argmax_{\tilde{\vec x}\in B_\epsilon(\vec x)} L\del{\argmax_k h(\vec x)_\ind{k},h(\tilde{\vec x})} \text{,}
\end{equation}
što je obično maksimizacija negativnog logaritma najvećeg izlaza softmaksa:
\begin{equation} \label{eq:neprijateljski-primjer-plogsoftmax}
\tilde{\vec x} = \argmax_{\tilde{\vec x}\in B_\epsilon(\vec x)} \del{-\ln h(\tilde{\vec x})_\ind{\argmax_k h(\vec x)_\ind{k}}} \text{.}
\end{equation}
To je slično virtualnim neprijateljskim primjerima koje su predložili \citet{Miyato:2015:DSVAE}. \citet{Miyato:2015:DSVAE,Miyato:2017:VATRMSSSL} definiraju regularizacisjki gubitak kojemu odgovara ovakav rizik koji možemo nazvati \emphasize{rizik lokalne zaglađenosti razdiobe} (engl. \textit{local distributional smoothness}, \textit{LDS}):
\begin{equation}\label{eq:adv-risk-lds}
R_\text{LDS}(\vec\theta;d,\epsilon) = \E_{(\vec x,y)\sim\mathcal{D}} \del{
	\max_{\tilde{\vec x} \in B_\epsilon(\vec x)} \Dkl{\rvec y\mid\vec x,\hat{\vec\theta}}{\rvec y\mid\tilde{\vec x},\vec\theta}
} \text{,}
\end{equation}
Razlika u odnosu na neprijateljski rizik je u tome što se umjesto KL-divergencije između ciljne oznake i razdiobe predikcije za neprijateljski primjer, ovdje koristi KL-divergencija između razdiobe predikcije za neizmijenjeni primjer i razdiobe predikcije za neprijateljski primjer. $\hat{\vec\theta}=\vec\theta$, ali $\hat{\vec\theta}$ označava da se parametri ne optimiziraju s obzirom na argument koji zamjenjuje oznaku. Takva regularizacija se može koristiti i u polunadziranom učenju, kada nisu poznate oznake svih primjera u skupu za učenje. 

Pokazuje se da se najučinkovitiji neprijateljski primjeri dobivaju u više koraka optimizacije \citep{Kurakin:2016:AMLS,Madry:2017:TDLMRAA}. \citet{Madry:2017:TDLMRAA} postižu dobru otpornost uz korištenja PGD-a (jednadžba~\ref{eq:pgd}) za generiranje neprijateljskih primjera tijekom učenja, a zaključuju i da je potreban veći kapacitet kako bi mreža zadržala performansu na prirodnim podacima.

\subsection{Dijeljenje parametara i dijelova mreže}

Dijeljenje ili višestruka uporaba parametara i dijelova mreže je korisna kada se za podatke vrijede neka svojstva ekvivarijantnosti (npr. na pomak u prostoru ili vremenu, skaliranje, kompozitnost,...). Ono se može primjenjivati i kod višezadaćnog učenja kod kojeg se dio mreže koristi za dobivanje značajki koje su korisne za učenje većeg broja različitih zadataka.

\subsection{Pomoćni gubici i preskočne veze}

Ponekad kod učenja dubokih mreža mogu pomoći \emphasize{dodatni gubici} koji ovise o funkcijama koje procjenjuju izlaz na temelju značajki niže razine. Najuspješniji modeli koriste \emphasize{preskočne veze} koje omogućuju da funkcije koje računaju značajke više razine imaju izravan pristup značajkama niže razine. Najjednostavniji i najčešće korišteni takvi modeli (u računalnom vidu) su \textit{rezidualne mreže} (\textit{ResNet}) \citep{He:2015:DRLIR,He:2016:IMDRL} i \textit{guste mreže} (\textit{DenseNet}) \citep{Huang:2016:DCCN} od kojih je osnovna struktura prikazana na slici~\ref{fig:resnet-densenet}. Empirijski se pokazuje da se povećavanjem dubine takvih mreža poboljšava generalizacija.

\begin{figure}
	\centering
	\begin{subfigure}[t]{1\textwidth}
		\centering
		\begin{tikzpicture}
		\def\inp{\_}
		\node[nrect] (x) {$\vec x$};
		\node[nrect] (f1) [above right=of x] {$f(\inp;\vec\theta_1)$};
		\node[nrect] (p1) [below right=of f1] {$+$};
		
		\node[nrect] (f2) [above right=of p1] {$f(\inp;\vec\theta_2)$};
		\node[nrect] (p2) [below right=of f2] {$+$};
		\node[nrect,draw=none] (dots) [right=of p2] {$\cdots$};	
		\node[nrect] (pn-1) [right=of dots] {$+$};
		
		\node[nrect] (fn) [above right=of pn-1] {$f(\inp;\vec\theta_n)$};
		\node[nrect] (pn) [below right=of fn] {$+$};
		
		\path (x) edge [dedge] (f1);
		\path (x) edge [dedge] (p1);		
		\path (f1) edge [dedge] (p1);
		
		\path (p1) edge [dedge] (f2);
		\path (p1) edge [dedge] (p2);		
		\path (f2) edge [dedge] (p2);
		
		\path (p2) edge [dedge] (dots);	
		\path (dots) edge [dedge] (pn-1);
		
		\path (pn-1) edge [dedge] (fn);
		\path (pn-1) edge [dedge] (pn);	
		\path (fn) edge [dedge] (pn);
		\end{tikzpicture}
		\caption{Grupa \textit{rezidualne mreže}.}
		\label{subfig:resnet}
	\end{subfigure}
	\vskip\baselineskip
	\begin{subfigure}[t]{1\textwidth}
		\centering
		\begin{tikzpicture}
		\def\inp{\_}
		\node[nrect] (x) {$\vec x$};
		\node[nrect] (f1) [above right=of x] {$f(\inp;\vec\theta_1)$};
		\node[nrect] (p1) [below right=of f1] {$\concat'$};
		
		\node[nrect] (f2) [above right=of p1] {$f(\inp;\vec\theta_2)$};
		\node[nrect] (p2) [below right=of f2] {$\concat'$};
		\node[nrect,draw=none] (dots) [right=of p2] {$\cdots$};	
		\node[nrect] (pn-1) [right=of dots] {$\concat'$};
		
		\node[nrect] (fn) [above right=of pn-1] {$f(\inp;\vec\theta_n)$};
		\node[nrect] (pn) [below right=of fn] {$\concat'$};
		
		\path (x) edge [dedge] (f1);
		\path (x) edge [dedge] (p1);		
		\path (f1) edge [dedge] (p1);
		
		\path (p1) edge [dedge] (f2);
		\path (p1) edge [dedge] (p2);		
		\path (f2) edge [dedge] (p2);
		
		\path (p2) edge [dedge] (dots);	
		\path (dots) edge [dedge] (pn-1);
		
		\path (pn-1) edge [dedge] (fn);
		\path (pn-1) edge [dedge] (pn);	
		\path (fn) edge [dedge] (pn);
		\end{tikzpicture}
		\caption{Blok \textit{guste mreže}.}
		\label{subfig:densenet}
	\end{subfigure}
	\caption{Osnovne strukture \textit{rezidualnih} i \textit{gustih} mreža. $f$ je obično niz od nekoliko konvolucijskih (ili linearnih slojeva) tako da su ispred svake konvolucije sloj normalizacije po grupama i sloj $\ReLU$-a. $+$ označava zbrajanje, a $\concat'$ konkatenaciju po zadnjoj dimenziji ulaznih nizova.}
	\label{fig:resnet-densenet}
\end{figure}


\section{Konvolucijske mreže}

\emphasize{Konvolucijske mreže} su mreže koje, prema definiciji u \citet{Goodfellow:2016:DL}, na barem jednom mjestu, umjesto općenite linearne transformacije, koriste \emphasize{konvoluciju}. Konvolucijske mreže koriste pretpostavku \emphasize{translacijske ekvivarijantnosti} po nekim dimenzijama ulaza i posebno se uspješno primjenjuju na zadacima u vezi slika. Pojedini elementi izlaza \emphasize{konvolucijskog sloja} računaju se množenjem manjeg \emphasize{filtra} s elementima ulaza koje on prekriva na svakom položaju ulaza. Element i izlaza ovise o malom broju elemenata ulaza oko odgovarajućih položaja, tj. \emphasize{povezanost} je \emphasize{lokalna}. To omogućuje da se broj parametara konvolucijskog sloja značajno smanji u odnosu na \emphasize{potpuno-povezani sloj}, tj. sloj linearne transformacije. Pojedine težine uče se na različitim dijelovima ulaza i to sve omogućuje veću efikasnost i bolju generalizaciju.

\subsection{Konvolucija}

Konvolucija funkcija iz $\Z\to\R$ definirana je ovim izrazom:
\begin{align}
(f*g)(t) \coloneqq \sum_\tau f(\tau)g(t-\tau) \text{.}
\end{align}
Jednako tako, definirana je konvolucija funkcija iz $\Z^n\to\R$:
\begin{align}
(f*g)(\vec t) \coloneqq \sum_{\vec\tau} f(\vec\tau)g(\vec t-\vec\tau) \text{.}
\end{align}
Na isti način, s integralom umjesto zbroja, definirana je i konvolucija funkcija s kontinuiranom domenom. Neka od svojstava konvolucije su:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item Komutativnost: $f*g=g*f$.
	\item Distributivnost zbrajanja. Vrijedi $(f+g)*h=f*h+g*h$.	
	\item Translacijska ekvivarijantnost. Ako $f'(t) \coloneqq f(t+d)$, onda $(f'*g)(t)=(f*g)(t+d)$.
	\item Konvolucija u vremenskoj domeni odgovara umnošku u Fourierovoj domeni, tj. $\const F[f*g]=\const F[f]\const F[g]$, gdje $\const F$ označava odgovarajuću Fourierovu transformaciju.
\end{enumerate}

Konvolucija se može poopćiti na funkcije s kodomenom koja može općeniti vektorski prostor, tj. funkcije iz $\Z^m\to\R^n$. Jedan način je ovaj, gdje se po svakoj komponenti paralelno obavlja konvolucija:
\begin{align}
(f*_\text{p}g)(\vec t) \coloneqq 
\sum_{\vec\tau} f(\vec\tau)\odot g(\vec t-\vec\tau) \text{.}
\end{align}
Drugi način je ovaj, gdje se izlazni vektori funkcija skalarno množe:
\begin{align} \label{eq:konvolucija-s}
(f*_\text{s}g)(\vec t) \coloneqq 
\sum_{\vec\tau} \braket{f(\vec\tau)}{g(\vec t-\vec\tau)} \text{.}
\end{align}
U ovom slučaju, kodomena funkcije $f*_\text{s}g$ je $\R$. Isti izraz vrijedi i ako je kodomena funkcija $f$ i $g$ neki skup $n$-dimenzionalnih nizova, tj. $\R^{d_1\times\dots\times d_n}$, gdje su $d_i$ pojedine dimenzije niza. Zato se za skalarni produkt ovdje koristi oznaka skalarnog produkta.

\subsection{Konvolucijski sloj}

Jednom umjetnom neuronu kod konvolucijskih mreža, ako se zanemari pomak, obično odgovara operacija u jednadžbi~\eqref{eq:konvolucija-s}, samo što funkcijama $f$ i $g$ odgovaraju konačni $(m+1)$-dimenzionalni (ili $m$-dimenzionalni ako $n=1$) nizovi, pa treba prilagoditi definiciju konvolucije za nizove. Jednoj funkciji odgovara ulazni niz, a drugoj \emphasize{konvolucijska jezgra} (\emphasize{filtar}) koja je obično manja i neovisna o veličini ulaza. Izlaz konvolucije je onda $m$-dimenzionalni niz kojem su dimenzije obično iste kao privih $m$ dimenzija ulaznog niza, ovisno o prilagodbi definicije konvolucije na nizove. Ovakvu konvoluciju ćemo nazivati \emphasize{$m$-dimenzionalna konvolucija}. Ovdje se neće razmatrati $m$-dimenzionalna konvolucija $(m+n)$-dimenzionalnih nizova kod kojih $n>1$, tj. $\vec A_\ind{i_1,\bidot,i_m,:}$ su vektori ako je $\vec A$ $(m+1)$-dimenzionalan.

Slojevi koji obavljaju konvoluciju nazivaju se \emphasize{konvolucijski slojevi}. Izlaz jedne jedinice (dobiven jednim filtrom) u konvolucijskom sloju naziva se \emphasize{mapa značajki}. Izlaz konvolucijskog sloja sastoji se od više mapa značajki i čini $(m+1)$-dimenzionalni izlaz kojem je zadnja dimenzija jednaka broju mapa značajki. $m$-dimenzionalnu konvoluciju s $k$ jezgri nazivat ćemo \emphasize{$k$-struka $m$-dimenzionalna konvolucija}.

Osnovni način definiranja $m$-dimenzionalne konvolucije (unakrsne korelacije ako ne reflektiramo jezgru) $(m+1)$-dimenzionalnog ulaza $\vec X$ s $(m+1)$-dimenzionalnom jezgrom $\vec W$, što daje $m$-dimenzionalni niz $\vec X*_\text{s}\vec W$, može se ovako izraziti:
\begin{align} \label{eq:konvolucija-sv}
(\vec X*_\text{s}^\text{v}\vec W)_\ind{\vec t} \coloneqq 
\braket{\vec X_\ind{\vec t:\vec t+ \vec d_{\vec W}+\cvec 1,:}}{\vec W} \text{,}
\end{align}
gdje je $\vec d_{\vec W} = \dim(\vec W)_\ind{1:m}$ vektor dimenzija jezgre po kojima se obavlja konvolucija. Skalarni produkt na desnoj je definiran ako $\forall i \in \cbr{1\bidot m}\ {\vec t}_\ind{i} \in \cbr{1,\bidot,{\vec d_{\vec X}}_\ind{i}-{\vec d_{\vec W}}_\ind{i}-1}$, gdje je $\vec d_{\vec X}=\dim(\vec X)_\ind{1:m}$ vektor dimenzija ulaza. Izlaz takve operacije je dimenzija $\del{{\vec d_{\vec X}}_\ind{i}-{\vec d_{\vec W}}_\ind{i}-\cvec 1}$.
Kod obrade slike obično želimo da izlaz konvolucije bude jednakih dimenzija kao ulaz. To se može ostvariti dopunjavanjem ulaza nulama po rubu dimenzija po kojima treba obavljati konvoluciju tako da sredina jezgre, za koju pretpostavljamo da ima neparne dimenzije, može doći do ruba izvornog ulaza. Neka $\mathrm{pad}\del{\vec X, \tfrac{1}{2}\del{\vec d_{\vec W}-\cvec 1}}$ označava takvu operaciju dopunjavanja. Definiramo novu operaciju:
\begin{align} \label{eq:konvolucija-ss}
\vec X *_\text{s}^\text{s} \vec W \coloneqq 
\mathrm{pad}\del{\vec X, \tfrac{1}{2}\del{\vec d_{\vec W}-\cvec 1}} *_\text{s}^\text{v} \vec W \text{.}
\end{align}
U gornjem indeksu operatora "v" dolazi od riječi \textit{valid} zato što se filtar pomiče samo unutar granica ulaza, a "s" od riječi \textit{same} zato što je izlaz istih dimenzija kao ulaz (osim zadnje). Na slici~\ref{fig:konvolucija-dopunjavanje} ilustrirani su najčešći načina dopunjavanja na primjeru jednostruke dvodimenzionalne konvolucije dvodimenzionalnih nizova. Na slici~\ref{fig:konvolucija-grafovi} prikazana je jednostruka jednodimenzionalna konvolucija (unakrsna korelacija) dvodimenzionalnih nizova s dopunjavanjem kao u jednadžbi~\eqref{eq:konvolucija-ss}. 

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.31\textwidth}
		\includegraphics[width=1\textwidth]{konv/no_padding_no_strides_00_i3}
		\caption{Bez dopunjavanja.}
		\label{subfig:konv-nopad}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.31\textwidth}
		\centering
		\includegraphics[width=1\textwidth]{konv/same_padding_no_strides_00}
		\caption{Dopunjavanje takvo da izlaz ima iste dimenzije kao ulaz.}
		\label{subfig:konv-samepad}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.31\textwidth}
		\centering
		\includegraphics[width=1\textwidth]{konv/full_padding_no_strides_00}
		\caption{Potpuno dopunjavanje.}
		\label{subfig:konv-fullpad}
	\end{subfigure}
	\caption{Ilustracija dopunjavanja kod dvodimenzionalne konvolucije. Slike~\ref{subfig:konv-samepad}~i~\ref{subfig:konv-fullpad} su preuzete, a slika~\ref{subfig:konv-nopad} je napravljena na temelju slika iz \citet{Dumoulin:2016:GCADL}.}
	\label{fig:konvolucija-dopunjavanje}
\end{figure}

\begin{figure}
\centering
\begin{subfigure}[t]{0.48\textwidth}
	\centering
	\begin{tikzpicture}
	\def\inp{\_}
	\node[nrect] (x) [] {$\vec X$};	
	\node[nrect] (y) [right=of x] {$*_\text{s}^\text{s}$};
	\node[nrect] (w) [above=of y] {$\vec W$};
	\node[right=0 of y] {$\vec y$};
	\path (w) edge [dedge] node[right=-1mm]  {\tiny $2$} (y);
	\path (x) edge [dedge] node[above=-1mm]  {\tiny $1$} (y);
	\end{tikzpicture}
	\caption{Apstraktni prikaz konvolucije.}
	\label{subfig:konv-aps}
\end{subfigure}
~
\begin{subfigure}[t]{0.48\textwidth}
	\centering
	\begin{tikzpicture}
	\def\inp{\_}
	\def\n{4}
	
	\node[nrect] (x0) {$\cvec 0$};
	\foreach \i in {1,2,...,\n}
	  \pgfmathtruncatemacro\result{\i-1}
	  \node[nrect] (x\i) [below=5mm of x\result] {$\vec x_\i$};
	\pgfmathtruncatemacro\result{\n+1}
	\node[nrect] (x\result) [below=5mm of x\n] {$\cvec 0$};
	
	\foreach \i in {1,2,...,\n} {
	  \node[nrect] (y\i) [right=20mm of x\i] {$\sum_{i=1}^3 \braket{\inp_i}{\vec w_i}$};
	  \node[right=0 of y\i] {$y_\i$};
	}
	\foreach \i in {1,2,...,\n}
	  \foreach \j in {1,2,3}
	    \pgfmathtruncatemacro\result{\i+\j-2}
	    \path (x\result) edge [dedge] node[above=-1mm,pos=0.88] {\tiny $\j$} (y\i);
	\node[nrect] (w2) [above=of y1] {$\vec w_2$};
	\node[nrect] (w1) [left=1mm of w2] {$\vec w_1$};
	\node[nrect] (w3) [right=1mm of w2] {$\vec w_3$};
	\end{tikzpicture}
	\caption{Detaljniji prikaz konvolucije.}
\label{subfig:konv-det}
\end{subfigure}
	\caption{Grafički prikaz jednodimenzionalne konvolucije s dopunjavanjem. Na slici~\subref{subfig:konv-det} detaljnije su prikazani dvodimenzionalni nizovi $\vec X\in\R^{4\times n}$ i $\vec W\in\R^{3\times n}$ iz slike~\subref{subfig:konv-aps} rastavljeni na vektore, dopunjavanje i konvolucija na razini vektora $\vec x_i=\vec X_\ind{i,:}$ i $\vec w_i=\vec W_\ind{i,:}$. Rezultat konvolucije je $\vec y=\sbr{y_1,\bidot,y_4}\in\R^4$. $\__i$ označava $i$-ti ulaz čvora u smjeru obrnutom od kazaljke na satu od desne strane.}
	\label{fig:konvolucija-grafovi}
\end{figure}

\subsubsection{Izlazni korak konvolucije i dilatacija jezgre}

Kod konvolucijski mreža još se koriste neke izmjene konvolucije kako bi se postigla veća računalna efikasnost. Jedna je korištenje \emphasize{izlaznog koraka} (ili \emphasize{korak}). Izlazni korak veći od $1$ da jezgra po toj dimenziji preskače neke položaje. Na taj način se postiže da dimenzije izlaza budu manje za otprilike za faktor veličine izlaznog koraka. Konvolucija s Izlazniim korakom $2$ po svim dimenzijama konvolucije ilustrirana ja na slici~\ref{fig:konvolucija-izl-korak}. 

\begin{figure}
	\centering
	\includegraphics[width=0.24\textwidth]{konv/no_padding_strides_00}
	\includegraphics[width=0.24\textwidth]{konv/no_padding_strides_01}
	\includegraphics[width=0.24\textwidth]{konv/no_padding_strides_02}
	\includegraphics[width=0.24\textwidth]{konv/no_padding_strides_03}
	\caption{Ilustracija konvolucije s korakom $2$. Slike su preuzete iz \citet{Dumoulin:2016:GCADL}.}
	\label{fig:konvolucija-izl-korak}
\end{figure}

Kako bi se povećalo \emphasize{receptivno polje} jedinice konvolucijskog sloja bez povećavanja dimenzija jezgre, koristi se konvolucija s \emphasize{dilatacijom} (ili \emphasize{dilacijom}), tj. \emphasize{širenjem jezgre}. Na slici~\ref{fig:konvolucija-dilatacija} ilustrirana konvolucija s dilacijom $1$. Takva konvolucija je ekvivalentan konvoluciji kod koje se koristi veća jezgra kod koje se svaki drugi redak ili stupac sastoji od nula.

\begin{figure}
	\centering
	\includegraphics[width=0.24\textwidth]{konv/dilation_00}
	\includegraphics[width=0.24\textwidth]{konv/dilation_01}
	\includegraphics[width=0.24\textwidth]{konv/dilation_02}
	\includegraphics[width=0.24\textwidth]{konv/dilation_03}
	\caption{Ilustracija konvolucije s dilacijom $1$. Slike su preuzete iz \citet{Dumoulin:2016:GCADL}.}
	\label{fig:konvolucija-dilatacija}
\end{figure}

\subsubsection{Konvolucija kao matrično množenje}

Konvolucija je linearna operacija. Na slici~\ref{fig:konvolucija-konk} je konvolucija sa slike~\ref{fig:konvolucija-grafovi} prikazana malo drugačije. Jezgra je pretvorena u vektor, a ulaz je pretvoren u vektore koji se skalarno množe s vektorom koji predstavlja jezgru. Možemo ulaz $\vec X$ pretvoriti u matricu $\vec X_\text{M}\in\R^{4\times 3n}$, a jezgru $\vec W$ u vektor $w\in\R^{3n}$ tako da njihov matrični umnožak daje izlaz konvolucije:
\begin{align}
\underbrace{
\begin{bmatrix}
\cvec 0_{1\times n} & \vec x_1^\tp & \vec x_2^\tp \\
       \vec x_1^\tp & \vec x_2^\tp & \vec x_3^\tp \\
       \vec x_2^\tp & \vec x_3^\tp & \vec x_4^\tp \\
       \vec x_3^\tp & \vec x_4^\tp & \cvec 0_{1\times n}         
\end{bmatrix}
}_{\vec X_{\text{M}}}
\underbrace{
\begin{bmatrix}
\vec w_1 \\
\vec w_2 \\
\vec w_3     
\end{bmatrix}
}_{\vecfunc(\vec W)}
=
\underbrace{
\begin{bmatrix}
y_1 \\ y_2 \\ y_3 \\y_4     
\end{bmatrix}
}_{\vec y}
\text{.}
\end{align}

Konvolucijski sloj obično ima više jezgri $\vec W_i$. Sada se lako vidi da vrijedi $\pd{\vec y}{\vecfunc(\vec W)}=\vec X_\text{M}$. To možemo poopćiti na $k$-struku konvoluciju:
\begin{align} \label{eq:konvolucija-matrica-tezina}
\vec X_\text{M}
\begin{bmatrix}
\vecfunc(\vec W_1) & \vecfunc(\vec W_2) & \cdots & \vecfunc(\vec W_k)
\end{bmatrix}
= 
\begin{bmatrix}
\vec y_1 & \vec y_2 & \cdots & \vec y_k \\
\end{bmatrix}
\text{.}
\end{align}

\begin{figure}
	\centering
	\begin{tikzpicture}
	\def\inp{\_}
	\def\n{4}
	
	\node[nrect] (x0) {$\cvec 0$};
	\foreach \i in {1,2,...,\n}
		\pgfmathtruncatemacro\result{\i-1}
		\node[nrect] (x\i) [below=5mm of x\result] {$\vec x_\i$};
	\pgfmathtruncatemacro\result{\n+1}
	\node[nrect] (x\result) [below=5mm of x\n] {$\cvec 0$};
	
	%\node[nrect] (X) [below left=0 and 15mm of x3] {$\vec X$};
	
	\foreach \i in {1,2,...,\n} {
		%\path (X) edge [dedge] (x\i);		
		\node[nrect] (xx\i) [right=15mm of x\i] {$\concat$};
		\node[nrect] (y\i) [right=of xx\i] {$\braket{\inp}{\vec w}$};
		\node[right=0 of y\i] {$y_\i$};
	}
	\foreach \i in {1,2,...,\n} {
		\foreach \j in {1,2,3}
			\pgfmathtruncatemacro\result{\i+\j-2}
			\path (x\result) edge [dedge] node[above=-1mm,pos=0.8] {\tiny $\j$} (xx\i);
		\path (xx\i) edge [dedge] (y\i);
	}
	\node[nrect] (w) [above=of y1] {$\vecfunc$};
	\node[right=0 of w] {$\vec w$};
	\node[nrect] (W) [left=of w] {$\vec W$};
	\path (W) edge [dedge] (w);
	\end{tikzpicture}
	\caption{Alternativni prikaz konvolucije ekivalentan onom na slici~\ref{fig:konvolucija-grafovi}. $\concat$ ovdje označava združivanje vektora $\vec x_i\in\R^n$ u vektor iz $\R^{3n}$, $\vecfunc$ funkciju koja $\vec W\in\R^{3\times n}$ preslikava u $\vec w\in\R^{3n}$.}
	\label{fig:konvolucija-konk}
\end{figure}

To se može poopćiti i na višedimenzionalnu konvoluciju \citep{Sharan:2014:EPDL}. Onda su reci matrice $\vec X_\text{M}$ vektori $\vecfunc\del{\mathrm{pad}\del{\vec X, \tfrac{1}{2}\del{\vec d_{\vec W}-\cvec 1}}_\ind{\vec t:\vec t+\vec {d^{\vec W}}_\ind{1:m}+\cvec 1,:}}$ redom po $\vec t$, uz oznake iz jednadžbe~\eqref{eq:konvolucija-sv}, tj. reci su vektori koji sadrže elemente ulaza koje \textit{pokriva} jezgra za svaki položaj. Jezgra je opet vektor, a kao izlaz se dobije vektor koji treba preoblikovati tako da mu prvih $m$ dimenzija bude jednako prvih $m$ dimenzija ulaza.

Drugi način pretvaranja konvolucije u matrično množenje je ovakav: 
\begin{align}
\underbrace{
\begin{bmatrix}
\vec w_2^\tp & \vec w_3^\tp & \cvec 0_{1\times n} & \cvec 0_{1\times n} \\
\vec w_1^\tp & \vec w_2^\tp & \vec w_3^\tp & \cvec 0_{1\times n} \\
\cvec 0_{1\times n} & \vec w_1^\tp & \vec w_2^\tp & \vec w_3^\tp \\
\cvec 0_{1\times n} & \cvec 0_{1\times n} & \vec w_1^\tp & \vec w_2^\tp 
\end{bmatrix}
}_{\vec W_\text{M}}
\underbrace{
	\begin{bmatrix}
	\vec x_1 \\ \vec x_2 \\ \vec x_3 \\ \vec x_4 
	\end{bmatrix}
}_{\vecfunc(\vec X)}
= 
\underbrace{
	\begin{bmatrix}
	y_1 \\ y_2 \\ y_3 \\y_4     
	\end{bmatrix}
}_{\vec y}
\text{.}
\end{align}
Ovdje se vidi da $\pd{\vec y}{\vecfunc(\vec X)}=\vec W_\text{M}$. Gradijent gubitka $L$ po $\vecfunc(\vec X)$ je $\del{\pd{L}{\vec y}\pd{\vec y}{\vecfunc(\vec X)}}^\tp = \vec W_\text{M}^\tp\nabla_{\vec y}L$. To isto odgovara jednoj vrsti konvolucije koja se naziva \emphasize{transponirana konvolucija} \citep{Segvic:2018:DUUUKS}.

\subsection{Slojevi sažimanja}

U konvolucijskim mrežama se, uglavnom radi smanjivanja dimenzija, mogu koristiti \emphasize{slojevi sažimanja}. Operacije sažimanja, slično konvolucijskim slojevima, primjenjuju neku funkciju pomicanjem okna po dimenzijama konvolucije, obično s korakom većim od 1. Za razliku od konvolucijskih slojeva, oni obično djeluju na svakoj mapi značajki posebno i izlazi sažimanja su invarijantni na zamjenu elemenata unutar okna. To svojstvo se naziva \emphasize{lokalna invarijantnost}. Najčešće se kao funkcija koja preslikava skup elementa okna u izlaz koristi $\max$ ili prosjek. Veličina okna je često jednaka veličini koraka tako da se susjedna okna ne preklapaju. Na slici~\ref{fig:sazimanje-primjeri} ilustrirani su primjeri sažimanja.

\begin{figure}
	\centering
	\begin{subfigure}[t]{0.48\textwidth}
		\includegraphics[width=1\textwidth]{konv/numerical_average_pooling_00}
		\caption{Sažimanje prosječnom vrijednošću s oknom dimenzija $3\times 3$ i korakom $1$.}
		\label{subfig:avg-pool}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=1\textwidth]{konv/numerical_max_pooling_00}
		\caption{Sažimanje maksimalnom vrijednošću s oknom dimenzija $3\times 3$ i korakom $1$.}
		\label{subfig:max-pool-31}
	\end{subfigure}
	\vskip\baselineskip
		\begin{subfigure}[t]{0.48\textwidth}
		\includegraphics[width=1\textwidth]{konv/numerical_max_pooling_00_i22}
		\caption{Sažimanje maksimalnom vrijednošću s oknom dimenzija $2\times 2$ i korakom 2.}
		\label{subfig:max-pool-22}
	\end{subfigure}
	~
	\begin{subfigure}[t]{0.48\textwidth}
		\centering
		\includegraphics[width=1\textwidth]{konv/numerical_max_pooling_00_ig}
		\caption{Globalno sažimanje maksimalnom vrijednošću.}
		\label{subfig:max-pool-g}
	\end{subfigure}
	\caption{Ilustracije primjera dvodimenzionalnog sažimanja. Slike su preuzete iz \citet{Dumoulin:2016:GCADL} i prilagođene.}
	\label{fig:sazimanje-primjeri}
\end{figure}

Za smanjivanje mapa značajki često se koriste i uobičajeni postupci interpolacije\footnote{\url{https://en.wikipedia.org/wiki/Multivariate_interpolation}} slika kao što su \emphasize{interpolacijski postupak najbližeg susjeda} i \emphasize{bilinearna interpolacija}.



\chapter{Procjenjivanje nesigurnosti kod dubokih modela} \label{chap:procjenjivanje-nesigurnosti}

Kod uobičajenih modela dubokog učenja ne možemo pouzdano procijeniti nesigurnost predikcija. Modeli za regresiju kao izlaz daju točkastu procjenu izlaza, a modeli za klasifikaciju daju vektor koji predstavlja razdiobu sigurnosti u klase, ali ta razdioba nije dobar pokazatelj stvarne nesigurnosti i neznanja.

Ovo poglavlje opisuje podjelu nesigurnosti, njenu ulogu i važnost u nekim algoritmima strojnog učenja i neke pristupe koji omogućuju bolje procjenjvanje nesigurnosti kod dubokih nadziranih modela. Rezultati eksperimenata s nekim postupcima opisani su u poglavlju~\ref{chap:eksperimenti}.


\section{Aleatorna i epistemička nesigurnost}

Postoje različiti izvori nesigurnosti \citep{Kennedy:2002:BCCM}, ali nesigurnost općenito možemo podijeliti na dvije vrste: \emphasize{aleatornu nesigurnost} i \emphasize{epistemičku nesigurnost} \citep{Kiureghian:2009:AEDM}. Riječ \textit{aleatorna} izvedena je vjerojatno od latinske riječi \textit{aleator} \citep{Gal:2016:UDL} koja znači \textit{kockar}, a riječ \textit{epistemička} izvedena je od grčke riječi \textit{epist\={e}m\={e}} koja znači \textit{znanje}. Aleatorna nesigurnost je nesigurnost koju model ne može smanjiti neovisno o znanju i količini dostupnih podataka. Ona dolazi od višeznačnosti podatka, tj. nedeterminizma samog procesa koji generira podatke, nedostupnosti dijela informacija ili ograničenja modela. Epistemička nesigurnost je nesigurnost u \emphasize{strukturu modela} i \emphasize{parametre modela} \citep{Gal:2016:UDL}. Ona se zato još naziva \emphasize{nesigurnost modela}. Ona dolazi od neznanja i može se smanjiti uz više informacija koje mogu biti veći skup podataka za učenje ili induktivna pristranost.

Razlikovanje aleatorne i epistemičke nesigurnosti ovisi o modelu. Nešto što je kod jednostavnijeg modela aleatorna nesigurnost, kod složenijeg modela može biti epistemička, tj. može se smanjiti uz više podataka. Ako su neke pojave po prirodi nasumične ili se ne mogu ili ne žele modelu dati informacije koje bi ih mogle objasniti, nesigurnost zaključivanja u vezi tih pojava će biti aleatorna neovisno o ograničenosti modela.

Na temelju aleatorne i epistemičke nesigurnosti može se procijeniti \emphasize{nesigurnost predikcije}. Kod bayesovskih modela nesigurnost predikcije izražava se razdiobom po vrijednostima varijable čija vrijednost se procjenjuje, a može se izraziti i nekom mjerom kao što je entropija ili varijanca, ovisno o tome što je prikladno.

Aleatorna nesigurnost može biti \emphasize{homoskedastička} ili \emphasize{heteroskedastička}. Kažemo da je aleatorna nesigurnost homoskedastička ako je neovisna o primjeru, a heteroskedastička ako ovisi o primjeru. Heteroskedastička nesigurnost se treba modelirati kao funkcija primjera. Za izlaz te funkcije se isto može procjenjivati epistemička nesigurnost --- nesigurnost u procjenu aleatorne nesigurnosti. Na slici~\ref{fig:bm-heteroskedasticki-sum} je prikazan primjer grafičkog modela koji pretpostavlja aleatorni šum, a na slici~\ref{fig:homoskedasticki-heteroskedasticki-sum-regresija} je ilustrirana usporedba regresijskih zadataka bez i sa šumom koji ovisi u ulaznom primjeru. Modeliranje aleatorne nesigurnosti se ostvaruje kao funkcija ulaza.

\begin{figure}
	\centering
	\begin{tikzpicture}
	\node[pnode] (t) [] {$\rvec \theta$};
	\node[textnode] (a) [right=of t] {$\alpha$};
	\node[greypnode] (yi) [left=of t] {$\rvar y_i$};
	\node[greypnode] (xi) [left=of yi] {$\rvec x_i$};
	\node[pnode] (ei) [above=of yi] {$\epsilon_i$};
	\node[pnode] (e) [below=of yi] {$\rvar\epsilon$};
	\node[pnode] (y) [below=of e] {$\rvar y$};	
	\node[greypnode] (x) [left=of y] {$\rvec x$};
	\path (a) edge [dedge] (t);	
	\path (t) edge [dedge] (yi);	
	\path (t) edge [dedge] (ei);	
	\path (t) edge [dedge] (y);
	\path (t) edge [dedge] (e);
	\path (e) edge [dedge] (y);
	\path (xi) edge [dedge] (yi);
	\path (xi) edge [dedge] (ei);
	\path (ei) edge [dedge] (yi);
	\path (x) edge [dedge] (y);
	\path (x) edge [dedge] (e);
	\plate{}{(xi)(yi)(ei)}{$i \in \cbr{1\bidot N}$};
	\end{tikzpicture}
	\caption{Model regresije (prema onom na slici~\ref{fig:bm-regresija}) kod kojeg su $\rvec\theta$ nepoznati parametri, $\rvec x$ opaženi ulaz, $\rvar y$ nepoznati izlaz, a $\rvar\epsilon$ heteroskedastički šum koji ovisi o ulazu $\rvec x$. Čvorovi s indeksima $i$ predstavljaju podatke za učenje (opaženi čvorovi) i odgovarajući šum ($\epsilon_i$).}
	\label{fig:bm-heteroskedasticki-sum}
\end{figure}

\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{homoscedastic-heteroscedastic-noises}
	\caption{Homoskedastički (lijevo) i heteroskedastički (desno) Gaussov šum.  Crta prikazuje očekivanje $f(x)$, svjetloplava površina standardnu devijaciju šuma $s(x)$, a točke slučajne uzorke. Točke su generirane prema $(\rvar y\mid x) \sim \mathcal{N}(f(x),s(x)^2)$. Na lijevoj slici je $s(x)=1$.}
	\label{fig:homoskedasticki-heteroskedasticki-sum-regresija}
\end{figure}


\subsection{Izvanrazdiobni primjeri}

Jedan poseban slučaj epistemičke nesigurnosti je nesigurnost u to \emphasize{pripada li primjer razdiobi skupa za učenje}. Modelu se dati ulazni primjer za koji ne postoji točna oznaka i nije sličan primjerima u skupu za učenje. Takav primjer može biti npr. slika koja pripada nekoj klasi koja nije među onima koje model treba raspoznavati ili samo slučajni šum. Primjeri koji su izvan razdiobe skupa za učenje dalje ćemo nazivati \emphasize{izvanrazdiobni primjeri}. Primjeri koji su iz razdiobe skupa za učenje nazivat ćemo \emphasize{unutarrazdiobni primjeri}.

Problem prepoznavanja primjera koji su izvan razdiobe skupa za učenje prirodno rješavaju generativni probabilistički modeli, ali kod složenih visokodimenzionalnih podataka to postaje problem zbog prokletstva dimenzionalnosti i složenosti modeliranja i statističkog zaključivanja. Kod diskriminativnih modela je problem to što oni ne modeliraju razdiobu ulaznih primjera $\p(\rvec x)$, nego samo uvjetnu razdiobu izlaza uz dani ulaz $\p(\rvec y \mid\vec x)$.


\section{Važnost i primjene procjenjivanja i razlikovanja nesigurnosti} \label{sec:vaznost-primjene-nesigurnosti}

Sve se više upotrebljavaju složeni duboki modeli kod ozbiljnih primjena kao što su medicina i autonomna vozila, gdje treba osigurati pouzdanost i sposobnost prepoznavanja primjera o kojima model ne može donositi pouzdane zaključke. Trenutno najuspješniji modeli imaju problema s pokazivanjem prevelike sigurnosti u predikciji kod izvanrazdiobnih primjera i krivo klasificiranih primjera \cite{Nguyen:2015:DNNEFHCPUI,Guo:2017:CMNN,Hendrycks:2016:BDMOODE}, a mogu se i pronalaziti neprijateljski primjeri  \citep{Szegedy:2013:IPNN,Goodfellow:2014:EHAE,Moosavi:2016:UAP}, koji su opisani u pododjeljku~\ref{subsec:neprijateljski-primjeri}.

Primjeri područja strojnog učenja u kojima je posebno važno procjenjivanje nesigunosti su aktivno učenje i podržano učenje. Aktivno učenje je oblik polunadziranog učenja gdje algoritam učenja bira primjere za koje zaključi da su potrebni za učenje. Kod podržanog učenja algoritam bira koja će stanja istraživati. Osim procjenjivanja mjere nesigurnosti, za efikasno učenje kod takvih algoritama je bitno i razlikovanje epsitemičke i aleatorne nesigurnosti \citep{Gal:2016:UDL}. Npr. agent kod podržanog učenja neće puno naučiti pretraživanjem stanja koja su sama po sebi nasumična (aleatorna), dok će pretraživanjem stanja o kojima nema puno znanja (epistemička nesigurnost) naučiti nešto novo. Dakle, uspješnim modeliranjem i razlikovanjem nesigurnosti može se poboljšati efikasnost takvih algoritama.


\section{Bayesovske neuronske mreže}

Dijelovi ovog odjeljka se temelje na \citet[poglavlje 2]{Gal:2016:UDL}.

\emphasize{Bayesovske neuronske mreže} su predložene otprilike početkom $90$-ih godina prošlog stoljeća \citep{Denker:1990:TNOLPD,MacKay:1992:PBFBN,Neal:1995:BLNN}. Za razliku od običnih neuronskih mreža, gdje se učenjem provodi točkasta procjena parametara, kod bayesovskih neuronskih mreža se provodi bayesovka procjena parametara (pododjeljak~\ref{subsec:bayesovski procjenitelj}), tj. zaključuje se o aposteriornoj razdiobi parametara na temelju apriorne razdiobe i podataka. Tako naučena mreža predstavlja razdiobu nad hipotezama, što omogućuje otpornost na prenaučenost i procjenjivanje nesigurnosti predikcija \citep{Gal:2016:UDL}.

Kod bayesovskih neuronskih mreža se za apriornu razdiobu težina često koristi pretpostavka nezavisnosti i Gaussova razdioba $\mathcal{N}(0,\lambda^{-1})$ za svaku težinu, gdje je $\lambda$ preciznost. Radi jednostavnosti se pomaci često točkasto procjenjuju. Iako su bayesovske neuronske mreže jednostavne za formulirati, kod njih nije jednostavno provoditi zaključivanje.

Prema jednadžbi~\eqref{eq:posterior-bayes}, aposteriorna vjerojatnost parametara je
\begin{equation}
\p(\vec\theta\mid\set D) 
= \frac{\p(\set{D}\mid\vec\theta)\p(\vec\theta)}{\p(\set{D})} \text{,}
\end{equation}
gdje je 
\begin{equation} \label{eq:marginalna-izglednost}
\p(\set{D}) = \int\p(\set{D}\mid\vec\theta)\p(\vec\theta)\dif\vec\theta = \E_{\rvec\theta}\p(\set{D}\mid\vec\theta)
\end{equation}
marginalna izglednost koja se računa marginalizacijom nazivnika po parametrima. Ta marginalizacija ovdje predstavlja glavni problem i aposteriorna razdioba se mora aproksimirati postupcima kao što su oni navedeni u odjeljku~\ref{sec:aproksimacija-razdioba}. Na temelju ulaza i aposteriorne razdiobe parametara provodi se zaključivanje o izlazu (isto kao jednadžba~\eqref{eq:zakljucivanje-y-bnm}):
\begin{align} \label{eq:zakljucivanje-y-bnm}
\p(\vec y\mid \vec x, \set{D})
= \int\p(\vec y\mid \vec x,\vec\theta)\p(\vec\theta\mid\set D) \dif{\vec\theta}
= \E_{\rvec\theta\mid\set D}\p(\vec y\mid\vec x,\vec\theta) \text{,}
\end{align}

Dvije osnovne skupine pristupa aproksimaciji aposteriorne razdiobe su kratko opisane u odjeljku~\ref{sec:aproksimacija-razdioba}. Kod jedne skupine (MCMC) definira se Markovljev lanac kod kojeg je stacionarna razdioba jednaka aposteriornoj razdiobi parametara i simulacijom se dobivaju uzorci parametara koji se mogu koristiti u \textit{Monte Carlo} aproksimacijama (npr. desnih strana jednadžbi \eqref{eq:marginalna-izglednost} i \eqref{eq:zakljucivanje-y-bnm}). Druga skupina je varijacijsko zaključivanje (opisano u odjeljku~\ref{sec:varijacijsko-zakljucivanje}), gdje se aposteriorna razdioba parametara zamijeni nekom jednostavnijom razdiobom za koju se optimizacijski traže parametri koji ju najviše približavaju aposteriornoj razdiobi.

\subsection{Varijacijsko zaključivanje kod bayesovskih neuronskih mreža}

Kod varijacijskog zaključivanja, koje je opisano u odjeljku~\ref{sec:varijacijsko-zakljucivanje}, za bayesovske neuronske mreže tražimo varijacijsku razdiobu koja minimizira KL-divergenciju prema jednadžbi~\eqref{eq:vz-argmin-dkl}:
\begin{align} \label{eq:vz-argmin-dkl-bnm}
q^* =\argmin_{q_{\vec\phi}} \Dkl{q_{\vec\phi}}{\p(\rvec\theta\mid\set D)}
\text{,}
\end{align}
Varijacijske razdiobe koje su definirane varijacijskim parametrima $\vec\phi$ ovdje su predstavljene slučajnim varijablama $\tilde{\rvec\theta}$. Minimizacija s obzirom na parametre varijacijske razdiobe je ekvivalentna maksimizaciji donje granice logaritma marginalne izglednosti
\begin{align}
L_{\set D}\del{\tilde{\rvec\theta}} 
&= \E_{\tilde{\vec\theta}\sim q_{\vec\phi}} \ln\p\del{\set D\midmid\rvec\theta=\tilde{\vec\theta}} - \Dkl{q_{\vec\phi}}{\p(\rvec\theta)} \text{,}
\end{align}
za koju ne treba računati marginalnu izglednost $\p(\set D)$. Zbog pretpostavke nezavisnosti primjera i pretpostavke diskriminativnog modela $\rvec x\perp\rvec\theta$ vrijedi 
\begin{align}
\p\del{\set D\midmid\rvec\theta=\tilde{\vec\theta}}=\prod_i\p\del{\vec x_i,\vec y_i\midmid\vec x_i,\rvec\theta=\tilde{\vec\theta}}=\prod_i\del{\p\del{\vec y_i\midmid\vec x_i,\rvec\theta=\tilde{\vec\theta}}\p\del{\vec x_i}}  \text{.}
\end{align}
Možemo zanemariti faktore $\p\del{\vec x_i}$ jer oni ne ovise o parametrima i maksimiziramo
\begin{align} \label{eq:bnm-marginalna-izglednost}
\E_{\tilde{\vec\theta}\sim q_{\vec\phi}}\del{\sum_i \ln\p\del{\vec y_i\midmid\vec x_i,\rvec\theta=\tilde{\vec\theta}}} - \Dkl{q_{\vec\phi}}{\p(\rvec\theta)}
\end{align}
s obzirom na varijacijske parametre. Prvi član u tom izrazu potiče maksimizaciju izglednosti parametara na skupu za učenje. Razlika u odnosu na maksimizaciju izglednosti kod običnih dubokih mreža je da se izglednost ne maksimizira po točkastim procjenama parametra, nego po po razdiobama. Drugi dio izraza kažnjava udaljavanje od apriorne razdiobe i služi kao regularizacija.

Zamjenom aposteriorne razdiobe u jednadžbi~\eqref{eq:zakljucivanje-y-bnm} sa zamjenskom razdiobom $q_{\vec\phi}$, zaključivanje o izlazu mreže postaje
\begin{align} \label{eq:zakljucivanje-y-bnm-q}
\p(\vec y\mid \vec x, \set{D})
\approx \int\p(\vec y\mid \vec x,\vec\theta)q_{\vec\phi}(\vec\theta) \dif{\vec\theta}
= \E_{\tilde{\vec\theta}\sim q_{\vec\phi}}\p(\vec y\mid\vec x,\vec\theta) \text{.}
\end{align}

U pododjeljku~\ref{subsec:bnm-dropout} je opisana aproksimacija bayesovske neuronske mreže pomoću \textit{dropouta}.


\section{Mjere za izražavanje nesigurnosti predikcije} \label{sec:mjere-nesigurnosti}

Osnovne mjere za izražavanje nesigurnosti su vjerojatnost, entropija i varijanca. Pretpostavimo da modeliramo (diskretnu ili kontinuiranu) razdiobu $\p(\rvar y\mid\vec x,\vec\theta)$ ili $\p(\rvar y\mid\vec x,\set D)$ ako se provodi bayesovsko zaključivanje. Jedan način izražavanja nesigurnosti u predikciju kod klasifikacije je vjerojatnost klase s najvećom vjerojatnošću
\begin{align}
\max_k \P(\rvar y=k\mid\vec x,\vec\theta) \text{.}
\end{align}
Nesigurnost se može izraziti i entropijom
\begin{align}
\H(\rvar y\mid\vec x,\vec\theta)=-\E_{\rvar y\mid\vec x,\vec\theta}\ln\P\del{y\mid\vec x,\vec\theta}
\end{align}
ili, kod regresije, diferencijalnom entropijom
\begin{align}
\h(\rvar y\mid\vec x,\vec\theta)=-\E_{\rvar y\mid\vec x,\vec\theta}\ln\p\del{y\mid\vec x,\vec\theta}
\end{align}
koja je, ako $\del{\rvar y\mid\vec x,\vec\theta}$ ima Gaussovu razdiobu, proporcionalna (i kao mjera ekvivalentna) varijanci $\D\del{\rvar y\mid\vec x,\vec\theta}$. Ako kod klasifikacije gledamo samo vjerojatnost klase s najvećom vjerojatnošću, možemo kao mjeru nesigurnosti koristiti i binarnu entropiju $-p_{\hat{y}}\ln p_{\hat{y}}-\del{1-p_{\hat{y}}}\ln\del{1-p_{\hat{y}}}$, gdje je $p_{\hat{y}}$ vjerojatnost klase s najvećom vjerojatnošću.

Jedan nedostatak ovih mjera je što ne razlikuju epistemičku i aleatornu nesigurnost. Još jedan mogući nedostatak entropije i maksimalne vjerojatnosti može biti to što npr. razdioba $(0.6,0.2,0.2)$ ima veću entropiju od razdiobe $(0.6,0.4,0)$ iako se može interpretirati da je kod prve razdiobe veća jednoznačnost zaključka o klasi.

\section{Razlikovanje aleatorne i epistemičke nesigurnosti} \label{sec:razlikovanje-aleatorne-epistemicke}

\subsection{Eksplicitno modeliranje aleatorne nesigurnosti} \label{subsec:eksplicitno-modeliranje-aleatorne}

\citet{Kendall:2017:WUNBDLCV} za bayesovske neuronske mreže predlažu eksplicitno modeliranje aleatorne nesigurnosti predikcijom varijance kod regresije i varijance logita kod klasifikacije. Kao konačnu procjenu nesigurnosti, za regresiju procjenjuju ukupnu varijancu izlaza koja je zbroj procjene aleatorne varijance i epistemičke varijance, a za klasifikaciju entropiju izlaza koji se dobiva marginalizacijom po parametrima i logitima za koje pretpostavljaju faktoriziranu Gaussovu razdiobu. Za regresiju predlažu gubitak proporcionalan negativnom logaritmu izglednosti koji uključuje varijancu, koja se inače ne uključuje u gubitak jer se pretpostavlja da je konstanta. Za regresiju je to
\begin{align} \label{eq:aleatorni-gubitak-regresija}
L(\vec y\mid h'(\vec x;\vec\theta))=\frac{1}{2\sigma(\vec x;\vec\theta)^2}\enVert{\vec y-h(\vec x;\vec\theta)}^2+\frac{1}{2}\ln\sigma(\vec x;\vec\theta)^2 \text{,}
\end{align}
gdje $h'(\vec x;\vec\theta)=(h(\vec x;\vec\theta),\sigma(\vec x;\vec\theta))$. U slučaju homoskedastičkog šuma $\sigma(\vec x;\vec\theta)=\sigma$, gdje je $\sigma$ parametar modela. Takav gubitak potiče predikciju veće varijance kada hipoteza očekuje veću kvadratnu pogrešku. Radi numeričke stabilnosti, \citet{Kendall:2017:WUNBDLCV} predlažu da se umjesto $\sigma(\vec x;\vec\theta)$ kao predikcija daje $s(\vec x,\vec\theta)=\ln\sigma(\vec x;\vec\theta)^2$. Gubitak je onda
\begin{align} \label{eq:aleatorni-gubitak-klasifikacija}
L(\vec y\mid h'(\vec x;\vec\theta))=\frac{1}{2}\exp(-s(\vec x;\vec\theta))\enVert{\vec y-h(\vec x;\vec\theta)}^2+\frac{1}{2}s(\vec x;\vec\theta) \text{.}
\end{align}
Za procjenu ukupne varijance predikcije predlažu zbroj aleatorne varijance i očekivanja varijanci elemenata izlaza:
\begin{align}
\E_{\rvec\theta\mid\set D}\sigma(\vec x;\vec\theta) + \sum_i \D_{\rvec\theta\mid\set D}\del{h(\vec x;\vec\theta)_\ind{i}} \text{.}
\end{align}

Za procjenjivanje epistemičke nesigurnosti predikcije kod klasifikacije, \citet{Kendall:2017:WUNBDLCV} koriste entropiju očekivanja predikcije: $\H\del{\rvar y\mid\vec x,\set D}=\H\del{\E_{\rvec\theta\mid\set D}(\rvar y\mid\vec x,\vec\theta)}$. Razdiobe $(\rvar y\mid\vec x,\vec\theta)$ predstavlja izlaz softmaksa, tj. $h(\vec x;\vec\theta)_\ind{k}=(\rvar y=k\mid\vec x,\vec\theta)$. Za procjenu aleatorne nesigurnosti kod klasifikacije pretpostavljaju da logiti imaju Gaussovu razdiobu i predlažu da se za svaki logit procjenjuje varijanca. Neka je $g(\vec x)=g(\vec x;\vec\theta)$ funkcija koja daje očekivanje, a $\sigma(\vec x)=\sigma(\vec x;\vec\theta)$ funkcija koja daje vektor standardnih devijacija logita. Izlazna razdioba se računa ovako:
\begin{align} \label{eq:kendall-hipoteza-klasifikacija}
h(\vec x;\set D) = \E_{\vec s\sim\mathcal{N}(g(\vec x),\diag\del{\sigma(\vec x)^2})}\softmax(\vec s) \text{.}
\end{align}
Gubitak ostaje negativni logaritam izglednosti i može se ovako izraziti:
\begin{align}
L(y\mid h'(\vec x;\vec\theta))
&=-\ln h(\vec x;\set D) \\
&=\ln\del{\E_{\vec s\sim\mathcal{N}(g(\vec x),\diag\del{\sigma(\vec x)^2})} \exp\del{\vec s-\ln\del{\cvec 1^\tp\exp\del{\vec s}}}} \text{.}
\label{eq:kendall-gubitak-klasifikacija}
\end{align}
Za procjenu ovog i drugih očekivanja (i varijanci) se koristi \textit{Monte Carlo} aproksimacija.

\citet{Kendall:2017:WUNBDLCV} su koristili aproksimaciju bayesovske neuronske mreže pomoću \textit{dropouta} i empirijski su pokazali da se uz modeliranje aleatorne nesigurnosti uz gubitke u jednadžbama~\eqref{eq:aleatorni-gubitak-regresija}~i~\eqref{eq:aleatorni-gubitak-klasifikacija} može dobiti malo poboljšanje predikcija na zadacima regresije dubine i semantičke segmentacije. Aproksimaciju bayesovske neuronske mreže pomoću \textit{dropouta} je opisana u pododjeljku~\ref{subsec:bnm-dropout}. Na slici \ref{fig:camvid_qual} se mogu vidjeti primjeri razlikovanja aleatorne i epistemičke nesigurnosti kod predikcije, što su dobili takvim postupkom za semantičku segmentaciju.

\begin{figure}
	\centering
	\resizebox{1\linewidth}{!}{
		\begin{subfigure}[t]{0.22\linewidth}
			\centering
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_1_output_0.jpg}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_13_output_0.jpg}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_2_output_0.jpg}
			\caption{Ulazna slika.}
		\end{subfigure}
		\begin{subfigure}[t]{0.22\linewidth}
			\centering
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_1_output_2.png}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_13_output_2.png}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_2_output_2.png}
			\caption{Ciljne oznake.}
		\end{subfigure}
		\begin{subfigure}[t]{0.22\linewidth}
			\centering
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_1_output_1.png}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_13_output_1.png}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_2_output_1.png}
			\caption{Samantičke segmentacija.}
		\end{subfigure}
		\begin{subfigure}[t]{0.22\linewidth}
			\centering
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_1_output_3.png}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_13_output_3.png}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_2_output_3.png}
			\caption{Aleatorna nesigurnost.}
		\end{subfigure}
		\begin{subfigure}[t]{0.22\linewidth}
			\centering
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_1_output_5.png}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_13_output_5.png}
			\\\vspace{1px}
			\includegraphics[width=\linewidth]{camvid-kendall/segnet_2_output_5.png}
			\caption{Epistemička nesigurnost}			
	\end{subfigure}}
	\caption{Ilustracija procjena aleatorne i epistemičke kod semantičke segmentacije preuzeta iz \citet{Kendall:2017:WUNBDLCV}. Aleatorna nesigurnost je veća na rubovima objekata, posebno na rubovima krošanja, i na udaljenim objektima.}
	\label{fig:camvid_qual}
\end{figure}

\subsection{Međusobna informacija kao mjera epistemičke nesigurnosti} \label{subsec:mi-epistemicka}

\citet{Rawat:2017:APEBDL,Smith:2018:UMUAED}, s ciljem prepoznavanja neprijateljskih primjera, predlažu korištenje međusobne informacije (jednadžbe~\eqref{eq:mutinf}-\eqref{eq:condentropy}) kod bayesovskog zaključivanja kako bi se razlikovale epistemička i aleatorna nesigurnost. Prema \citet{Smith:2018:UMUAED}, količina informacije koju dobijemo o parametrima ako dobijemo oznaku za novi ulazni primjer $\vec x$ je
\begin{align}
\I(\rvar y,\rvec\theta\mid\vec x,\set D) 
&= \H(\rvar y\mid\vec x,\set D) - \H\del{\del{\rvar y\mid\vec x,\set D}\mid\del{\rvec\theta\mid\vec x,\set D}} \\
&= \H(\rvar y\mid\vec x,\set D) - \E_{\rvec\theta\mid\set D} \H(\rvar y\mid\vec\theta,\vec x,\set D) \\
&= \H(\rvar y\mid\vec x,\set D) - \E_{\rvec\theta\mid\set D} \H(\rvar y\mid\vec\theta,\vec x) \text{,}
\end{align}
gdje je korištena definicija uvjetne entropije i pretpostavka $\rvar y\perp\rvec\theta\mid\rset D$, tj. znanje o podacima ne nosi nove informacije o oznaci ako znamo parametre. Veća međusobna informacija se može interpretirati tako da opažanje oznake $y$ za primjer $x$ povećava znanje o parametrima ako postoji nesigurnost u njih. Ako nema puno nesigurnosti u parametre, a ima u predikciju zbog velike aleatorne nesigurnosti, međusobna informacija će biti mala jer je naučeno da za primjer $x$ nije moguće puzdano predvidjeti oznaku. Dakle, međusobna informacije je mjera epistemičke nesigurnosti \citep{Smith:2018:UMUAED}. Dobro je još primijetiti da vrijedi $0<\I(\rvar y,\rvec\theta\mid\vec x,\set D)<\H(\rvar y\mid\vec x,\set D)$, kao što je i ilustrirano na slici~\ref{fig:entropije}. \citet{Smith:2018:UMUAED} objašnjavaju uspješnost korištenja varijance softmaksa kao mjere nesigurnosti u drugim radovima pokazujući da varijanca može dobiti kao aproksimacija međusobne informacije razvojem međusobne informacije u Taylorov red.

\citet{Smith:2018:UMUAED} su koristili aproksimaciju bayesovske neuronske mreže pomoću dropouta, što je opisano u pododjeljku~\ref{subsec:bnm-dropout}, i koristili su uzorkovanje, tj. \textit{Monte Carlo} aproksimaciju za procjenu izlazne razdiobe i mjera nesigurnosti.


\section{Primjeri pristupa za procjenu nesigurnosti} \label{sec:pristupi-procjena-nesigurnosti}

U ovom odjeljku su opisani primjeri pristupa za procjenu nesigurnosti i prepoznavanje izvanrazdiobnih i krivo klasificiranih primjera bez puno izmjena uobičajenih dubokih modela. U poglavlju~\ref{chap:eksperimenti} su prikazani rezultati nekih eksperimenata s nekima od opisanih pristupa.

\subsection{Aproksimacija bayesovske neuronske mreže pomoću dropouta} \label{subsec:bnm-dropout}

\textit{Dropout}, opisan u pododjeljku~\ref{subsec:dropout}, je postupak koji tijekom učenja nasumično isključuje jedinice i može se interpretirati kao aproksimacija učenja eksponencijalnog broja mreža koje dijele parametre. Pri testiranju se obično usrednjavanje aproksimira tako da se, umjesto isključivanja jedinica, izlazi slojeva usrednje skaliranjem koje odgovara vjerojatnosti neisključivanja. Drugi način usrednjavanja je usrednjavanje izlaza cijele mreže dobivenih uzorkovanjem uz dropout kao pri učenju \cite{Srivastava:2014:DASWPNNO,Gal:2015:DBA}, što se naziva \emphasize{MC-dropout} (\textit{Monte Carlo dropout}). Taj način usrednjavanja je ispravniji i daje bolju performansu, ali manje efikasan jer zahtijeva veći broj evaluacija izlaza uz isključivanje jedinica.

\cite{Gal:2016:BCNNBAVI} učenje s \textit{dropoutum} interpretiraju kao varijacijsko zaključivanje s Bernoullijevom razdiobom kod bayesovske neuronske mreže i pokazuju da korištenje \textit{MC-dropouta} pri testiranju daje bolje rezultate ako je mreža učena na manjem skupu za učenje. Ako pretpostavimo da  \textit{dropout} dolazi iza slojeva linearne transformacije kojima odgovaraju matrice $\vec M_l$, slučajna varijabla koja odgovara varijacijskoj razdiobi matrice težina je
\begin{align} \label{eq:dropout-matrica-tezina}
\rvec W_l = \diag\del{\sbr{\rvar z_{l,i}}_{i=1\bidot n_l}}\vec M_l \text{,}
\end{align}
gdje je $l$ indeks linearnog sloja, $n_l$ broj redaka matrice težina, tj. broj jedinica sloja, $\vec M_l$ varijacijski parametri, a $\rvar z_{l,i}$ nezavisne slučajne varijable s Bernoullijevom razdiobom s očekivanjem $p$, ako je $1-p$ vjerojatnost isključivanja. Druge parametre možemo točkasto procjenjivati, što za svaki parametar odgovara razdiobi koja ima samo jednu moguću vrijednost koja je varijacijski parametar.

Prvi član funkcije definirane izrazom~\eqref{eq:bnm-marginalna-izglednost} (očekivanje) možemo aproksimirati \textit{Monte Carlo} aproksimacijom. Ako zamijenimo redoslijed očekivanja i zbroja i odaberemo $1$ uzorak po svakom očekivanju, on postaje
\begin{align}
\sum_i \ln\p\del{\vec y_i\midmid\vec x_i,\rvec\theta=\tilde{\vec\theta}_i} \text{,}
\end{align}
gdje su $\tilde{\vec\theta}_i$ uzorci parametara iz varijacijske razdiobe $q_{\vec\phi}$. Za svaki primjer se uzima jedan uzorak parametara u jednoj iteraciji ili epohi, kao što je uobičajeno kada se koristi \textit{dropout}. Drugi član u izrazu~\eqref{eq:bnm-marginalna-izglednost} (bez minusa) je
\begin{align}
\Dkl{q_{\vec\phi}}{\p(\rvec\theta)} 
&=\int_{\vec\theta}q_{\vec\phi}(\vec\theta)\ln\frac{q_{\vec\phi}(\vec\theta)}{\p(\vec\theta)}\dif\vec\theta \\ \label{eq:dropoutvi-dkl-qp-2}
&=\int_{\vec\theta}q_{\vec\phi}(\vec\theta)\ln q_{\vec\phi}(\vec\theta)\dif\vec\theta - \int_{\vec\theta}q_{\vec\phi}(\vec\theta)\ln\p(\vec\theta)\dif\vec\theta \text{.}
\end{align}
Prvi integral u zadnjem izrazu je baskonačan zato što se faktori varijacijske razdiobe sastoje od Diracovih \textit{šiljaka}. Šiljke možemo aproksimirati proizvoljno uskim pravokutnicima širine $2\epsilon$, npr.
\begin{align}
\p({\rvec W_l}_\ind{i,j}=w) 
&= (1-p)\dirac(w)+p\dirac(w-{\vec M_l}_\ind{i,j}) \\
&\approx \frac{1-p}{2\epsilon}\enbbracket{-\epsilon<w<\epsilon}+\frac{p}{2\epsilon}\enbbracket{{-\epsilon<w-\vec M_l}_\ind{i,j}<\epsilon} \text{.}
\end{align}
Ako pretpostavimo da neke težine neće postati točno $0$, tj. bliže nuli od $2\epsilon$, prvi član u izrazu~\eqref{eq:dropoutvi-dkl-qp-2} (diferencijalna entropija varijacijske razdiobe) onda postaje konačan i neovisan o varijacijskim parametrima i može se zanemariti kod učenja. Za drugi član u izrazu~\eqref{eq:dropoutvi-dkl-qp-2} ne aproksimiramo varijacijsku razdiobu. Ona je težinski zbroj višedimenzionalnih Diracovih \textit{šiljaka} kojima se \textit{uzorkuje} apriorna razdioba. Ako se koristi Gaussova apriorna razdioba, može se pokazati da je taj član proporcionalan $p$ i zbroju kvadrata težina, što odgovara $L^2$ regularizaciji. Malo drugačiji i detaljniji izvod može se vidjeti u \cite{Gal:2015:DBA,Gal:2015:DBAA}, gdje se mreža s \textit{dropoutum} interpretira kao aproksimacija s Gaussovog procesa\footnote{\url{https://en.wikipedia.org/wiki/Gaussian_process}}. Vidimo da ako su regularizirane samo matrice težina, maksimizaciji izraza~\eqref{eq:bnm-marginalna-izglednost} odgovara minimizacija ove funkcije pogreške:
\begin{align}
E(\vec\theta;\set{D}) = -\sum_i \ln\p\del{\vec y_i\midmid\vec x_i,\rvec\theta=\tilde{\vec\theta}_i} + \frac{\lambda}{2}\sum_l\enVert{\vec M_l}_\text{F}^2 \text{,}
\end{align}
gdje $\lambda\in\R_{\geq 0}$. To je ista funkcija pogreške koja se inače koristi kod mreže s \textit{dropoutom}.

Za zaključivanje prema izrazu~\eqref{eq:zakljucivanje-y-bnm-q} može se koristiti \textit{Monte Carlo} aproksimacija (\textit{MC-dropout}):
\begin{align} \label{eq:zakljucivanje-y-bnm-q-mcd}
\p(\vec y\mid \vec x, \set{D})
\approx \E_{\tilde{\vec\theta}\sim q_{\vec\phi}}\p(\vec y\mid\vec x,\vec\theta) \approx \frac{1}{M}\sum_{i=1}^M \p\del{\vec y\midmid\vec x,\rvec\theta=\tilde{\vec\theta}_i}  \text{,}
\end{align}
gdje su $\tilde{\vec\theta}_i$ uzorci parametara iz varijacijske razdiobe $q_{\vec\phi}$.

\subsubsection{Konvolucijske mreže}

Kod konvolucijskih mreža \textit{dropoutom} se obično krši svojstvo ekvivarijantnosti, tj. za svaki položaj jezgre se nezavisno određuje hoće li se element izlaza isključit. \textit{Dropoutu} kod konvolucijskih slojeva za svaki položaj jezgre odgovara posebna slučajna varijabla prema jednadžbi~\eqref{eq:dropout-matrica-tezina}, ali sve dijele parametre $\vec M_l$. Matrici $\vec M_l$ kod konvolucijskog sloja odgovara matrica težina kao u jednadžbi~\eqref{eq:konvolucija-matrica-tezina} transponirana tako da jezgre odgovaraju recima.

Slika~\ref{fig:mc-drouput-samples-DSN} prikazuje ovisnost klasifikacijske pogreške o broju uzoraka \textit{MC-dropouta} na primjeru konvolucijske mreže. Broj uzoraka potrebnih za postizanje bolje performanse ovisi o modelu i skupu podataka. Npr. \cite{Srivastava:2014:DASWPNNO} su za nekonvolucijski model koji su ispitivali na lakšem skupu, MNIST-u, trebali više od $50$ uzoraka za postizanje manje klasifikacijske pogreške uz \textit{MC-dropout}. 

\begin{figure}
	\centering
	\includegraphics[width=1.0\textwidth]{uncertainty/DSN_samples}
	\caption{Ovisnost klasifikacijske pogreške (plavo) o broju uzoraka u \textit{Monte Carlo} aproksimaciji izlaza na mreži koju su ispitivali autori \citep{Gal:2016:BCNNBAVI} na skupu CIFAR-10 \citep{Krizhevsky:2009:LMLFTI}. Svaka točka je prosjek $5$ mjerenja i prikazane su standardne devijacije. Zeleni pravac označava klasifikacijsku pogrešku kod userdnjavanja kakvo se inače koristi kod testiranja. Slika je preuzeta iz \citet{Gal:2016:BCNNBAVI}.}
	\label{fig:mc-drouput-samples-DSN}
\end{figure}

\subsection{Prepoznavanje izvanrazdiobnih i krivo klasificiranih primjera na temelju izlaza softmaksa ili logita} \label{subsec:pristupi-ood-softmaks-logiti}

Kao što je spomenuto u odjeljku~\ref{sec:vaznost-primjene-nesigurnosti}, razdiobe koje duboki modeli daju kao izlaz softmaksa su često previše sigurne kod krive klasifikacije i nije ih dobro interpretirati kao vjerojatnosti.

\cite{Hendrycks:2016:BDMOODE} pokazuju da se krivo klasificirani i izvanrazdiobni primjeri mogu uspješnije nego što je očekivano prepoznavati klasifikacijom maksimalne vjerojatnosti softmaksa kod različitih zadataka i skupova podataka. 

\citet{Guo:2017:CMNN} pokazuju da se samo skaliranjem temperature softmaksa, tj. dodavanjem dijeljenja svih logita (ulaza softmaksa) s $T$ prije softmaksa, može značajno poboljšati kalibracija\footnote{Model je dobro kalibriran ako svaka vjerojatnost koju djeljuje nekoj klasi slična stvarnoj učestalosti te klase kada model dodjeljuje tu vjerojatnost.} već naučene mreže. Kod skaliranja temperature, ako su logiti $\vec s$ ($h(\vec x)=\softmax(\vec s)$), izlazni vektor vjerojatnosti uz skaliranje temperature je $\softmax\del{\frac{1}{T}\vec s}$. Optimalni $T$ se traži na validacijskom skupu. \citet{Guo:2017:CMNN} su još isprobali nekoliko složenijih postupaka, ali s njima nisu dobili bolje rezultate. Još nešto zanimljivo što su zaključili je da se optimalne općenitije transfomacije logita kao $\softmax(\vec s\oslash\vec t)$ otprilike svode na skaliranje temperature, tj. vrijedi $\vec t^*\approx T^*\cvec 1$ gdje su $\vec t^*$ i $T^*$ optimalni. 

\cite{Liang:2017:PDOODENN} predlažu dva poboljšanja klasifikacije maksimalne vrijednosti softmaksa. Jedno poboljšanje je skaliranje temperature. Pokazuju da, što je veća temperatura, to se primjeri izvanrazdiobni primjeri mogu bolje odvojiti od unutarrazdiobnih primjera na temelju maksimalne vrijednosti softmaksa. Drugo poboljšanje je izmjena ulaza mreže tako da se FGSM-om (jednadžba~\eqref{eq:FGSM}) pomakne u smjeru povećavanja maksimalnog izlaza softmaksa (za razliku od smanjivanja kod neprijateljskih primjera):
\begin{equation} \label{eq:ODIN-FGSM}
\tilde{\vec x} = \vec x - \epsilon\sgn\nabla_{\vec x}\del{-\ln \del{\max_k h(\vec x)_\ind{k}}} \text{.}
\end{equation}
$\epsilon$ je parametar koji se određuje pomoću izdvojenog skupa izvanrazdiobnih primjera. \cite{Liang:2017:PDOODENN} pokazuju da takav pomak ulaznog primjera ima veći utjecaj na unutarrazdiobne primjere i tako ih bolje razdvaja od izvanrazdiobnih.

Za ovaj rad su još ispitani slični pristupi kod kojih se umjesto maksimalnog izlaza softmaksa klasificira maskimalni logit



\chapter{Eksperimenti} \label{chap:eksperimenti}

Eksperimentalno su ispitani neki od pristupa za razlikovanje aleatorne i epistemičke nesigurnosti (odjeljak~\ref{sec:razlikovanje-aleatorne-epistemicke}) i neki od pristupa za prepoznavanje izvanrazdiobnih primjera (odjeljak~\ref{sec:pristupi-procjena-nesigurnosti}). 

Korišten je programski jezik Python i biblioteke TensorFlow, NumPy, PyTorch, Scikit-image, Scikit-learn, Matplotlib, SciPy i druge. Programski kod je u repozitoriju \url{https://github.com/Ivan1248/deep-learning-uncertainty}.


\section{Evaluacijske mjere za klasifikaciju}

U ovom odjeljku su opisane evaluacijske mjere korištene u eksperimentima.

\subsection{Binarna klasifikacija}

Kod binarne klasifikacije klase dijelimo na \emphasize{pozitivnu klasu} i \emphasize{negativnu klasu}. Primjere iz skupa korištenog za ispitivanje prema predikcijama klasifikatora dijelimo u $4$ skupine:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item \emphasize{stvarno pozitivni} (engl. \textit{true positives}, TP) --- pozitivno klasificirani pozitivni primjeri
	\item \emphasize{stvarno negativni} (engl. \textit{true negatives}, TN) --- negativno klasificirani negativni primjeri
	\item \emphasize{lažno pozitivni} (engl. \textit{false positives}, FP) --- pozitivno klasificirani negativni primjeri
	\item \emphasize{lažno negativni} (engl. \textit{true negatives}, FN) --- negativno klasificirani pozitivni primjeri.
\end{enumerate}
Neka $h(\vec x_i)$ označava predikciju modela za primjer $\vec x_i$ čija je stvarna oznaka $y_i$. Ovako ćemo označavati brojeve primjera u navedenim skupinama:
\begin{align}
\begin{aligned}
\TP&\coloneqq\sum_i\enbbracket{h(\vec x_i)=1}\enbbracket{y_i=1} \text{, }
\FP\coloneqq\sum_i\enbbracket{h(\vec x_i)=1}\enbbracket{y_i=0} \text{,} \\
\FN&\coloneqq\sum_i\enbbracket{h(\vec x_i)=0}\enbbracket{y_i=1} \text{, }
\TN\coloneqq\sum_i\enbbracket{h(\vec x_i)=0}\enbbracket{y_i=0} \text{.}
\end{aligned}
\end{align}
To možemo prikazati konfuzijskom matricom kao na slici~\ref{fig:konfuzijska-matrica}. Ako je $N$ ukupan broj primjera, vrijedi $N=\TP+\TN+\FP+\FN$. 

\begin{figure}
	\centering
	\begin{tabular}{cccc}
	&                        & \multicolumn{2}{c}{$y$}                                 \\ \cline{3-4} 
	& \multicolumn{1}{c|}{}  & \multicolumn{1}{c|}{1}     & \multicolumn{1}{c|}{0}     \\ \cline{2-4} 
	\multicolumn{1}{c|}{\multirow{2}{*}{$h(\vec x)$}} & \multicolumn{1}{c|}{1} & \multicolumn{1}{c|}{$\TP$} & \multicolumn{1}{c|}{$\FP$} \\ \cline{2-4} 
	\multicolumn{1}{c|}{}                             & \multicolumn{1}{c|}{0} & \multicolumn{1}{c|}{$\FN$} & \multicolumn{1}{c|}{$\TN$} \\ \cline{2-4} 
	\end{tabular}
	\caption{Konfuzijska matrica kod binarne klasifikacije. Stupcima odgovaraju stvarne klase, a recima predikcije.}
	\label{fig:konfuzijska-matrica}
\end{figure}

Neke od češćih evaluacijskih mjera za binarnu klasifikaciju su:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item \emphasize{točnost} (engl. \textit{accuracy}) --- udio točno klasificiranih primjera: $A\coloneqq\frac{\TP+\TN}{N}=\frac{\TP+\TN}{\TP+\FP+\TN+\FN}$
	\item \emphasize{preciznost} (engl. \textit{precision}) --- udio stvarno pozitivnih primjera u pozitivno klasificiranim primjerima: $P\coloneqq\frac{\TP}{\TP+\FP}$
	\item \emphasize{odziv} ili \emphasize{stopa stvarnih pozitiva} (engl. \textit{recall}, \textit{true positive rate}) --- udio stvarno pozitivnih primjera u pozitivnim primjerima: $R\coloneqq \TPR\coloneqq\frac{\TP}{\TP+\FN}$
	%\item \emphasize{specifičnost} (engl. \textit{specificity}, \textit{true negative rate}) --- udio stvarno negativnih primjera u negativnim primjerima: $\mathit{TNR}\coloneqq\frac{\TN}{\TN+\FP}$
	\item \emphasize{stopa lažnih pozitiva} (engl. \textit{false positive rate}) --- udio lažno pozitivnih primjera u negativnim primjerima: $\FPR\coloneqq\frac{\FP}{\TN+\FP}$%=1-\mathit{TNR}$
	\item \emphasize{mjera $F_1$} - harmonijska sredina preciznosti i odziva: $F_1\coloneqq\frac{2}{P^{-1}+R^{-1}}=\frac{2PR}{P+R}=\frac{2\TP}{2\TP+\FP+\FN}$
	\item \emphasize{Jaccardov indeks} ili \emphasize{omjer presjeka i unije} (engl. \textit{intersection over union}) - udio točno klasificiranih primjera u uniji pozitivnih i pozitivno klasificiranih primjera: $J\coloneqq\IoU\coloneqq\frac{\TP}{\TP+\FP+\FN}=\frac{1}{P^{-1}+R^{-1}-1}$.
\end{enumerate}
Kod binarne klasifikacije (ne kod višeklasne) su $F_1$ i $J$ ekvivalentne u smislu da se jedna može izraziti preko druge --- $F_1$ je harmonijska sredina između $J$ i $1$: $F_1=\frac{2}{J^{-1}+1}$.

\subsubsection{Mjere neovisne o pragu klasifikatora}

Obično se kod binarne klasifikacije kao izlaz dobiva realni broj koji može, ali ne mora, predstavljati vjerojatnost pozitivne klase. Ako je on veći od praga, primjer se klasificira u pozitivnu klasu, a inače u negativnu. Promjenom praga možemo mijenjati odnos preciznosti i odziva. Za najniži prag je odziv $1$, a za najviši je $0$. Ovisnost preciznosti o odzivu se može prikazati monotono padajućom krivuljom koju nazivamo \emphasize{krivulja preciznosti i odziva}, kraće \emphasize{PR-krivulja}. Klasifikator možemo evaluirati neovisno o pragu računanjem \emphasize{prosječne preciznosti} koja je definirana kao površina ispod PR-krivulje, tj. integriranjem preciznosti kao funkcije o odzivu:
\begin{align}
\AP \coloneqq \int_0^1 P(R)\dif R \text{.}
\end{align}
Prosječna preciznost je, kao i preciznost, ovisna o omjeru klasa u skupu za testiranje. Odziv i stopa lažnih pozitiva nisu. Krivulja koja opisuje odnos između odziva (stope stvarnih pozitiva) i stope lažnih pozitiva naziva se \emphasize{ROC-krivulja} (engl. \textit{receiver operating characteristic}). Ona nije ovisna o omjeru klasa. \emphasize{Površina ispod ROC-krivulje},
\begin{align}
\AUROC \coloneqq \int_0^1 \FPR(R)\dif R \text{,}
\end{align}
se može interpretirati kao vjerojatnost da će kod klasifikatora neki pozitivni primjer  biti pozitivniji od nekog negativnog primjera. Za nasumični klasifikator je očekivanje te površine $\frac{1}{2}$.

\subsection{Višeklasna klasifikacija}

Kod višeklasne klasifikacije u $C$ klasa, konfuzijska matrica je dimenzija $C\times C$. Njen element s indeksima $\sbr{i,j}$ predstavlja broj primjera klasificiranih u klasu $i$ i pripadaju klasi $j$. Za svaku klasu $k$ možemo definirati
\begin{align}
\begin{aligned}
\TP_k&\coloneqq\sum_i\enbbracket{h(\vec x_i)=k}\enbbracket{y_i=k} \text{, }
\FP_k\coloneqq\sum_i\enbbracket{h(\vec x_i)=k}\enbbracket{y_i\neq k} \text{,} \\
\FN_k&\coloneqq\sum_i\enbbracket{h(\vec x_i)\neq k}\enbbracket{y_i=k} \text{, }
\TN_k\coloneqq\sum_i\enbbracket{h(\vec x_i)\neq k}\enbbracket{y_i\neq k} \text{.}
\end{aligned}
\end{align}

%\begin{align}
%\TP\coloneqq\sum_k\TP_k \text{, }
%\FP\coloneqq\sum_k\FP_k \text{, }
%\FN\coloneqq\sum_k\FN_k \text{.} 
%\end{align}

Neke od evaluacijskih mjera za višeklasnu klasifikaciju u $C$ klasa su:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item \emphasize{točnost} (engl. \textit{accuracy}) --- udio točno klasificiranih primjera: $A\coloneqq\frac{\sum_k \TP_k}{N}$
	\item \emphasize{makro-usrednjena preciznost} (engl. \textit{macro-averaged precision}) --- srednja preciznost po klasama: $P_\text{m}\coloneqq\frac{1}{C}\sum_k P_k$, gdje $P_k\coloneqq\frac{\TP_k}{\TP_k+\FP_k}$
	\item \emphasize{srednja prosječna preciznost preciznost} (engl. \textit{mean average precision}) --- srednja prosječna preciznost po klasama: $\mathit{mAP}\coloneqq\frac{1}{C}\sum_k \AP_k$, gdje $\AP_k\coloneqq\int_0^1 P_k(R_k)\dif R_k$
	\item \emphasize{makro-usrednjeni Jaccardov indeks} ili \emphasize{srednji omjer presjeka i unije} (engl. \textit{mean intersection over union}) - srednji Jaccardov indeks po klasama: $J_\text{m}\coloneqq\mIoU\coloneqq\frac{1}{C}\sum_k J_k$, gdje $J_k\coloneqq\frac{\TP_k}{\TP_k+\FP_k+\FN_k}$.
\end{enumerate}

%Kod višeklasne klasifikacije navedenim evaluacijskim mjerama odgovaraju te mjere usrednjene po klasama, najčešće srednja preciznost . Za svaku klasu $k$ se posebno gledaju $\TP_k$,$\TN_k$,$\FP_k$,$\FN_k$ tako da nju uzimamo kao pozitivnu klasu, a sve ostale kao negativnu. Npr. srednja (\textit{makro-usrednjena}) preciznost (engl. \textit{mean precision}) je definirana kao aritmetička sredina preciznosti svih klasa: $P_\text{m}\coloneqq\frac{1}{C}\sum_k P_k$. Tako usrednjene mjere ćemo označavati s $\text{m}$ u indeksu. Za svaku klasu $k$ vrijedi $A_\text{m}=A_k=\frac{1}{N}\sum_k \TP_k$, gdje je $N$ ukupan broj primjera.

\subsection{Semantička segmentacija}

Kod semantičke segmentacije ulazni primjeri su slike i svakom pikselu se dodjeljuje oznaka. Kod evaluacije se obično pikseli iz svih slika iz skupa za ispitivanje smatraju nezavisnim primjerima, pa je zbroj svih elemenata konfuzijske matrice $\envert{\set D}HW$, gdje je $\envert{\set D}$ broj slika u skupu za ispitivanje, a $H$ i $W$ prostorne dimenzije slika. Kod semantičke segmentacije se često koriste točnost i srednji omjer presjeka i unije.


\section{Procjena i razlikovanje nesigurnosti kod semantičke segmentacije pomoću MC-dropouta}

Aproksimacija bayesovske neuronske mreže pomoću \textit{dropouta} \citep{Gal:2015:DBA,Gal:2015:DBA,Gal:2016:BCNNBAVI} je opisana u pododjeljku~\ref{subsec:bnm-dropout}. Neki pristupi \citep{Kendall:2017:WUNBDLCV,Smith:2018:UMUAED} za razlikovanje aleatorne i epistemičke nesigurnosti pomoću \textit{dropouta} su opisani u pododjeljku~\ref{sec:razlikovanje-aleatorne-epistemicke}. \citet{Kendall:2017:WUNBDLCV} su postupak opisan u pododjeljku~\ref{subsec:bnm-dropout} koristili na konvolucijskim mrežama i zadatku semantičke segmentacije, gdje se svakom pikselu dodeljuje oznaka, i na zadatku procjene prostorne dubine (regresije) svakog piksela ulazne slike. 

Kako bi razlikovali aleatornu i epistemičku nesigurnosti kod semantičke segmentacije, \citet{Kendall:2017:WUNBDLCV} aleatornu nesigurnost modeliraju pomoću predikcije varijanci logita svakog piksela kao što je opisano u pododjeljku~\ref{subsec:eksplicitno-modeliranje-aleatorne}, tj. gubitak za svaki piksel je negativni logaritam vjerojatnosti ciljne klase, ali vjerojatnosti se računaju kao očekivanje izlaza softmaksa po razdiobi logita, kao što je opisano jednadžbom~\eqref{eq:kendall-gubitak-klasifikacija}. Očekivanje se procjenjuje \textit{Monte Carlo} aprosksimacijom. Za semantičku segmentaciju se ukupan gubitak jedne slike računa kao srednji gubitak po pikselima. Kao mjeru epistemičke nesigurnosti, \citet{Kendall:2017:WUNBDLCV} za svaki piksel koriste entropiju njegove izlazne razdiobe dobivene uz \textit{MC-dropout}.

Ovaj pristup nije do kraja ostvaren i umjesto njega je isproban \textit{MC-dropout} uz procjenu epistemičke nesigurnosti međusobnom informacijom kao što je opisano u pododjeljku~\ref{subsec:mi-epistemicka} \citep{Smith:2018:UMUAED}.

\subsubsection{Modeli i skupovi podataka}

Za ovaj rad su ispitane neke od tih ideja na zadatku semantičke segmentacije. Umjesto mreže koju su koristili \citet{Kendall:2017:WUNBDLCV}, korištena je mreža LadderDensenet-121 \citep{Kreso:2017:LSDFSSLNI}, za koju je potrebno manje memorije. Korištena je vlastita implementacija te mreže koja ne postiže jednako dobru performansu kao originalna iako nije poznata razlika u inicijalizaciji i učenju. Ta mreža će se označavati s \textit{LadderDensenet-121-V}. Na validacijskom skupu Cityscapesa \citep{Cordts:2016:Cityscapes} LadderDensenet-121-V bez \textit{dropouta} postiže srednji omjer presjeka i unije $\mIoU=0.6721\pm0.007$ i točnost piksela $A=0.9459\pm0.0006$ (sredina i standardna devijacija skupa od $5$ mjerenja), što je značajno manje od $\mIoU=0.7282$ i $A=0.9506$ kod originalne implementacije. Na skupu za testiranje CamVida \citep{Brostow:2008:CamVid} ista mreža uz isti postupak učenja postiže $\mIoU=0.6774\pm0.0031$ i $A=0.9176\pm0.0025$. Pokazalo se da dodavanje \textit{dropouta} s vjerojatnošću isključivanja $1-p=0.2$, prema \citep{Huang:2016:DCCN}, loše utječe na performansu modela. Čini se da ni vjerojatnost isključivanja $0.1$ nema značajno pozitivan utjecaj na rezultat u odnosu na mrežu bez \textit{dropouta}, pogotovo za Cityscapes, koji je veći skup od CamVida. 

Unatoč lošijoj performansi, za eksperimente je korištena mreža s vjerojatnošću isključivanja $0.2$ kako aposteriorna razdioba parametara ne bi imala premalu entropiju i različiti uzorci mreže s \textit{dropoutom} ne bi bili previše slični, što bi onemogućilo dobro procjenjivanje epistemičke nesigurnosti predikcije, koja proizlazi iz nesigurnosti u parametre. Kako nije bilo dovoljno memorije za učenje mreže s \textit{dropoutom} na slikama iz Cityscapesa umanjenim na dimenzije $1024\times448$, kao kod \citet{Kreso:2017:LSDFSSLNI}, pri učenju je korišteno nasumično izrezivanje dijelova slika dimenzija $448\times448$ i broj epoha je povećan s $30$ na $80$. Kod CamVida su slike dimenzija $480\times360$ i bilo je dovoljno memorije. Veličina mini-grupe za CamVid je bila $8$. 

Za \textit{MC-dropout} je, kao kod \cite{Kendall:2017:WUNBDLCV} za evaluaciju korišteno po $50$ uzoraka, tj. unaprijednih prolaza s \textit{dropoutom}, za procjenu izlazne razdiobe klasa za svaki primjer.

\subsubsection{Rezultati}

U tablici~\ref{tab:evaluacija-camvid} su prikazani rezultati evaluacije različitih modela učenih na CamVidu (osim podskupa za testiranje). Može se vidjeti da MC-dropout skoro uvijek ima pozitivan učinak na evaluaciju u odnosu na obični \textit{dropout}.

\begin{table}
	\centering\small
	\begin{tabular}{lrr}
		\toprule
		\bfseries Model & $\mIoU$ & $A$ \\
		\midrule
		DenseNet + \textit{dropout} \citep{Kendall:2017:WUNBDLCV} & $0.671$ & - \\
		+ aleatorna nesigurnost & $0.672$ & - \\
		+ \textit{MC-dropout} & $0.673$ & -  \\
		+ aleatorna nesigurnost i \textit{MC-dropout} & $0.674$ & -\\
		\midrule
		LadderDenseNet-121-V & $0.677$ & $0.918$ \\
		+ \textit{dropout}-$0.1$ & $0.678$ & $0.913$ \\
		+ \textit{MC-dropout}-$0.1$ & $0.677$ & $0.915$ \\
		+ \textit{dropout}-$0.2$ & $0.661$ & $0.912$ \\
		+ \textit{MC-dropout}-$0.2$ & $0.665$ & $0.913$
		\\\bottomrule
	\end{tabular}
	\caption{Usporedba rezultata evaluacije na skupu CamVid. Vrijednosti za LadderDenseNet-121-V bez \textit{dropouta} je prosjek $5$ evaluacija, vrijednosti za LadderDenseNet-121-V s običnim \textit{dropoutom} i \textit{MC-dropoutom} su prosjek $2$ evaluacije za vjerojatnost isključivanja $0.1$ i $2$ evaluacije za vjerojatnost isključivanja $0.2$.}
	\label{tab:evaluacija-camvid}
\end{table}



CamVid -- $1/4$, $1/2$ i cijeli skup za učenje -- usporedba aleatorne i epistemičke nesigurnosti kao u \cite{Smith:2018:UMUAED}

kalibracija nesigurnosti -- ako stignem

eksplicitna aleatorna nesigurnost s Gaussovom razdiobom logita kao u \cite{Kendall:2017:WUNBDLCV} -- ako stignem (mislim da neću)

slike -- primjeri izlaza

\section{Prepoznavanje izvanrazdiobnih i krivo klasificiranih primjera na temelju izlaza softmaksa ili logita kod klasifikacije slika}

Isprobani su postupci koji su opisani u odjeljku~\ref{subsec:pristupi-ood-softmaks-logiti}, tj. prepoznavanje izvanrazdiobnih primjera na temelju maksimalnog izlaza softmaksa \citep{Hendrycks:2016:BDMOODE} i postupak predložen u \cite{Liang:2017:PDOODENN}. Uz to su isprobani analogni postupci kod kojih se klasifikacija provodi na temelju maksimalnog logita -- klasifikacija na temelju maksmialnog logita uz pomak i bez pomaka ulaza u smjeru povećanja vjerojatnosti klase maksimalnog izlaza softmaksa prema izrazu~\eqref{eq:ODIN-FGSM}.

\subsubsection{Modeli}

Za ispitivanje su korištene rezidualna mreža WRN-28-10 \citep{Zagoruyko:2016:WRN} i mreža DenseNetBC \citep{Huang:2016:DCCN} s dubinom $L=100$ i faktorom rasta (engl. \textit{growth rate}) $k=12$, koja će biti označavana s \textit{DN-100-12}. Ni kod jedne mreže se ne koristi \textit{dropout}. Korištene su vlastite implementacije tih mreža koje se ne bi trebale previše razlikovati od originalnih, tj. trebalo bi biti sve isto kao što je opisano u \citet{Zagoruyko:2016:WRN,Huang:2016:DCCN}. I jedna i druga ipak postižu malo manju točnost od originalnih mreža na skupu za testiranje skupa CIFAR-10 \citep{Krizhevsky:2009:LMLFTI}. Od mreža korištenih za ispitivanje, WRN-28-10 ima točnost oko $0.957$, a DN-100-12 oko $0.948$.

\subsubsection{Izvanrazdiobni skupovi}

Za ove eksperimente je kao unutarrazdiobni skup korišten podskup za testiranje iz skupa CIFAR-10. Slike su dimenzija $32\times 32$ i ima ih $10000$ u skupu za testiranje. Za izvanrazdiobne skupove su, slično kao kod \cite{Hendrycks:2016:BDMOODE,Liang:2017:PDOODENN}, korišteni skupovi:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
	\item TinyImageNet\footnote{\url{https://tiny-imagenet.herokuapp.com/}} --- podskup ImageNet-a \citep{Deng:2009:ILSHID} sa slikama iz $200$ klasa. Skup za testiranje sadrži $10000$ slika. Za ove eksperimente su iz skupa za testiranje konstruirana dva skupa: TinyImageNet-C, kojeg čine slike iz kojih su nasumično izrezani dijelovi dimenzija $32\times 32$, i TinyImageNet-R, kojeg čine slike umanjene na iste dimenzije, tj. dimenzije slika iz skupa CIFAR-10.
	\item LSUN \citep{Yu:2015:LSUN} --- skup sličan TinyImageNetu. Skup za testiranje sastoji se od $10000$ slika. Kao i za TinyImageNet, iz skupa za testiranje konstruirana su dva skupa: LSUN-C, kojeg čine slike iz kojih su nasumično izrezani dijelovi dimenzija $32\times 32$, i LSUN-R, kojeg čine slike umanjene slike.
	\item iSUN \citep{Xu:2015:TCSWBET} --- podskup SUN-a \citep{Xiao:2016:SUN}. Za eksperimente se koriste sve slike iSUN-a umanjene na dimenzije $32\times 32$.
	\item Gaussov šum --- slučajni uzorci nizova dimenzija $32\times 32\times 3$ tako da svaki element ima nezavisnu vrijednost iz Gaussove razdiobe s očekivanjem $0$ i varijancom $1$.
	\item Uniformni šum --- slučajni uzorci nizova dimenzija $32\times 32\times 3$ tako da svaki element ima nezavisnu vrijednost iz uniformne razdiobe s očekivanjem $0$ i varijancom $1$.
\end{enumerate}
Kao i kod učenja, za svaki skup, slike koje se daju kao ulaz mreži su normalizirane oduzimanjem prosječne vrijednosti i dijeljenjem sa standardnom devijacijom svake komponente (RGB) prema pikselima u skupu za učenje (i validaciju).

\subsubsection{Odabir parametara}

Na temelju rezultata u \cite{Liang:2017:PDOODENN}, koji pokazuju da su veće temperature bolje, za eksperimente u kojima se koristi temperaturno skaliranje logita prije softmaksa koristi se temperatura $T=1000$. Za odabir veličine pomaka $\epsilon$ iz svakog izvanrazdiobnog skupa se izvoji $1000$ slika. Optimalni $\epsilon$ se traži u skupu $\cbr{0,10^{-3},2\cdot 10^{-3},\bidot,12\cdot 10^{-3}}$. I kod mreže WRN-28-10 i kod mreže DN-100-12 (vlastitih implementacija), optimalni $\epsilon$ je ispadao oko $5$ puta veći nego kod \citet{Liang:2017:PDOODENN} za svaki izvanrazdiobni skup.

\subsubsection{Rezultati}

Rezultati glavnih eksperimenata su prikazani u tablicama~\ref{tab:ood-dn-cifar}~i~\ref{tab:ood-wrn-cifar}. Za svaku evaluacijsku mjeru, $5$ stupaca redom predstavlja klasifikaciju maksimalne vrijednosti:
\begin{enumerate}[topsep=0pt,itemsep=0pt,partopsep=0pt]
\item softmaksa uz $T=1$
\item softmaksa uz $T=1000$ (ili logita s pomakom ulaza uz $T\gg 1$)
\item softmaksa uz $T=1000$ i pomak ulaza
\item logita (uz bilo koji $T$)
\item logita uz pomak ulaza za $T=1$.
\end{enumerate}

\begin{table} \centering
	\resizebox{\textwidth}{!}{%
		\begingroup
		\newcommand\hnc[1]{\phantom{\mathbf{00.0}}\mathllap{#1}}
		\begin{tabular}{llllll}
			\toprule
			{} &                                             $\mathit{FPR}_{R=0.95}/\%$ &                                                    $\mathit{AUROC}/\%$ &                                             $\mathit{AP}_\text{in}/\%$ &                                            $\mathit{AP}_\text{out}/\%$ &                                       $\epsilon/10^{-3}$ \\
			\midrule
			CIFAR-10       &  $\hnc{95.0}\;\hnc{\mathbf{95.0}}\;\hnc{95.0}\;\hnc{95.0}\;\hnc{95.0}$ &  $\hnc{\mathbf{50.0}}\;\hnc{50.0}\;\hnc{50.0}\;\hnc{50.0}\;\hnc{50.0}$ &  $\hnc{\mathbf{62.1}}\;\hnc{52.6}\;\hnc{52.6}\;\hnc{52.6}\;\hnc{52.6}$ &  $\hnc{\mathbf{47.4}}\;\hnc{47.4}\;\hnc{47.4}\;\hnc{47.4}\;\hnc{47.4}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}$ \\
			Gaussian       &  $\hnc{74.3}\;\hnc{6.1}\;\hnc{\mathbf{0.0}}\;\hnc{0.0}\;\hnc{0.0}$ &  $\hnc{93.3}\;\hnc{97.0}\;\hnc{\mathbf{98.9}}\;\hnc{98.9}\;\hnc{98.9}$ &  $\hnc{96.2}\;\hnc{98.3}\;\hnc{\mathbf{99.3}}\;\hnc{99.3}\;\hnc{99.3}$ &  $\hnc{85.2}\;\hnc{91.2}\;\hnc{\mathbf{96.8}}\;\hnc{96.8}\;\hnc{96.8}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{2.0}\;\hnc{0.0}\;\hnc{2.0}$ \\
			LSUN-C         &  $\hnc{54.0}\;\hnc{\mathbf{33.3}}\;\hnc{33.3}\;\hnc{39.5}\;\hnc{33.3}$ &  $\hnc{91.8}\;\hnc{\mathbf{94.5}}\;\hnc{94.5}\;\hnc{93.1}\;\hnc{94.5}$ &  $\hnc{94.1}\;\hnc{\mathbf{95.5}}\;\hnc{95.5}\;\hnc{94.3}\;\hnc{95.5}$ &  $\hnc{88.0}\;\hnc{\mathbf{92.9}}\;\hnc{92.9}\;\hnc{91.3}\;\hnc{92.9}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}$ \\
			LSUN-R         &  $\hnc{48.7}\;\hnc{18.9}\;\hnc{\mathbf{12.1}}\;\hnc{15.0}\;\hnc{12.1}$ &  $\hnc{93.1}\;\hnc{96.8}\;\hnc{\mathbf{97.7}}\;\hnc{97.4}\;\hnc{97.7}$ &  $\hnc{95.1}\;\hnc{97.5}\;\hnc{\mathbf{98.1}}\;\hnc{97.9}\;\hnc{98.1}$ &  $\hnc{89.8}\;\hnc{95.9}\;\hnc{\mathbf{97.4}}\;\hnc{96.8}\;\hnc{97.4}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{7.0}\;\hnc{0.0}\;\hnc{7.0}$ \\
			TinyImageNet-C &  $\hnc{52.1}\;\hnc{23.9}\;\hnc{18.8}\;\hnc{20.4}\;\hnc{\mathbf{18.8}}$ &  $\hnc{92.5}\;\hnc{96.0}\;\hnc{96.2}\;\hnc{\mathbf{96.3}}\;\hnc{96.2}$ &  $\hnc{94.6}\;\hnc{96.8}\;\hnc{96.5}\;\hnc{\mathbf{96.9}}\;\hnc{96.5}$ &  $\hnc{88.9}\;\hnc{94.7}\;\hnc{\mathbf{95.8}}\;\hnc{95.5}\;\hnc{95.8}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{6.0}\;\hnc{0.0}\;\hnc{6.0}$ \\
			TinyImageNet-R &  $\hnc{58.5}\;\hnc{39.5}\;\hnc{\mathbf{36.5}}\;\hnc{37.0}\;\hnc{36.5}$ &  $\hnc{90.3}\;\hnc{92.4}\;\hnc{92.3}\;\hnc{\mathbf{92.7}}\;\hnc{92.3}$ &  $\hnc{92.6}\;\hnc{93.6}\;\hnc{92.9}\;\hnc{\mathbf{93.6}}\;\hnc{92.9}$ &  $\hnc{86.2}\;\hnc{90.6}\;\hnc{91.3}\;\hnc{\mathbf{91.4}}\;\hnc{91.3}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{6.0}\;\hnc{0.0}\;\hnc{6.0}$ \\
			Uniform        &  $\hnc{74.3}\;\hnc{6.1}\;\hnc{\mathbf{0.0}}\;\hnc{0.0}\;\hnc{0.0}$ &  $\hnc{93.3}\;\hnc{97.0}\;\hnc{\mathbf{98.9}}\;\hnc{98.9}\;\hnc{98.9}$ &  $\hnc{96.2}\;\hnc{98.3}\;\hnc{\mathbf{99.3}}\;\hnc{99.3}\;\hnc{99.3}$ &  $\hnc{85.2}\;\hnc{91.2}\;\hnc{\mathbf{96.8}}\;\hnc{96.8}\;\hnc{96.8}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{2.0}\;\hnc{0.0}\;\hnc{2.0}$ \\
			iSUN           &  $\hnc{51.1}\;\hnc{20.5}\;\hnc{\mathbf{12.7}}\;\hnc{15.5}\;\hnc{12.7}$ &  $\hnc{92.9}\;\hnc{96.6}\;\hnc{\mathbf{97.6}}\;\hnc{97.3}\;\hnc{97.6}$ &  $\hnc{95.4}\;\hnc{97.7}\;\hnc{\mathbf{98.2}}\;\hnc{98.0}\;\hnc{98.2}$ &  $\hnc{88.3}\;\hnc{95.2}\;\hnc{\mathbf{97.0}}\;\hnc{96.3}\;\hnc{97.0}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{7.0}\;\hnc{0.0}\;\hnc{7.0}$ \\
			\bottomrule
		\end{tabular}
		\endgroup
	}
	\caption{DN-100-12, CIFAR-10, $A = 0.9481$, $T=1000$ (softmax, t= logits softmax-perturb logits-perturb).}
	\label{tab:ood-dn-cifar}
\end{table}


\begin{table} \centering
	\resizebox{\textwidth}{!}{%
		\begingroup
		\newcommand\hnc[1]{\phantom{\mathbf{00.0}}\mathllap{#1}}
		\begin{tabular}{llllll}
			\toprule
			{} &                                             $\mathit{FPR}_{R=0.95}/\%$ &                                                    $\mathit{AUROC}/\%$ &                                             $\mathit{AP}_\text{in}/\%$ &                                            $\mathit{AP}_\text{out}/\%$ &                                       $\epsilon/10^{-3}$ \\
			\midrule
			TinyImageNet-C &  $\hnc{51.8}\;\hnc{35.7}\;\hnc{\mathbf{32.0}}\;\hnc{34.0}\;\hnc{32.0}$ &  $\hnc{90.6}\;\hnc{93.1}\;\hnc{93.3}\;\hnc{92.3}\;\hnc{\mathbf{93.3}}$ &  $\hnc{92.5}\;\hnc{\mathbf{94.1}}\;\hnc{93.8}\;\hnc{92.2}\;\hnc{93.8}$ &  $\hnc{87.4}\;\hnc{91.7}\;\hnc{92.5}\;\hnc{91.8}\;\hnc{\mathbf{92.5}}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{4.0}\;\hnc{0.0}\;\hnc{4.0}$ \\
			TinyImageNet-R &  $\hnc{55.0}\;\hnc{43.2}\;\hnc{\mathbf{42.7}}\;\hnc{49.8}\;\hnc{42.7}$ &  $\hnc{89.4}\;\hnc{\mathbf{90.2}}\;\hnc{90.0}\;\hnc{85.1}\;\hnc{90.0}$ &  $\hnc{\mathbf{90.3}}\;\hnc{90.1}\;\hnc{89.6}\;\hnc{83.5}\;\hnc{89.6}$ &  $\hnc{86.0}\;\hnc{88.8}\;\hnc{\mathbf{88.9}}\;\hnc{85.2}\;\hnc{88.9}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{1.0}\;\hnc{0.0}\;\hnc{1.0}$ \\
			LSUN-C         &  $\hnc{37.4}\;\hnc{\mathbf{17.2}}\;\hnc{17.2}\;\hnc{37.0}\;\hnc{17.2}$ &  $\hnc{94.3}\;\hnc{96.6}\;\hnc{96.6}\;\hnc{89.1}\;\hnc{\mathbf{96.6}}$ &  $\hnc{95.6}\;\hnc{97.0}\;\hnc{97.0}\;\hnc{87.6}\;\hnc{\mathbf{97.0}}$ &  $\hnc{91.5}\;\hnc{96.0}\;\hnc{96.0}\;\hnc{90.0}\;\hnc{\mathbf{96.0}}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}\;\hnc{0.0}$ \\
			LSUN-R         &  $\hnc{47.3}\;\hnc{28.0}\;\hnc{22.3}\;\hnc{23.8}\;\hnc{\mathbf{22.3}}$ &  $\hnc{92.6}\;\hnc{94.6}\;\hnc{\mathbf{94.8}}\;\hnc{94.1}\;\hnc{94.8}$ &  $\hnc{94.2}\;\hnc{\mathbf{95.2}}\;\hnc{94.7}\;\hnc{93.8}\;\hnc{94.7}$ &  $\hnc{89.4}\;\hnc{93.5}\;\hnc{\mathbf{94.6}}\;\hnc{94.1}\;\hnc{94.6}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{4.0}\;\hnc{0.0}\;\hnc{4.0}$ \\
			iSUN           &  $\hnc{49.0}\;\hnc{31.8}\;\hnc{\mathbf{25.8}}\;\hnc{26.5}\;\hnc{25.8}$ &  $\hnc{91.8}\;\hnc{93.9}\;\hnc{\mathbf{94.3}}\;\hnc{93.4}\;\hnc{94.3}$ &  $\hnc{94.0}\;\hnc{\mathbf{95.0}}\;\hnc{94.9}\;\hnc{93.7}\;\hnc{94.9}$ &  $\hnc{87.4}\;\hnc{91.9}\;\hnc{93.3}\;\hnc{92.8}\;\hnc{\mathbf{93.3}}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{3.0}\;\hnc{0.0}\;\hnc{3.0}$ \\
			Uniform        &  $\hnc{88.2}\;\hnc{71.8}\;\hnc{\mathbf{0.0}}\;\hnc{0.0}\;\hnc{0.0}$ &  $\hnc{87.4}\;\hnc{91.6}\;\hnc{98.7}\;\hnc{\mathbf{98.7}}\;\hnc{98.7}$ &  $\hnc{92.6}\;\hnc{95.0}\;\hnc{99.1}\;\hnc{\mathbf{99.1}}\;\hnc{99.1}$ &  $\hnc{75.1}\;\hnc{82.5}\;\hnc{97.8}\;\hnc{\mathbf{97.8}}\;\hnc{97.8}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{7.0}\;\hnc{0.0}\;\hnc{7.0}$ \\
			Gaussian       &  $\hnc{88.2}\;\hnc{71.8}\;\hnc{\mathbf{0.0}}\;\hnc{0.0}\;\hnc{0.0}$ &  $\hnc{87.4}\;\hnc{91.6}\;\hnc{98.7}\;\hnc{\mathbf{98.7}}\;\hnc{98.7}$ &  $\hnc{92.6}\;\hnc{95.0}\;\hnc{99.1}\;\hnc{\mathbf{99.1}}\;\hnc{99.1}$ &  $\hnc{75.1}\;\hnc{82.5}\;\hnc{97.8}\;\hnc{\mathbf{97.8}}\;\hnc{97.8}$ &  $\hnc{0.0}\;\hnc{0.0}\;\hnc{7.0}\;\hnc{0.0}\;\hnc{7.0}$ \\
			\bottomrule
		\end{tabular}
		\endgroup
	}
	\caption{(softmax ($T=0$), softmax ($T=1000$), softmax-perturb ($T=1000$), logits,  logits-perturb ($T=1000$))\\
		WRN-28-10, CIFAR-10,  $A = 0.9571$, $T=1000$, .}
	\label{tab:ood-wrn-cifar}
\end{table}

Eksperimenti su pokazali da klasifikacija maksimalnog logita s pomakom ulaza uz $T=1000$ daje skoro pa iste rezultate kao klasifikacija maksimalne vrijednosti softmaksa uz $T=1000$, tj. nije se vidjela razlika barem u prve $3$ decimale. Slijedi objašnjenje. Neka su $s_i=\vec s_\ind{i}$ logiti. Prema definiciji softmaksa,
\begin{align}
\softmax\del{\frac{1}{T}\vec s}_\ind{i} = \frac{\exp(s_i/T)}{\sum_j \exp(s_j/T)} \text{.}
\end{align}
Za dovoljno velik $T$ eksponencijalne funkcije se mogu linearno aproksimirati s velikom točnošću, pa 
\begin{align}
\softmax\del{\frac{1}{T}\vec s}_\ind{i}
\approx \frac{1+s_i/T}{\sum_j (1+s_j/T)}
= \frac{1+s_i/T}{C + \frac{1}{T}\sum_j s_j}
\text{,}
\end{align}
gdje je $C$ broj klasa. U eksperimentima s mrežama naučenim na skupu CIFAR-10, kod DN-100-12 je zbroj logita, neovisno o skupu, skoro uvijek ima vrijednost iz $\intcc{0.001,0.004}$, a maksimalni logit iz intervala $\intcc{2,30}$, a kod WRN-28-10 je zbroj logita skoro uvijek ima vrijednost iz $\intcc{0,0.0004}$, a maksimalni logit iz $\intcc{2,20}$. Primjeri iz različitih skupova su za DN-100-12 prikazani u prostoru \textit{maksimalni~logit~--~zbroj~logita} na slici~\ref{fig:dn-100-12-maxlogits-sumlogits}. Zbrojevi logita podijeljeni s velikom temperaturom $T$ su zanemarivi u odnosu na $C$, pa softmax možemo aproksimirati ovako:
\begin{align}
\softmax\del{\frac{1}{T}\vec s}_\ind{i}
\approx \frac{1+s_i/T}{C}
= \frac{1}{C}+\frac{1}{TC}s_i
\text{.}
\end{align}
Uz ovakvu aproksimaciju vidimo da se maksimalni izlaz softmaksa svodi na afinu transformaciju maksimalnog logita, pa se klasifikacija maksimalne vrijednosti softmaksa svodi na klasifikaciju maksimalnog logita.

\begin{figure}
	\centering
	\includegraphics[width=1\textwidth]{dn-100-12-maxlogits-sumlogits}
	\caption{Odnos maksimalnog logita i zbroja logita za različite skupove kod mreže DN-100-12. Svaka točka predstavlja jedan primjer iz podskupova s po $500$ primjera iz skupova korištenih za ispitivanje.}
	\label{fig:dn-100-12-maxlogits-sumlogits}
\end{figure}


\url{http://elbereth.zemris.fer.hr:8080/wiki_vision2/index.php?title=Uncertainty}



\chapter{Zaključak}

U ovom radu su opisani i eksperimentalno ispitani neki od nadziranih pristupa za procjenu nesigurnosti kod dubokih nadziranih modela. 

Jedna skupina razmatranih pristupa se temelji na aproksimaciji bayesovskih neuronskih mreža kod kojih se provodi bayesovska procjena parametara. Oni omogućuju procjenu nesigurnosti i razlikovanje je li uzrok nesigurnosti višeznačnost podatka ili nesigurnost u parametre modela, ali i uz jako jednostavnu varijacijsku razdiobu kojom se aproksimira aposteriorna razdioba parametara zahtijevaju puno više računanja u odnosu na uobičajene mreže. \citet{Gal:2016:BCNNBAVI} su učenje mreže s \textit{dropoutom} interpretirali kao varijacijsko zaključivanje. Za ovaj rad je ispitan pristup za procjenjivanje i razlikovanje nesigurnosti pomoću \textit{Monte Carlo dropouta} i drugih ideja iz \citet{Kendall:2017:WUNBDLCV,Smith:2018:UMUAED}.

Druga skupina razmatranih pristupa za procjenu nesigurnosti su pristupi za prepoznavanje primjera koji su izvan razdiobe skupa za učenje \citet{Guo:2017:CMNN,Hendrycks:2016:BDMOODE,Liang:2017:PDOODENN} na temelju maksimalnog izlaza softmaksa ili logita kod unaprijed naučenih modela. Postupci opisani u \citet{Hendrycks:2016:BDMOODE,Liang:2017:PDOODENN}, koji za klasifikaciju koriste maksimalni izlaz softmaksa, uspoređeni su s analognim postupcima koji umjesto maksimalnog izlaza softmaksa koriste maksimalni logit.


\bibliography{literatura}
\bibliographystyle{fer} 

\begin{sazetak}
Sažetak na hrvatskom jeziku.

\kljucnerijeci{Ključne riječi, odvojene zarezima.}
\end{sazetak}

% TODO: Navedite naslov na engleskom jeziku.
\engtitle{Title}
\begin{abstract}
Abstract.

\keywords{Keywords.}
\end{abstract}

\end{document}
